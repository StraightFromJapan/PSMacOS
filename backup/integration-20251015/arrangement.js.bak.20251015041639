// ========================================
// Standalone implementation
// ========================================

console.log('ðŸŽµ Arrangement View Loading...');

// State
const arrangementState = {
    tracks: [],
    clips: [],
    patterns: {},
    tempo: 120,
    zoom: 1,
    scrollX: 0,
    scrollY: 0,
    isPlaying: false,
    currentTime: 0,
    currentBarPosition: 0, // Track position in bars (tempo-independent)
    animationId: null,
    currentBar: 1,
    lastUpdateTime: 0, // For calculating delta time
    placeMode: null, // {type: 'sample'|'pattern', data: sampleNum|patternName}
    selectedClip: null,
    scheduledSources: [], // Audio sources for cleanup
    activeClipNodes: {}, // Store audio nodes for each clip by ID {clipId: {gainNode, filterNode, etc}}
    startTime: 0, // Playback start time
    editMode: 'stretch', // 'stretch' or 'trim'
    resizingClip: null, // {clip, edge: 'left'|'right', originalStart, originalLength, originalTrimStart}
    trimStart: 0, // For trim mode - where the sample starts playing from
    loopEnabled: false, // Whether loop is enabled
    loopStart: null, // Loop start bar (null = no loop)
    loopEnd: null // Loop end bar (null = no loop)
};

// Piano Roll State
let pianoRollData = {};
let currentSampleForPopup = null;
let isPreviewingPianoRoll = false;
let pianoRollPreviewNodes = {};
let pianoRollLoopInterval = null;
let pianoRollNoteLength = 1; // Default 1/16 note
let pianoRollFilterNodes = {};
let pianoRollVisualizer = null;
let pianoRollVisualizerCtx = null;
let pianoRollVisualizerAnalyzer = null;
let pianoRollVisualizerAnimationId = null;
let pianoRollVisualizerHistory = [];
const pianoRollVisualizerHistorySize = 100;
let pianoRollPreviewActiveVoices = {};
let pianoRollZoomLevel = 1.0;
let isEditingPattern = false; // Whether we're editing an existing pattern from arrangement
let currentEditingPatternName = null; // Name of pattern being edited
let pianoRollNotes = []; // Notes for the piano roll editor
let pianoRollGridWidth = 16; // Grid width for piano roll

// Note length options
const noteLengths = [
    { value: 0.0625, display: '1/64' },
    { value: 0.125, display: '1/32' },
    { value: 0.25, display: '1/16' },
    { value: 0.5, display: '1/8' },
    { value: 1, display: '1/4' },
    { value: 2, display: '1/2' },
    { value: 4, display: '1 bar' },
    { value: 8, display: '2 bars' }
];

// DOM Elements
let timelineCanvas, tracksContainer, playButton, stopButton;
let sampleDropdown, patternDropdown, playheadLine;
let patternEditorPopup; // Piano roll / Pattern editor popup

// Loop selection state
let isSelectingLoop = false; // Whether user is dragging to select loop
let loopSelectionStartBar = null; // Starting bar of selection

// Effects preview playback
let previewSource = null;
let previewGainNode = null;
let previewFilterNode = null;
let previewEqNodes = {};
let previewDelayNode = null;
let previewDelayWetGain = null; // Wet gain for delay effect
let previewFeedbackNode = null;
let previewReverbNode = null;
let previewReverbMixNode = null;
let previewDryNode = null;
let previewLfoNode = null;
let previewLfoGainNode = null;
let previewLfoUpdateTimeout = null;
let previewLoopTimeout = null; // Timeout for looping preview
let previewInterval = null;

// Reverb convolver nodes for preview
let previewReverbConvolver = null;
let previewReverbWetGain = null;
let previewLastReverbDecay = null; // Track last decay to avoid recreating impulse

// LFO and Automation systems for preview
let previewLfoOscillators = []; // Array of 4 LFO oscillators
let previewLfoGains = []; // Array of 4 LFO gain nodes
let previewAutomationIntervals = []; // Array of automation update intervals

// Interactive EQ Canvas
let eqCanvas = null;
let eqCtx = null;
const MAX_EQ_POINTS = 12;
let isDraggingEqBand = false;
let draggedPoint = null;
let isCreatingNewPoint = false;
let waveformAnalyzer = null;
let waveformAnimationId = null;
let waveformHistory = [];
const waveformHistorySize = 100;

// Audio Context (shared from main app if coming from there)
let audioContext = null;
let sampleBuffers = {}; // Store loaded sample buffers
let currentSampleFolder = 'mykicks'; // Default sample folder

// Load samples from main app localStorage
function loadSamplesFromStorage() {
    try {
        // Check if there's a saved folder name
        const savedFolder = localStorage.getItem('psychologicalStudioSampleFolder');
        if (savedFolder) {
            currentSampleFolder = savedFolder;
            console.log('ï¿½ Using sample folder:', currentSampleFolder);
        }
        
        // We don't need to store sample metadata
        // Just directly load from the folder when needed
        return {};
    } catch (e) {
        console.error('Failed to load folder info:', e);
    }
    return {};
}

// Initialize
// Helper: determine whether Arrangement was opened from PsychologicalStudio
function checkPsychStudioAccess() {
    try {
        // 0) If embedded into PsychologicalStudio as a single-app integration
        if (typeof window !== 'undefined' && window.PS_INTEGRATED === true) return true;
        // 1) Explicit localStorage key set by PsychologicalStudio before opening
        if (localStorage.getItem('psychologicalStudioArrangementAccess') === '1') return true;

        // 2) Opener is PsychologicalStudio (when opened via window.open from the studio)
        if (window.opener && window.opener.location && typeof window.opener.location.pathname === 'string') {
            if (window.opener.location.pathname.toLowerCase().includes('psychologicalstudio')) return true;
        }

        // 3) URL query param fallback (e.g. arrangement.html?ps_access=1)
        const params = new URLSearchParams(window.location.search);
        if (params.get('ps_access') === '1') return true;
    } catch (e) {
        console.warn('Error while checking PsychologicalStudio access:', e);
    }
    return false;
}

function showAccessLockedOverlay() {
    // If overlay exists, do nothing
    if (document.getElementById('ps-arrangement-locked-overlay')) return;

    const overlay = document.createElement('div');
    overlay.id = 'ps-arrangement-locked-overlay';
    overlay.style.position = 'fixed';
    overlay.style.top = '0';
    overlay.style.left = '0';
    overlay.style.width = '100%';
    overlay.style.height = '100%';
    overlay.style.background = 'rgba(0,0,0,0.85)';
    overlay.style.color = '#fff';
    overlay.style.zIndex = '99999';
    overlay.style.display = 'flex';
    overlay.style.flexDirection = 'column';
    overlay.style.alignItems = 'center';
    overlay.style.justifyContent = 'center';
    overlay.style.padding = '20px';

    overlay.innerHTML = `
        <div style="max-width:720px;text-align:center;">
            <h2 style="margin-bottom:8px;">Arrangement Locked</h2>
            <p style="margin-bottom:16px;color:#ddd;">This Arrangement view may only be opened from PsychologicalStudio. Please use the "Arrangement" button inside PsychologicalStudio to access it.</p>
            <div style="display:flex;gap:8px;justify-content:center;">
                <a id="ps-open-studio" href="./PsychologicalStudio.html" style="background:#3F51B5;color:#fff;padding:10px 14px;border-radius:6px;text-decoration:none;">Open PsychologicalStudio</a>
                <button id="ps-refresh-btn" style="background:#555;color:#fff;padding:10px 14px;border-radius:6px;border:none;cursor:pointer;">Retry</button>
            </div>
            <p style="margin-top:24px;color:#999;font-size:12px;">If you are the developer and want to open Arrangement directly for testing, set <code>localStorage.setItem('psychologicalStudioArrangementAccess','1')</code> in the console before reloading.</p>
        </div>
    `;

    document.body.appendChild(overlay);

    document.getElementById('ps-refresh-btn').addEventListener('click', () => {
        // Small retry: if access was granted by the opener, reload to re-check
        location.reload();
    });
}

// Wrapper to require access before running init
function requirePsychStudioAccessAndInit(initFn) {
    if (checkPsychStudioAccess()) {
        try {
            // Clear one-time localStorage token to prevent direct reuse (optional)
            localStorage.removeItem('psychologicalStudioArrangementAccess');
        } catch (e) {}
        initFn();
    } else {
        // block UI with overlay and do not run initialization
        document.addEventListener('DOMContentLoaded', () => showAccessLockedOverlay());
    }
}

// Wrap initialization so it can be triggered on DOMContentLoaded or immediately if the script is loaded after DOM ready
function __arrangementInitWrapper() {
    // Gate the full initialization behind PsychologicalStudio access (or integrated flag)
    requirePsychStudioAccessAndInit(() => {
        console.log('âœ… DOM Loaded - Initializing Arrangement View...');

    // Get DOM references
    timelineCanvas = document.getElementById('arrangement-timeline');
    tracksContainer = document.getElementById('arrangement-tracks');
    playButton = document.getElementById('arr-play');
    stopButton = document.getElementById('arr-stop');
    sampleDropdown = document.getElementById('arr-sample-select');
    patternDropdown = document.getElementById('arr-pattern-select');
    playheadLine = document.getElementById('playhead-line');
    patternEditorPopup = document.getElementById('pattern-popup');
    // Disable user selection across the whole page to prevent accidental text selection while dragging
    // Allow text selection in inputs/textareas/selects/contenteditable
    try {
        const style = document.createElement('style');
        style.id = 'disable-user-select-style';
        style.innerHTML = `
            * { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none !important; }
            input, textarea, select, [contenteditable="true"] { -webkit-user-select: text !important; -moz-user-select: text !important; -ms-user-select: text !important; user-select: text !important; }
        `;
        document.head.appendChild(style);
    } catch (e) {
        console.warn('Could not inject user-select style:', e);
    }

    console.log('ðŸ“‹ DOM Elements initialized:', {
        timelineCanvas: !!timelineCanvas,
        tracksContainer: !!tracksContainer,
        playButton: !!playButton,
        stopButton: !!stopButton,
        sampleDropdown: !!sampleDropdown,
        patternDropdown: !!patternDropdown,
        playheadLine: !!playheadLine,
        patternEditorPopup: !!patternEditorPopup
    });

        // Setup event listeners
        setupEventListeners();

        // Initialize context menu and effects popup
        initContextMenu();

    // Load saved data or create default tracks
    loadArrangementData();
    if (arrangementState.tracks.length === 0) {
        // Create 10 empty tracks on first load
        for (let i = 1; i <= 10; i++) {
            addTrack(`Track ${i}`);
        }
    }

    // Load samples from localStorage if available
    loadSamplesFromMainApp();

    // Initial render
    updateTrackBackgrounds();
    renderTimeline();

    // Update BPM display
    const bpmSlider = document.getElementById('arr-bpm-slider');
    const bpmValue = document.getElementById('arr-tempo-value');
    if (bpmSlider && bpmValue) {
        bpmSlider.value = arrangementState.tempo;
        bpmValue.textContent = arrangementState.tempo;
    }

        console.log('âœ… Arrangement View Ready!');
    });
}

document.addEventListener('DOMContentLoaded', __arrangementInitWrapper);
// If the document is already ready (script injected after DOMContentLoaded), run immediately
if (document.readyState !== 'loading') {
    try { __arrangementInitWrapper(); } catch (e) { console.warn('Arrangement init failed on immediate run:', e); }
}

// ========== EVENT LISTENERS ==========
function setupEventListeners() {
    // Scroll sync flags to prevent infinite loops
    let syncingScroll = false;
    let isDraggingTimeline = false;
    
    // Back button
    document.getElementById('arr-back').addEventListener('click', () => {
        try {
            // If integrated (iframe), notify parent to hide the embedded UI
            if (window !== window.parent) {
                window.parent.postMessage('ps-arrangement-close', '*');
                return;
            }
        } catch (e) {}
        // Fallback: navigate back to the studio page when standalone
        window.location.href = './PsychologicalStudio.html';
    });
    
    // Play/Stop
    playButton.addEventListener('click', playArrangement);
    stopButton.addEventListener('click', stopArrangement);
    
    // BPM Slider with real-time tempo changes
    const bpmSlider = document.getElementById('arr-bpm-slider');
    const bpmValue = document.getElementById('arr-tempo-value');
    if (bpmSlider) {
        let bpmChangeTimeout = null;
        
        bpmSlider.addEventListener('input', (e) => {
            const newBpm = parseInt(e.target.value);
            const oldBpm = arrangementState.tempo;
            const wasPlaying = arrangementState.isPlaying;
            const currentBarPos = arrangementState.currentBarPosition; // Save bar position, NOT time
            
            // Update tempo immediately for visual feedback
            arrangementState.tempo = newBpm;
            bpmValue.textContent = newBpm;
            
            // If playing, we need to restart with new tempo while maintaining bar position
            if (wasPlaying) {
                // Clear any pending restart
                if (bpmChangeTimeout) {
                    clearTimeout(bpmChangeTimeout);
                }
                
                // Debounce the restart to avoid excessive restarts while dragging slider
                bpmChangeTimeout = setTimeout(() => {
                    // Stop current playback
                    stopArrangement();
                    
                    // Restore bar position (this is key - maintain musical position, not time position)
                    arrangementState.currentBarPosition = currentBarPos;
                    
                    // Calculate new time position based on bar position and new tempo
                    const beatDuration = 60 / newBpm;
                    const barDuration = beatDuration * 4;
                    arrangementState.currentTime = currentBarPos * barDuration;
                    
                    // Restart playback
                    playArrangement();
                    
                    console.log(`ðŸŽµ BPM changed: ${oldBpm} â†’ ${newBpm} (bar position maintained at ${currentBarPos.toFixed(2)})`);
                }, 50); // 50ms debounce
            } else {
                console.log('ðŸŽµ BPM changed:', newBpm);
            }
        });
    }
    
    // Add track
    document.getElementById('arr-add-track').addEventListener('click', () => {
        addTrack(`Track ${arrangementState.tracks.length + 1}`);
    });
    
    // Sample dropdown
    sampleDropdown.addEventListener('change', function() {
        if (this.value) {
            // Keep string values for custom/recording samples, parse numbers for regular samples
            const sampleData = isNaN(parseInt(this.value)) ? this.value : parseInt(this.value);
            arrangementState.placeMode = {type: 'sample', data: sampleData};
            patternDropdown.value = ''; // Clear other dropdown
            console.log('ðŸ“ Place mode activated: Sample', sampleData);
        } else {
            // Deselected - cancel place mode
            arrangementState.placeMode = null;
            console.log('âŒ Place mode cancelled');
        }
    });
    
    // Pattern dropdown
    patternDropdown.addEventListener('change', function() {
        if (this.value) {
            arrangementState.placeMode = {type: 'pattern', data: this.value};
            sampleDropdown.value = ''; // Clear other dropdown
            console.log('ðŸ“ Place mode activated: Pattern', this.value);
        } else {
            // Deselected - cancel place mode
            arrangementState.placeMode = null;
            console.log('âŒ Place mode cancelled');
        }
    });
    
    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
        // Escape to cancel place mode
        if (e.key === 'Escape' && arrangementState.placeMode) {
            arrangementState.placeMode = null;
            sampleDropdown.value = '';
            patternDropdown.value = '';
            console.log('âŒ Place mode cancelled (Escape pressed)');
        }
    });
    
    // New pattern
    document.getElementById('arr-new-pattern').addEventListener('click', createNewPattern);
    
    // New sample - upload or record
    document.getElementById('arr-new-sample').addEventListener('click', handleNewSample);
    document.getElementById('arr-sample-file-input').addEventListener('change', handleSampleFileUpload);
    
    // Edit mode (Trim/Stretch)
    document.getElementById('edit-mode-stretch').addEventListener('change', (e) => {
        if (e.target.checked) {
            arrangementState.editMode = 'stretch';
            console.log('ðŸ”§ Edit mode: Stretch');
        }
    });
    document.getElementById('edit-mode-trim').addEventListener('change', (e) => {
        if (e.target.checked) {
            arrangementState.editMode = 'trim';
            console.log('âœ‚ï¸ Edit mode: Trim');
        }
    });
    
    // Save/Load/Clear
    document.getElementById('arr-save').addEventListener('click', () => saveArrangement(true));
    document.getElementById('arr-load').addEventListener('click', loadArrangement);
    document.getElementById('arr-clear').addEventListener('click', clearArrangement);
    
    // Zoom on scroll (desktop)
    timelineCanvas.addEventListener('wheel', handleTimelineZoom, { passive: false });
    
    // Drag to seek (desktop)
    // Prevent context menu on timeline (we'll use right-click for loop selection)
    timelineCanvas.addEventListener('contextmenu', (e) => {
        e.preventDefault();
    });
    
    // Timeline click to seek (left-click only)
    timelineCanvas.addEventListener('mousedown', (e) => {
        if (e.button === 0) {
            // Left click - seek
            isDraggingTimeline = true;
            handleTimelineSeek(e);
        } else if (e.button === 2) {
            // Right click - start loop selection
            isSelectingLoop = true;
            const bar = getBeatFromMouseX(e.clientX);
            loopSelectionStartBar = bar;
            arrangementState.loopStart = bar;
            arrangementState.loopEnd = bar;
            arrangementState.loopEnabled = true;
            renderTimeline();
            console.log('ðŸ” Loop selection started at bar:', bar);
        }
    });
    window.addEventListener('mousemove', (e) => {
        if (isDraggingTimeline) {
            handleTimelineSeek(e);
            // Auto-scroll when dragging the playhead near edges
            autoScrollDuringDrag(e.clientX);
        } else if (isSelectingLoop) {
            // Update loop end as mouse moves
            const bar = getBeatFromMouseX(e.clientX);
            
            // Set loop start/end based on drag direction
            if (bar >= loopSelectionStartBar) {
                arrangementState.loopStart = loopSelectionStartBar;
                arrangementState.loopEnd = bar;
            } else {
                arrangementState.loopStart = bar;
                arrangementState.loopEnd = loopSelectionStartBar;
            }
            renderTimeline();
        }
    });
    window.addEventListener('mouseup', (e) => {
        if (isSelectingLoop) {
            // Finalize loop selection
            isSelectingLoop = false;
            loopSelectionStartBar = null;
            
            // If loop is just one bar, disable it
            if (arrangementState.loopStart === arrangementState.loopEnd) {
                arrangementState.loopEnabled = false;
                arrangementState.loopStart = null;
                arrangementState.loopEnd = null;
                console.log('ðŸ” Loop disabled (single bar click)');
            } else {
                console.log(`ðŸ” Loop set: Bar ${arrangementState.loopStart} to ${arrangementState.loopEnd}`);
            }
            renderTimeline();
        }
        isDraggingTimeline = false;
    });
    
    // Touch interactions (mobile)
    let touchStartDist = 0;
    let initialZoom = 1;
    let isTouchSeeking = false;
    
    timelineCanvas.addEventListener('touchstart', (e) => {
        if (e.touches.length === 2) {
            // Two fingers - pinch to zoom
            touchStartDist = getTouchDistance(e.touches);
            initialZoom = arrangementState.zoom;
            e.preventDefault();
        } else if (e.touches.length === 1) {
            // One finger - seek
            isTouchSeeking = true;
            handleTimelineSeek(e.touches[0]);
        }
    }, { passive: false });
    
    timelineCanvas.addEventListener('touchmove', (e) => {
        if (e.touches.length === 2) {
            // Pinch zoom
            const currentDist = getTouchDistance(e.touches);
            const scale = currentDist / touchStartDist;
            const newZoom = Math.max(0.25, Math.min(4, initialZoom * scale));
            arrangementState.zoom = newZoom;
            updateZoomDisplay();
            updateTrackBackgrounds();
            renderTimeline();
            renderAllClips();
            e.preventDefault();
        } else if (e.touches.length === 1 && isTouchSeeking) {
            // Touch slide to seek
            handleTimelineSeek(e.touches[0]);
            autoScrollDuringDrag(e.touches[0].clientX);
            e.preventDefault();
        }
    }, { passive: false });
    
    timelineCanvas.addEventListener('touchend', (e) => {
        if (e.touches.length < 2) {
            touchStartDist = 0;
        }
        if (e.touches.length === 0) {
            isTouchSeeking = false;
        }
    });
    
    // Track click (for placing clips)
    const tracksScroll = document.getElementById('arrangement-tracks-scroll');
    tracksScroll.addEventListener('click', handleTrackClick);
    
    // Zoom on tracks area (desktop)
    tracksScroll.addEventListener('wheel', (e) => {
        // Horizontal scroll or small vertical scroll = zoom
        // Large vertical scroll = scroll between tracks
        const isHorizontalScroll = Math.abs(e.deltaX) > Math.abs(e.deltaY);
        const isSmallVerticalScroll = Math.abs(e.deltaY) < 40;
        
        if (isHorizontalScroll || isSmallVerticalScroll || e.ctrlKey || e.metaKey) {
            // Zoom
            e.preventDefault();
            const delta = e.deltaY > 0 ? 0.9 : 1.1;
            const newZoom = Math.max(0.25, Math.min(4, arrangementState.zoom * delta));
            
            // Calculate mouse position relative to tracks
            const rect = tracksScroll.getBoundingClientRect();
            const mouseX = e.clientX - rect.left;
            const scrollX = tracksScroll.scrollLeft;
            const oldBarWidth = 100 * arrangementState.zoom;
            const positionInArrangement = scrollX + mouseX;
            const barPosition = positionInArrangement / oldBarWidth;
            
            // Apply zoom
            arrangementState.zoom = newZoom;
            updateZoomDisplay();
            updateTrackBackgrounds();
            
            // Adjust scroll to keep same position under mouse
            const newBarWidth = 100 * newZoom;
            const newPositionInArrangement = barPosition * newBarWidth;
            tracksScroll.scrollLeft = Math.max(0, newPositionInArrangement - mouseX);
            
            renderTimeline();
            renderAllClips();
        }
        // Otherwise allow vertical scrolling for tracks
    }, { passive: false });
    
    // Scroll sync between timeline and tracks
    const timelineWrapper = document.getElementById('timeline-scroll-wrapper');
    
    tracksScroll.addEventListener('scroll', () => {
        if (syncingScroll) return;
        syncingScroll = true;
        
        arrangementState.scrollX = tracksScroll.scrollLeft;
        arrangementState.scrollY = tracksScroll.scrollTop;
        timelineWrapper.scrollLeft = tracksScroll.scrollLeft; // Sync timeline horizontal scroll
        
        // Sync track headers vertical scroll
        const trackHeaders = document.getElementById('track-headers');
        trackHeaders.scrollTop = tracksScroll.scrollTop;
        
        renderTimeline();
        
        syncingScroll = false;
    });
    
    timelineWrapper.addEventListener('scroll', () => {
        if (syncingScroll) return;
        syncingScroll = true;
        
        tracksScroll.scrollLeft = timelineWrapper.scrollLeft; // Sync tracks horizontal scroll
        
        syncingScroll = false;
    });
    
    // Sync vertical scroll from track headers back to tracks
    const trackHeaders = document.getElementById('track-headers');
    trackHeaders.addEventListener('scroll', () => {
        if (syncingScroll) return;
        syncingScroll = true;
        
        tracksScroll.scrollTop = trackHeaders.scrollTop;
        
        syncingScroll = false;
    });
}

// ========== TRACK MANAGEMENT ==========
function addTrack(name) {
    console.log(`âž• Adding track: ${name}`);
    
    const trackIndex = arrangementState.tracks.length;
    arrangementState.tracks.push({
        name: name,
        muted: false,
        solo: false
    });
    
    // Add track header
    const trackHeaders = document.getElementById('track-headers');
    const header = document.createElement('div');
    header.className = 'track-header';
    header.dataset.trackIndex = trackIndex;
    header.innerHTML = `
        <div class="track-name">${name}</div>
        <div class="track-controls">
            <button class="track-btn track-mute-btn" title="Mute">M</button>
            <button class="track-btn track-solo-btn" title="Solo">S</button>
            <button class="track-btn track-delete-btn" title="Delete">X</button>
        </div>
    `;
    trackHeaders.appendChild(header);
    
    // Apply theme to track buttons immediately using computed styles
    const trackBtns = header.querySelectorAll('.track-btn');
    const computedAccent = getComputedStyle(document.documentElement).getPropertyValue('--accent-color').trim();
    const computedText = getComputedStyle(document.documentElement).getPropertyValue('--text-color').trim();
    const computedBorder = getComputedStyle(document.documentElement).getPropertyValue('--border-color').trim();
    
    trackBtns.forEach(btn => {
        if (computedAccent) btn.style.backgroundColor = computedAccent;
        if (computedText) btn.style.color = computedText;
        if (computedBorder) btn.style.borderColor = computedBorder;
    });
    
    // Add track lane
    const lane = document.createElement('div');
    lane.className = 'track-lane';
    lane.dataset.trackIndex = trackIndex;
    
    // Add canvas for grid background
    const canvas = document.createElement('canvas');
    canvas.className = 'track-lane-canvas';
    canvas.width = 5000;
    canvas.height = 58; // Leave room for 2px border
    lane.appendChild(canvas);
    
    tracksContainer.appendChild(lane);
    
    // Event listeners
    header.querySelector('.track-delete-btn').addEventListener('click', () => deleteTrack(trackIndex));
    
    // Render grid on canvas
    renderTrackGrid(canvas);
    renderTimeline();
    saveArrangement(false);
    
    console.log(`âœ… Track "${name}" added!`);
}

function deleteTrack(index) {
    if (arrangementState.tracks.length <= 1) {
        alert('Cannot delete the last track!');
        return;
    }
    
    if (!confirm(`Delete ${arrangementState.tracks[index].name}?`)) return;
    
    // Remove clips on this track
    arrangementState.clips = arrangementState.clips.filter(clip => clip.trackIndex !== index);
    
    // Remove track
    arrangementState.tracks.splice(index, 1);
    
    // Rebuild UI
    rebuildTrackList();
    renderAllClips();
    saveArrangement(false);
}

function rebuildTrackList() {
    const trackHeaders = document.getElementById('track-headers');
    trackHeaders.innerHTML = '';
    tracksContainer.innerHTML = '';
    
    arrangementState.tracks.forEach((track, index) => {
        const header = document.createElement('div');
        header.className = 'track-header';
        header.dataset.trackIndex = index;
        header.innerHTML = `
            <div class="track-name">${track.name}</div>
            <div class="track-controls">
                <button class="track-btn track-mute-btn" title="Mute">M</button>
                <button class="track-btn track-solo-btn" title="Solo">S</button>
                <button class="track-btn track-delete-btn" title="Delete">X</button>
            </div>
        `;
        trackHeaders.appendChild(header);
        
        // Apply theme to track buttons immediately using computed styles
        const trackBtns = header.querySelectorAll('.track-btn');
        const computedAccent = getComputedStyle(document.documentElement).getPropertyValue('--accent-color').trim();
        const computedText = getComputedStyle(document.documentElement).getPropertyValue('--text-color').trim();
        const computedBorder = getComputedStyle(document.documentElement).getPropertyValue('--border-color').trim();
        
        trackBtns.forEach(btn => {
            if (computedAccent) btn.style.backgroundColor = computedAccent;
            if (computedText) btn.style.color = computedText;
            if (computedBorder) btn.style.borderColor = computedBorder;
        });
        
        const lane = document.createElement('div');
        lane.className = 'track-lane';
        lane.dataset.trackIndex = index;
        
        // Add canvas for grid background
        const canvas = document.createElement('canvas');
        canvas.className = 'track-lane-canvas';
        canvas.width = 5000;
        canvas.height = 58; // Leave room for 2px border
        lane.appendChild(canvas);
        
        tracksContainer.appendChild(lane);
        
        // Render grid on canvas
        renderTrackGrid(canvas);
        
        header.querySelector('.track-delete-btn').addEventListener('click', () => deleteTrack(index));
    });
}

// ========== TIMELINE RENDERING ==========
function renderTimeline() {
    const ctx = timelineCanvas.getContext('2d');
    
    const zoom = arrangementState.zoom;
    const numBars = 50;
    const barWidth = Math.round(100 * zoom);
    const totalWidth = numBars * barWidth;
    
    // Set CSS width for layout
    timelineCanvas.style.width = totalWidth + 'px';
    timelineCanvas.style.height = '40px';
    
    // Use higher resolution for crisp rendering, but reasonable size
    const dpr = window.devicePixelRatio || 1;
    const minResolution = 5000; // Minimum resolution for quality
    const canvasWidth = Math.max(totalWidth * dpr, minResolution);
    timelineCanvas.width = canvasWidth;
    timelineCanvas.height = 40 * dpr;
    
    // Calculate scale factor from canvas to displayed width
    const scale = canvasWidth / totalWidth;
    
    const width = canvasWidth;
    const height = 40 * dpr;
    
    // Get current theme colors
    const theme = getCurrentTheme();
    
    ctx.fillStyle = theme.timelineBg;
    ctx.fillRect(0, 0, width, height);
    
    const scaledBarWidth = barWidth * scale;
    const beatWidth = scaledBarWidth / 4;
    const stepWidth = beatWidth / 4;
    
    // Draw bar lines
    ctx.strokeStyle = theme.barLine;
    ctx.lineWidth = 2 * dpr;
    
    // Font size that compensates for canvas-to-display scaling - increased base size
    const fontSize = Math.max(10, Math.min(16, (12 / scale) * dpr));
    ctx.font = `bold ${fontSize}px Arial`;
    
    for (let i = 0; i < numBars; i++) {
        // Calculate bar position in canvas pixels
        const barX = i * scaledBarWidth;
        
        if (barX >= width) break;
        
        // Bar line (thick)
        ctx.beginPath();
        ctx.moveTo(barX, 0);
        ctx.lineTo(barX, height);
        ctx.stroke();
        
        // Draw beat numbers (1.1, 1.2, 1.3, 1.4) - visible at normal
        const minBeatWidth = 15 * scale; // Lower threshold for beat numbers
        const minBarWidth = 10 * scale; // Even lower threshold for just bar numbers
        
        if (beatWidth > minBeatWidth) {
            // Show full beat notation (1.1, 1.2, etc.)
            for (let beat = 0; beat < 4; beat++) {
                const beatX = barX + beat * beatWidth;
                const barNum = i + 1;
                const beatNum = beat + 1;
                
                // Draw bar number in accent color, beat number in white
                const barText = `${barNum}`;
                const beatText = `.${beatNum}`;
                
                // Measure text widths
                ctx.fillStyle = theme.accent; // Theme accent for bar number
                ctx.fillText(barText, beatX + 5 * dpr, 15 * dpr);
                const barTextWidth = ctx.measureText(barText).width;
                
                ctx.fillStyle = theme.text; // Theme text color for beat number
                ctx.fillText(beatText, beatX + 5 * dpr + barTextWidth, 15 * dpr);
            }
        } else if (scaledBarWidth > minBarWidth) {
            // When zoomed out too much, show only bar numbers in accent color
            const barNum = i + 1;
            ctx.fillStyle = theme.accent; // Theme accent for bar number
            ctx.fillText(`${barNum}`, barX + 5 * dpr, 15 * dpr);
        }
        
        // Draw beat subdivisions within each bar
        ctx.strokeStyle = theme.beatLine;
        ctx.lineWidth = 1 * dpr;
        for (let beat = 1; beat < 4; beat++) {
            const beatX = barX + beat * beatWidth;
            if (beatX < width) {
                ctx.beginPath();
                ctx.moveTo(beatX, height * 0.3);
                ctx.lineTo(beatX, height);
                ctx.stroke();
            }
        }
        
        // Draw step subdivisions (lighter) - only if zoomed in enough
        if (stepWidth > 2 * dpr) {
            ctx.strokeStyle = theme.stepLine;
            ctx.lineWidth = 0.5 * dpr;
            for (let step = 1; step < 16; step++) {
                if (step % 4 === 0) continue; // Skip beat lines
                const stepX = barX + step * stepWidth;
                if (stepX < width) {
                    ctx.beginPath();
                    ctx.moveTo(stepX, height * 0.6);
                    ctx.lineTo(stepX, height);
                    ctx.stroke();
                }
            }
        }
        
        ctx.strokeStyle = theme.barLine;
        ctx.lineWidth = 2 * dpr;
    }
    
    // Draw loop region if enabled
    if (arrangementState.loopEnabled && arrangementState.loopStart !== null && arrangementState.loopEnd !== null) {
        const loopStartX = (arrangementState.loopStart - 1) * scaledBarWidth;
        const loopEndX = arrangementState.loopEnd * scaledBarWidth;
        const loopWidth = loopEndX - loopStartX;
        
        // Semi-transparent overlay with theme accent color
        const accentRgb = hexToRgb(theme.accent);
        ctx.fillStyle = `rgba(${accentRgb.r}, ${accentRgb.g}, ${accentRgb.b}, 0.2)`;
        ctx.fillRect(loopStartX, 0, loopWidth, height);
        
        // Loop region borders
        ctx.strokeStyle = theme.accent;
        ctx.lineWidth = 3 * dpr;
        ctx.beginPath();
        ctx.moveTo(loopStartX, 0);
        ctx.lineTo(loopStartX, height);
        ctx.stroke();
        ctx.beginPath();
        ctx.moveTo(loopEndX, 0);
        ctx.lineTo(loopEndX, height);
        ctx.stroke();
        
        // Loop markers at top
        ctx.fillStyle = theme.accent;
        const markerSize = 8 * dpr;
        // Start marker (down arrow)
        ctx.beginPath();
        ctx.moveTo(loopStartX, 0);
        ctx.lineTo(loopStartX - markerSize / 2, markerSize);
        ctx.lineTo(loopStartX + markerSize / 2, markerSize);
        ctx.closePath();
        ctx.fill();
        // End marker (down arrow)
        ctx.beginPath();
        ctx.moveTo(loopEndX, 0);
        ctx.lineTo(loopEndX - markerSize / 2, markerSize);
        ctx.lineTo(loopEndX + markerSize / 2, markerSize);
        ctx.closePath();
        ctx.fill();
        
        // Loop label
        ctx.font = `bold ${fontSize}px Arial`;
        ctx.fillStyle = theme.text;
        const loopText = `LOOP: ${arrangementState.loopStart}-${arrangementState.loopEnd}`;
        const textWidth = ctx.measureText(loopText).width;
        const textX = loopStartX + (loopWidth - textWidth) / 2;
        ctx.fillText(loopText, textX, height - 8 * dpr);
    }
}

// Helper function to convert hex to RGB
function hexToRgb(hex) {
    const result = /^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(hex);
    return result ? {
        r: parseInt(result[1], 16),
        g: parseInt(result[2], 16),
        b: parseInt(result[3], 16)
    } : { r: 0, g: 0, b: 0 };
}

// Helper function to get bar number from mouse X position with sub-beat precision
function getBarFromMouseX(clientX, offsetX) {
    if (!timelineCanvas) {
        console.warn('âš ï¸ Timeline canvas not initialized');
        return 0;
    }
    
    // If offsetX is provided (from event.offsetX), use it directly
    // offsetX gives position relative to the element, accounting for scroll
    if (offsetX !== undefined && offsetX !== null) {
        const totalWidth = 50 * (100 * arrangementState.zoom);
        const barWidth = 100 * arrangementState.zoom;
        const bar = offsetX / barWidth;
        return Math.max(0, bar);
    }
    
    // Fallback to clientX method
    const rect = timelineCanvas.getBoundingClientRect();
    const timelineWrapper = document.getElementById('timeline-scroll-wrapper');
    const scrollX = timelineWrapper ? timelineWrapper.scrollLeft : arrangementState.scrollX;
    
    const x = clientX - rect.left + scrollX;
    const barWidth = 100 * arrangementState.zoom;
    const bar = x / barWidth;
    
    return Math.max(0, bar);
}

// Helper function for snapped bar position (used when placing clips)
function getSnappedBarFromMouseX(clientX, offsetX) {
    if (!timelineCanvas) {
        console.warn('âš ï¸ Timeline canvas not initialized');
        return 0;
    }
    
    // If offsetX is provided, use it directly
    if (offsetX !== undefined && offsetX !== null) {
        const barWidth = 100 * arrangementState.zoom;
        const beatWidth = barWidth / 4;
        const stepWidth = beatWidth / 4; // 1/16th note precision
        
        // Snap to nearest 1/16th step
        const steps = Math.round(offsetX / stepWidth);
        const snappedX = steps * stepWidth;
        const bar = snappedX / barWidth;
        
        return Math.max(0, bar);
    }
    
    // Fallback to clientX method
    const rect = timelineCanvas.getBoundingClientRect();
    const timelineWrapper = document.getElementById('timeline-scroll-wrapper');
    const scrollX = timelineWrapper ? timelineWrapper.scrollLeft : arrangementState.scrollX;
    
    const x = clientX - rect.left + scrollX;
    const barWidth = 100 * arrangementState.zoom;
    const beatWidth = barWidth / 4;
    const stepWidth = beatWidth / 4; // 1/16th note precision
    
    // Snap to nearest 1/16th step
    const steps = Math.round(x / stepWidth);
    const snappedX = steps * stepWidth;
    const bar = snappedX / barWidth;
    
    return Math.max(0, bar);
}

// Helper function to get beat-precise position (for loop selection)
function getBeatFromMouseX(clientX) {
    if (!timelineCanvas) {
        console.warn('âš ï¸ Timeline canvas not initialized');
        return 1;
    }
    const rect = timelineCanvas.getBoundingClientRect();
    const x = clientX - rect.left + arrangementState.scrollX;
    const barWidth = 100 * arrangementState.zoom;
    const beatWidth = barWidth / 4;
    
    // Snap to nearest beat (quarter note)
    const beats = Math.round(x / beatWidth);
    const bar = Math.floor(beats / 4) + 1; // Convert to bar number (1-indexed)
    
    return Math.max(1, bar);
}

function handleTimelineSeek(e) {
    if (!timelineCanvas) {
        console.warn('âš ï¸ Timeline canvas not initialized');
        return;
    }
    const clientX = e.clientX || (e.touches && e.touches[0] ? e.touches[0].clientX : 0);
    const offsetX = e.offsetX !== undefined ? e.offsetX : null;
    
    // Debug info
    console.log(`ðŸ“ SEEK: clientX=${clientX}, offsetX=${offsetX}, zoom=${arrangementState.zoom}`);
    
    const barPosition = getBarFromMouseX(clientX, offsetX);
    console.log(`    â†’ Calculated barPosition: ${barPosition.toFixed(3)}`);
    
    // Update playhead position with sub-beat precision
    const beatDuration = 60 / arrangementState.tempo;
    const barDuration = beatDuration * 4;
    
    // Update BOTH time and bar position
    arrangementState.currentTime = barPosition * barDuration;
    arrangementState.currentBarPosition = barPosition; // Set bar position for tempo-independent tracking
    arrangementState.currentBar = Math.floor(barPosition) + 1;
    
    document.getElementById('arr-current-bar').textContent = arrangementState.currentBar;
    renderTimeline();
    
    // If playing, restart from new position
    if (arrangementState.isPlaying) {
        stopArrangement();
        playArrangement();
    }
}

function handleTimelineZoom(e) {
    e.preventDefault();
    e.stopPropagation(); // Prevent scroll event from propagating
    
    // Zoom in/out based on scroll direction
    const delta = e.deltaY > 0 ? 0.9 : 1.1;
    const newZoom = Math.max(0.25, Math.min(4, arrangementState.zoom * delta));
    
    // Calculate mouse position in arrangement space before zoom
    const rect = timelineCanvas.getBoundingClientRect();
    const mouseX = e.clientX - rect.left;
    const scrollX = arrangementState.scrollX;
    const oldBarWidth = 100 * arrangementState.zoom;
    const positionInArrangement = scrollX + mouseX;
    const barPosition = positionInArrangement / oldBarWidth;
    
    // Apply zoom
    arrangementState.zoom = newZoom;
    updateZoomDisplay();
    updateTrackBackgrounds();
    
    // Adjust scroll to keep same bar position under mouse
    const newBarWidth = 100 * newZoom;
    const newPositionInArrangement = barPosition * newBarWidth;
    const tracksScroll = document.getElementById('arrangement-tracks-scroll');
    tracksScroll.scrollLeft = Math.max(0, newPositionInArrangement - mouseX);
    
    renderTimeline();
    renderAllClips();
}

function getTouchDistance(touches) {
    const dx = touches[0].clientX - touches[1].clientX;
    const dy = touches[0].clientY - touches[1].clientY;
    return Math.sqrt(dx * dx + dy * dy);
}

function updateZoomDisplay() {
    const zoomDisplay = document.getElementById('arr-zoom-display');
    if (zoomDisplay) {
        const percentage = Math.round(arrangementState.zoom * 100);
        zoomDisplay.textContent = `${percentage}%`;
    }
}

// Auto-scroll tracks/timeline when pointer is near left/right edges during drag
function autoScrollDuringDrag(clientX) {
    const tracksScroll = document.getElementById('arrangement-tracks-scroll');
    const timelineWrapper = document.getElementById('timeline-scroll-wrapper');
    if (!tracksScroll || !timelineWrapper) return;

    const rect = tracksScroll.getBoundingClientRect();
    const edgeMargin = 40;
    // Use clientWidth to compute right edge relative to left so we don't depend on rect.right
    const leftEdge = rect.left + edgeMargin; // start scrolling when 40px from left
    const rightEdge = rect.left + tracksScroll.clientWidth - edgeMargin; // start scrolling when 40px from right
    // Compute distance from edges and derive a proportional, capped speed so scrolling feels smooth
    // Increase speeds for more responsive scrolling during direct drag events
    const maxSpeed = 140; // max px per event (was 40)
    const minSpeed = 6;   // min px per event when pointer is just inside threshold (was 3)

    if (clientX < leftEdge) {
        const dist = Math.max(0, leftEdge - clientX);
        const speed = Math.min(maxSpeed, Math.max(minSpeed, Math.ceil(dist / 3)));
        tracksScroll.scrollLeft = Math.max(0, tracksScroll.scrollLeft - speed);
        timelineWrapper.scrollLeft = tracksScroll.scrollLeft;
        arrangementState.scrollX = tracksScroll.scrollLeft;
        renderTimeline();
        // Avoid renderAllClips here while a clip is actively being dragged; re-render is done on drop
        if (!arrangementState.draggingClipId) renderAllClips();
    } else if (clientX > rightEdge) {
        const dist = Math.max(0, clientX - rightEdge);
        const speed = Math.min(maxSpeed, Math.max(minSpeed, Math.ceil(dist / 3)));
        tracksScroll.scrollLeft = Math.min(tracksScroll.scrollWidth - tracksScroll.clientWidth, tracksScroll.scrollLeft + speed);
        timelineWrapper.scrollLeft = tracksScroll.scrollLeft;
        arrangementState.scrollX = tracksScroll.scrollLeft;
        renderTimeline();
        if (!arrangementState.draggingClipId) renderAllClips();
    }
}

// Smooth auto-scroll using requestAnimationFrame while dragging
function startAutoScrollLoop() {
    if (arrangementState._autoScrollRunning) return;
    arrangementState._autoScrollRunning = true;
    arrangementState._autoScrollLastTime = performance.now();
    arrangementState._autoScrollRAF = requestAnimationFrame(autoScrollLoop);
}

function stopAutoScrollLoop() {
    if (!arrangementState._autoScrollRunning) return;
    arrangementState._autoScrollRunning = false;
    if (arrangementState._autoScrollRAF) {
        cancelAnimationFrame(arrangementState._autoScrollRAF);
        arrangementState._autoScrollRAF = null;
    }
    arrangementState._autoScrollPointerX = null;
    arrangementState._autoScrollPointerY = null;
}

function autoScrollLoop(now) {
    if (!arrangementState._autoScrollRunning) return;
    const last = arrangementState._autoScrollLastTime || now;
    const dt = Math.max(1, now - last);
    arrangementState._autoScrollLastTime = now;

    const tracksScroll = document.getElementById('arrangement-tracks-scroll');
    const timelineWrapper = document.getElementById('timeline-scroll-wrapper');
    if (!tracksScroll || !timelineWrapper) {
        stopAutoScrollLoop();
        return;
    }

    const rect = tracksScroll.getBoundingClientRect();
    const edgeMargin = 40;
    const leftEdge = rect.left + edgeMargin;
    const rightEdge = rect.left + tracksScroll.clientWidth - edgeMargin;
    const pxPointer = arrangementState._autoScrollPointerX;
    const pyPointer = arrangementState._autoScrollPointerY;

    // Horizontal auto-scroll
    if (pxPointer != null) {
        // Increase speeds and tighten normalization for snappier scrolling
        const maxSpeed = 900; // px per second
        const minSpeed = 40;  // px per second

        let scrollDelta = 0;
        if (pxPointer < leftEdge) {
            const dist = Math.max(0, leftEdge - pxPointer);
            const t = Math.min(1, dist / 120); // normalize over 120px (was 200)
            const speed = Math.round(minSpeed + (maxSpeed - minSpeed) * (t * t)); // quadratic ease
            scrollDelta = -Math.round(speed * (dt / 1000));
        } else if (pxPointer > rightEdge) {
            const dist = Math.max(0, pxPointer - rightEdge);
            const t = Math.min(1, dist / 120);
            const speed = Math.round(minSpeed + (maxSpeed - minSpeed) * (t * t));
            scrollDelta = Math.round(speed * (dt / 1000));
        }

        if (scrollDelta !== 0) {
            const newLeft = Math.max(0, Math.min(tracksScroll.scrollWidth - tracksScroll.clientWidth, tracksScroll.scrollLeft + scrollDelta));
            if (newLeft !== tracksScroll.scrollLeft) {
                tracksScroll.scrollLeft = newLeft;
                timelineWrapper.scrollLeft = newLeft;
                arrangementState.scrollX = newLeft;
                // only re-render timeline while dragging; clips are re-rendered on drop
                renderTimeline();
            }
        }
    }

    // Vertical auto-scroll (scroll tracks vertically when pointer near top/bottom)
    if (pyPointer != null) {
    const topEdge = rect.top + 40;
    const bottomEdge = rect.top + tracksScroll.clientHeight - 40;
    // make vertical scroll faster so dragging to bottom moves the viewport promptly
    const maxVSpeed = 700; // px per second
    const minVSpeed = 30; // px per second

        let vDelta = 0;
        if (pyPointer < topEdge) {
            const dist = Math.max(0, topEdge - pyPointer);
            const t = Math.min(1, dist / 120);
            const speed = Math.round(minVSpeed + (maxVSpeed - minVSpeed) * (t * t));
            vDelta = -Math.round(speed * (dt / 1000));
        } else if (pyPointer > bottomEdge) {
            const dist = Math.max(0, pyPointer - bottomEdge);
            const t = Math.min(1, dist / 120);
            const speed = Math.round(minVSpeed + (maxVSpeed - minVSpeed) * (t * t));
            vDelta = Math.round(speed * (dt / 1000));
        }

        if (vDelta !== 0) {
            const newTop = Math.max(0, Math.min(tracksScroll.scrollHeight - tracksScroll.clientHeight, tracksScroll.scrollTop + vDelta));
            if (newTop !== tracksScroll.scrollTop) {
                tracksScroll.scrollTop = newTop;
                arrangementState.scrollY = newTop;
                // we don't re-render clips here; visual transform keeps drag smooth
            }
        }
    }

    arrangementState._autoScrollRAF = requestAnimationFrame(autoScrollLoop);
}

// ========== CLIP MANAGEMENT ==========
async function handleTrackClick(e) {
    if (!arrangementState.placeMode) return;
    
    const target = e.target.closest('.track-lane');
    if (!target) return;
    
    const trackIndex = parseInt(target.dataset.trackIndex);
    
    // Calculate bar position from track click
    // The track-lane's getBoundingClientRect() already accounts for parent scroll
    // So we just need offsetX if available, or calculate from clientX
    let x;
    
    // Calculate x from clientX using the tracks scroll container as stable reference
    const tracksScroll = document.getElementById('arrangement-tracks-scroll');
    // Use tracksScroll as the stable reference for horizontal coordinates, which handles zoom/scroll correctly
    const tracksRect = tracksScroll ? tracksScroll.getBoundingClientRect() : target.getBoundingClientRect();
    const scrollLeft = tracksScroll ? tracksScroll.scrollLeft : arrangementState.scrollX;
    x = e.clientX - tracksRect.left + scrollLeft;
    console.log(`ðŸŽ¯ Track click computed (tracksRect): clientX=${e.clientX}, tracksRect.left=${tracksRect.left}, scrollLeft=${scrollLeft}, x=${x}`);
    
    const barWidth = 100 * arrangementState.zoom;
    const beatWidth = barWidth / 4;
    const stepWidth = beatWidth / 4; // 1/16th note precision
    
    // Snap to nearest 1/16th step
    const steps = Math.round(x / stepWidth);
    const snappedX = steps * stepWidth;
    const bar = Math.max(0, snappedX / barWidth);
    
    console.log(`    â†’ bar=${bar.toFixed(3)}, barWidth=${barWidth}`);
    
    let clipLength = 1; // Default to 1 bar
    
    // For samples, calculate actual length based on sample duration at 120 BPM reference
    if (arrangementState.placeMode.type === 'sample') {
        const sampleNum = arrangementState.placeMode.data;
        
        // Try to load sample if not already loaded (only for numbered samples)
        if (!sampleBuffers[sampleNum] && typeof sampleNum === 'number') {
            console.log(`ðŸ“¦ Loading sample ${sampleNum} to calculate length...`);
            await loadSampleBuffer(sampleNum);
        }
        
        // Calculate clip length in bars at reference tempo (120 BPM)
        // This ensures sample clips maintain consistent visual size regardless of project BPM
        if (sampleBuffers[sampleNum]) {
            const sampleDuration = sampleBuffers[sampleNum].duration; // in seconds
            const referenceBeatDuration = 60 / 120; // 120 BPM reference
            const referenceBarDuration = referenceBeatDuration * 4; // 4 beats per bar
            const exactBars = sampleDuration / referenceBarDuration;
            
            // Only round up if we're more than 90% into the next bar
            // This prevents short samples from appearing too long
            if (exactBars - Math.floor(exactBars) > 0.9) {
                clipLength = Math.ceil(exactBars);
            } else {
                clipLength = Math.max(1, Math.floor(exactBars));
            }
            
            console.log(`  Sample duration: ${sampleDuration.toFixed(2)}s = ${exactBars.toFixed(2)} bars @ 120BPM â†’ displayed as ${clipLength} bars`);
        }
    } else if (arrangementState.placeMode.type === 'pattern') {
        // Patterns have predefined length
        const pattern = arrangementState.patterns[arrangementState.placeMode.data];
        clipLength = pattern ? pattern.length : 4;
    }
    
    // Check for collision with existing clips
    const hasCollision = arrangementState.clips.some(existingClip => {
        if (existingClip.trackIndex !== trackIndex) return false;
        
        const existingStart = existingClip.startBar;
        const existingEnd = existingClip.startBar + existingClip.length;
        const newStart = bar;
        const newEnd = bar + clipLength;
        
        // Check if ranges overlap
        return (newStart < existingEnd && newEnd > existingStart);
    });
    
    if (hasCollision) {
        console.log('âš ï¸ Cannot place clip here - collision with existing clip');
        return; // Don't place the clip
    }
    
    const clip = {
        id: Date.now(),
        trackIndex: trackIndex,
        startBar: bar,
        type: arrangementState.placeMode.type,
        data: arrangementState.placeMode.data,
        length: clipLength,
        trimStart: 0, // For trim mode - which bar to start playing from
        stretchMode: false // Whether this clip has been stretched (false = trim mode)
    };
    
    arrangementState.clips.push(clip);
    renderClip(clip);
    saveArrangement(false);
    
    console.log('âœ… Clip placed:', clip);
    
    // If currently playing, schedule this new clip if it should be playing
    if (arrangementState.isPlaying) {
        // Calculate precise current position
        const elapsedTime = audioContext.currentTime - arrangementState.startTime;
        const secondsPerBar = 60 / arrangementState.tempo * 4;
        const currentBarPrecise = elapsedTime / secondsPerBar;
        
        const clipEndBar = clip.startBar + clip.length;
        
        // If the clip overlaps with current playback position
        if (clip.startBar <= currentBarPrecise && currentBarPrecise < clipEndBar) {
            // Calculate how far into the clip we should be
            const barsIntoClip = currentBarPrecise - clip.startBar;
            const offsetIntoClip = barsIntoClip * secondsPerBar;
            
            // Schedule from current time with offset
            if (clip.type === 'sample') {
                scheduleClipWithOffset(clip, audioContext.currentTime, offsetIntoClip);
            }
        } else if (clip.startBar > currentBarPrecise) {
            // Clip is ahead of playhead, calculate exact time until it should play
            const barsUntilClip = clip.startBar - currentBarPrecise;
            const timeUntilClip = barsUntilClip * secondsPerBar;
            const startTime = audioContext.currentTime + timeUntilClip;
            
            if (clip.type === 'sample') {
                scheduleSampleClip(clip, startTime);
            }
        }
    }
    
    // DON'T reset place mode - allow multiple placements
    // User can deselect dropdown or press Escape to exit
}

function renderClip(clip) {
    const lane = tracksContainer.querySelector(`[data-track-index="${clip.trackIndex}"]`);
    if (!lane) return;
    
    const barWidth = 100 * arrangementState.zoom;
    const clipEl = document.createElement('div');
    clipEl.className = `clip ${clip.type}`;
    clipEl.dataset.clipId = clip.id;
    clipEl.style.left = (clip.startBar * barWidth) + 'px';
    clipEl.style.width = (clip.length * barWidth - 4) + 'px';
    
    if (clip.type === 'sample') {
        renderSampleClip(clipEl, clip);
    } else if (clip.type === 'pattern') {
        renderPatternClip(clipEl, clip);
    }
    
    // Context menu on right-click (desktop) and long-press (mobile)
    let longPressTimer = null;
    
    // FEATURE [4]: Click on clip to select it and copy its settings
    clipEl.addEventListener('click', (e) => {
        // Don't trigger if we're resizing
        if (arrangementState.resizingClip) return;
        
        // Select this clip's type and value in the dropdowns
        if (clip.type === 'sample') {
            const sampleSelect = document.getElementById('arr-sample-select');
            sampleSelect.value = clip.data;
            console.log(`âœ… Selected sample clip: ${clip.data}`);
        } else if (clip.type === 'pattern') {
            const patternSelect = document.getElementById('arr-pattern-select');
            patternSelect.value = clip.data;
            console.log(`âœ… Selected pattern clip: ${clip.data}`);
        }
        
        // Visual feedback
        document.querySelectorAll('.clip').forEach(c => c.style.outline = 'none');
        clipEl.style.outline = '3px solid #FFD700';
        setTimeout(() => {
            clipEl.style.outline = 'none';
        }, 1000);
    });
    
    // Context menu on right-click (desktop). We intentionally suppress touch-initiated contextmenus
    // so long-press on mobile doesn't open the menu and interfere with dragging.
    clipEl._lastPointerType = null;
    clipEl.addEventListener('contextmenu', (e) => {
        // If the last interaction was touch, ignore contextmenu (prevents long-press menu on mobile)
        const lastType = clipEl._lastPointerType || e.pointerType || (e.sourceCapabilities && e.sourceCapabilities.firesTouchEvents ? 'touch' : null);
        if (lastType === 'touch') {
            e.preventDefault();
            return;
        }
        e.preventDefault();
        showContextMenu(clip, e.clientX, e.clientY);
    });
    
    // Resize/Trim on mousedown near edges
    clipEl.addEventListener('mousedown', (e) => {
        const rect = clipEl.getBoundingClientRect();
        const x = e.clientX - rect.left;
        const edgeThreshold = 10; // 10px from edge
        
        if (x <= edgeThreshold && arrangementState.editMode === 'trim') {
            // Left edge - trim start
            startClipResize(clip, 'left', e);
            e.stopPropagation();
        } else if (x >= rect.width - edgeThreshold) {
            // Right edge - stretch or trim end
            startClipResize(clip, 'right', e);
            e.stopPropagation();
        }
    });
    
    // Change cursor near edges
    clipEl.addEventListener('mousemove', (e) => {
        const rect = clipEl.getBoundingClientRect();
        const x = e.clientX - rect.left;
        const edgeThreshold = 10;
        
        if (x <= edgeThreshold && arrangementState.editMode === 'trim') {
            clipEl.style.cursor = 'w-resize';
        } else if (x >= rect.width - edgeThreshold) {
            clipEl.style.cursor = 'e-resize';
        } else {
            clipEl.style.cursor = 'default';
        }
    });

    // ---- Drag-to-move clip (click & drag) ----
    // We'll ignore drags when starting near the edges (reserved for resize)
    let isDraggingClip = false;
    let dragStartX = 0;
    let originalStartBar = 0;

    const beginDrag = (clientX) => {
        const rect = clipEl.getBoundingClientRect();
        const x = clientX - rect.left;
        const edgeThreshold = 10;
        // If initiating near an edge, treat as resize (don't start move)
        if (x <= edgeThreshold || x >= rect.width - edgeThreshold) return false;

        isDraggingClip = true;
        dragStartX = clientX;
        originalStartBar = clip.startBar;
        document.body.style.cursor = 'grabbing';
        // Bring clip to front while dragging
        clipEl.style.zIndex = 1000;
        return true;
    };

    const onDragMove = (clientX) => {
        if (!isDraggingClip) return;
        const deltaX = clientX - dragStartX;
        const barWidth = 100 * arrangementState.zoom;
        const deltaBars = deltaX / barWidth;
        let newStart = originalStartBar + deltaBars;
        // Prevent negative start
        newStart = Math.max(0, newStart);

        // Snap to nearest 1/16th step for cleaner placement
        const step = (barWidth / 4) / 4; // 1/16th in px
        const tracksScroll = document.getElementById('arrangement-tracks-scroll');
        const snappedPx = Math.round((newStart * barWidth) / step) * step;
        const snappedBars = snappedPx / barWidth;

        // Check collision with other clips on same track - avoid overlap
        const collision = arrangementState.clips.some(other => {
            if (other.id === clip.id) return false;
            if (other.trackIndex !== clip.trackIndex) return false;
            const otherStart = other.startBar;
            const otherEnd = other.startBar + other.length;
            const newEnd = snappedBars + clip.length;
            return (snappedBars < otherEnd && newEnd > otherStart);
        });

        if (!collision) {
            clip.startBar = snappedBars;
            // Move DOM element visually
            clipEl.style.left = (clip.startBar * barWidth) + 'px';
        }
    };

    const endDrag = () => {
        if (!isDraggingClip) return;
        isDraggingClip = false;
        document.body.style.cursor = 'default';
        clipEl.style.zIndex = '';
        saveArrangement(false);
        renderAllClips();
    };

    // Pointer events for robust dragging (mouse + touch + pen)
    // Use document-level listeners so dragging continues reliably even if the element moves visually.
    clipEl.style.touchAction = 'none'; // Disable default touch gestures while interacting with clips
    clipEl.addEventListener('pointerdown', (e) => {
        if (e.button !== 0 || arrangementState.resizingClip) return;

        const rect = clipEl.getBoundingClientRect();
        const xInEl = e.clientX - rect.left;
        const edgeThreshold = 10;
        if (xInEl <= edgeThreshold || xInEl >= rect.width - edgeThreshold) {
            return; // startResize will handle this
        }

        e.preventDefault();

        // Pointer capture to keep receiving pointer events
        try { clipEl.setPointerCapture(e.pointerId); } catch (err) { /* ignore */ }

        const pointerId = e.pointerId;
    const startX = e.clientX;
    const startY = e.clientY;
        let dragStarted = false;
        const dragThreshold = 6; // px
        originalStartBar = clip.startBar;
        const originalTrackIndex = clip.trackIndex;
        let currentTranslateY = 0;
    // Calculate grab offset in bars (arrangement coordinates) so it's stable when scrollLeft changes
    const barWidth = 100 * arrangementState.zoom;
    const tracksScroll = document.getElementById('arrangement-tracks-scroll');
    const startScrollLeft = tracksScroll ? tracksScroll.scrollLeft : arrangementState.scrollX;
    // Use the tracks scroll container as the stable reference for arrangement X coordinates
    const tracksRectForGrab = tracksScroll ? tracksScroll.getBoundingClientRect() : clipEl.parentElement.getBoundingClientRect();
    const startArrangementX = startX - tracksRectForGrab.left + startScrollLeft; // px in arrangement coords
    const grabOffsetBars = (startArrangementX / barWidth) - clip.startBar; // in bars

        // Long-press timer for touch to open context menu (only if no drag occurs)
        let longPressTimer = null;
        if (e.pointerType === 'touch') {
            longPressTimer = setTimeout(() => {
                // show context menu if user hasn't moved enough to start drag
                if (!dragStarted) {
                    showContextMenu(clip, startX, startY);
                }
            }, 500);
        }

        document.body.style.cursor = 'grabbing';
        clipEl.style.zIndex = 1000;

        const onDocPointerMove = (ev) => {
            if (ev.pointerId !== pointerId) return;
            // Prevent scrolling while dragging
            ev.preventDefault();

            const dx = ev.clientX - startX;
            const dy = ev.clientY - startY;

                if (!dragStarted) {
                        if (Math.abs(dx) > dragThreshold || Math.abs(dy) > dragThreshold) {
                            dragStarted = true;
                            // Mark global dragging state so auto-scroll doesn't re-render clips
                            arrangementState.draggingClipId = clip.id;
                            if (longPressTimer) { clearTimeout(longPressTimer); longPressTimer = null; }
                            // Start smooth RAF-driven auto-scroll and set pointer X/Y
                            arrangementState._autoScrollPointerX = ev.clientX;
                            arrangementState._autoScrollPointerY = ev.clientY;
                            startAutoScrollLoop();
                    } else {
                        return; // don't start drag until threshold passed
                    }
                }
            // Determine target lane under pointer first (so we can use it to compute lane rect)
            let targetLaneEl = null;
            try {
                const els = document.elementsFromPoint(ev.clientX, ev.clientY);
                for (const el of els) {
                    if (el && el.classList && el.classList.contains('track-lane')) { targetLaneEl = el; break; }
                }
            } catch (err) { /* ignore */ }

            // Horizontal: compute new start bar using pointer position relative to lane + grab offset (bars)
            const barWidth = 100 * arrangementState.zoom;
            const tracksScroll = document.getElementById('arrangement-tracks-scroll');
            const tracksRect = tracksScroll ? tracksScroll.getBoundingClientRect() : clipEl.parentElement.getBoundingClientRect();
            const scrollLeft = tracksScroll ? tracksScroll.scrollLeft : arrangementState.scrollX;
            // Compute pointer X in arrangement coordinates using the stable tracks container rect
            const xInArrangement = ev.clientX - tracksRect.left + scrollLeft;
            // Use grabOffsetBars (computed at pointerdown) so changes to scrollLeft don't offset the grabbed point
            let newStart = (xInArrangement / barWidth) - grabOffsetBars;
            newStart = Math.max(0, newStart);
            const stepPx = (barWidth / 4) / 4;
            const snappedPx = Math.round((newStart * barWidth) / stepPx) * stepPx;
            const snappedBars = snappedPx / barWidth;

            const targetTrackIndex = targetLaneEl ? parseInt(targetLaneEl.dataset.trackIndex) : originalTrackIndex;

            // Collision check on target track
            const collision = arrangementState.clips.some(other => {
                if (other.id === clip.id) return false;
                if (other.trackIndex !== targetTrackIndex) return false;
                const otherStart = other.startBar;
                const otherEnd = other.startBar + other.length;
                const newEnd = snappedBars + clip.length;
                return (snappedBars < otherEnd && newEnd > otherStart);
            });

            if (!collision) {
                // Update logical X position live
                clip.startBar = snappedBars;
                clipEl.style.left = (clip.startBar * barWidth) + 'px';
                // Visual vertical move using transform (no reparenting while dragging)
                currentTranslateY = dy;
                clipEl.style.transform = `translateY(${currentTranslateY}px)`;
                clipEl.dataset._targetTrack = targetTrackIndex;
                clipEl.style.opacity = '';

                // Ensure the dragged clip stays visible inside the tracks scroll viewport
                try {
                    const tracksScrollEl = document.getElementById('arrangement-tracks-scroll');
                    if (tracksScrollEl) {
                        const tracksRect = tracksScrollEl.getBoundingClientRect();
                        const clipRectVis = clipEl.getBoundingClientRect();
                        const edgeMargin = 20; // keep a small margin from the edges
                                        // Don't perform an immediate large jump here; rely on RAF-driven smooth auto-scroll
                                        // to keep the grid moving smoothly. We still keep this block in case of tiny
                                        // out-of-view corrections in future, but for now do nothing here.
                    }
                } catch (err) { /* ignore visibility adjust errors */ }
            } else {
                clipEl.style.opacity = '0.6';
            }
            // Update RAF auto-scroll pointer X/Y so the loop can scroll smoothly
            arrangementState._autoScrollPointerX = ev.clientX;
            arrangementState._autoScrollPointerY = ev.clientY;
        };

        const onDocPointerUp = (ev) => {
            if (ev.pointerId !== pointerId) return;
            if (longPressTimer) { clearTimeout(longPressTimer); longPressTimer = null; }

            // If drag started and we have a target track, finalize move
            const targetTrackIndex = clipEl.dataset._targetTrack ? parseInt(clipEl.dataset._targetTrack) : originalTrackIndex;
            if (dragStarted) {
                // Remove visual transform
                clipEl.style.transform = '';
                // If target track changed and no collision, commit it
                if (targetTrackIndex !== originalTrackIndex) {
                    // Final collision check before committing
                    const finalCollision = arrangementState.clips.some(other => {
                        if (other.id === clip.id) return false;
                        if (other.trackIndex !== targetTrackIndex) return false;
                        const otherStart = other.startBar;
                        const otherEnd = other.startBar + other.length;
                        const newEnd = clip.startBar + clip.length;
                        return (clip.startBar < otherEnd && newEnd > otherStart);
                    });
                    if (!finalCollision) {
                        clip.trackIndex = targetTrackIndex;
                    }
                }

                // Commit changes
                saveArrangement(false);
                renderAllClips();

                // If playing, reschedule clips from current time
                if (arrangementState.isPlaying && audioContext) {
                    if (arrangementState.scheduledSources) {
                        arrangementState.scheduledSources.forEach(src => { try { src.stop(); } catch (e) {} });
                        arrangementState.scheduledSources = [];
                    }
                    if (arrangementState.clipPlaybackData) {
                        arrangementState.clipPlaybackData.forEach(cd => { if (cd.lfoIntervals) cd.lfoIntervals.forEach(id => clearInterval(id)); if (cd.automationIntervals) cd.automationIntervals.forEach(id => clearInterval(id)); });
                        arrangementState.clipPlaybackData = [];
                    }
                    const elapsed = audioContext.currentTime - arrangementState.startTime;
                    arrangementState.currentTime = Math.max(0, elapsed);
                    scheduleClips();
                }
            } else {
                // No drag started -> pointerup without movement. For touch, this should not open the menu
                // (we used long-press to open menu). For mouse, allow click handlers elsewhere to run.
            }

            document.body.style.cursor = 'default';
            clipEl.style.zIndex = '';
            clipEl.style.opacity = '';
            try { clipEl.releasePointerCapture(pointerId); } catch (err) {}
            // Clear global dragging state
            arrangementState.draggingClipId = null;
            // Stop RAF-driven auto-scroll
            stopAutoScrollLoop();

            // Remove listeners
            document.removeEventListener('pointermove', onDocPointerMove);
            document.removeEventListener('pointerup', onDocPointerUp);
            document.removeEventListener('pointercancel', onDocPointerUp);
        };

        document.addEventListener('pointermove', onDocPointerMove, { passive: false });
        document.addEventListener('pointerup', onDocPointerUp);
        document.addEventListener('pointercancel', onDocPointerUp);
    });
    
    lane.appendChild(clipEl);
}

function startClipResize(clip, edge, startEvent) {
    arrangementState.resizingClip = {
        clip: clip,
        edge: edge,
        startX: startEvent.clientX,
        originalStart: clip.startBar,
        originalLength: clip.length,
        originalTrimStart: clip.trimStart || 0,
        originalTrimEnd: clip.trimEnd || 0
    };
    
    document.body.style.cursor = edge === 'left' ? 'w-resize' : 'e-resize';
    
    const handleMouseMove = (e) => {
        if (!arrangementState.resizingClip) return;
        
        const deltaX = e.clientX - arrangementState.resizingClip.startX;
        const barWidth = 100 * arrangementState.zoom;
        const deltaBars = deltaX / barWidth;
        
        const resizing = arrangementState.resizingClip;
        
        if (resizing.edge === 'left') {
            if (arrangementState.editMode === 'trim') {
                // Trim from start - increase trimStart, move visual position, reduce length
                resizing.clip.trimStart = Math.max(0, resizing.originalTrimStart + deltaBars);
                resizing.clip.startBar = Math.max(0, resizing.originalStart + deltaBars);
                resizing.clip.length = Math.max(0.25, resizing.originalLength - deltaBars);
                resizing.clip.stretchMode = false; // Mark as trim mode
                console.log(`âœ‚ï¸ Trim left: trimStart=${resizing.clip.trimStart.toFixed(2)}, length=${resizing.clip.length.toFixed(2)}`);
            } else {
                // Stretch from left - move start and adjust length
                const newStart = Math.max(0, resizing.originalStart + deltaBars);
                const startChange = newStart - resizing.originalStart;
                resizing.clip.startBar = newStart;
                resizing.clip.length = Math.max(0.25, resizing.originalLength - startChange);
                resizing.clip.stretchMode = true; // Mark as stretch mode
                console.log(`ðŸŽµ Stretch left: length=${resizing.clip.length.toFixed(2)}`);
            }
        } else if (resizing.edge === 'right') {
            if (arrangementState.editMode === 'stretch') {
                // Stretch - change length (plays whole sample faster/slower)
                resizing.clip.length = Math.max(0.25, resizing.originalLength + deltaBars);
                resizing.clip.stretchMode = true; // Mark as stretch mode
                console.log(`ðŸŽµ Stretch right: length=${resizing.clip.length.toFixed(2)}`);
            } else {
                // Trim from end - reduce visual length without stretching
                resizing.clip.length = Math.max(0.25, resizing.originalLength + deltaBars);
                resizing.clip.stretchMode = false; // Mark as trim mode
                console.log(`âœ‚ï¸ Trim right: length=${resizing.clip.length.toFixed(2)}`);
                // trimEnd is implicit - we just play less of the sample
            }
        }
        
        renderAllClips();
    };
    
    const handleMouseUp = () => {
        document.body.style.cursor = 'default';
        arrangementState.resizingClip = null;
        document.removeEventListener('mousemove', handleMouseMove);
        document.removeEventListener('mouseup', handleMouseUp);
        saveArrangement(false);
    };
    
    document.addEventListener('mousemove', handleMouseMove);
    document.addEventListener('mouseup', handleMouseUp);
}

function renderSampleClip(clipEl, clip) {
    // Create canvas for waveform
    const canvas = document.createElement('canvas');
    const clipWidth = clip.length * 100 * arrangementState.zoom - 4;
    canvas.width = clipWidth;
    canvas.height = 50;
    canvas.style.width = '100%';
    canvas.style.height = '100%';
    canvas.style.position = 'absolute';
    canvas.style.top = '0';
    canvas.style.left = '0';
    canvas.style.pointerEvents = 'none';
    
    // Add label
    const label = document.createElement('div');
    label.style.position = 'absolute';
    label.style.top = '5px';
    label.style.left = '5px';
    label.style.fontSize = '10px';
    label.style.fontWeight = 'bold';
    label.style.color = 'white';
    label.style.textShadow = '1px 1px 2px rgba(0,0,0,0.8)';
    label.style.zIndex = '1';
    
    // Display proper label based on sample type
    if (typeof clip.data === 'string') {
        if (clip.data.startsWith('custom_')) {
            label.textContent = `Custom ${clip.data.replace('custom_', '')}`;
        } else if (clip.data.startsWith('recording_')) {
            label.textContent = `Recording ${clip.data.replace('recording_', '')}`;
        } else {
            label.textContent = clip.data;
        }
    } else {
        label.textContent = `Sample ${clip.data}`;
    }
    
    clipEl.appendChild(canvas);
    clipEl.appendChild(label);
    
    // Draw waveform if sample is loaded
    if (sampleBuffers[clip.data]) {
        drawWaveform(canvas, sampleBuffers[clip.data], clip);
    } else {
        // Load sample and draw waveform (only for numbered samples)
        if (typeof clip.data === 'number') {
            loadSampleBuffer(clip.data).then(() => {
                if (sampleBuffers[clip.data]) {
                    drawWaveform(canvas, sampleBuffers[clip.data], clip);
                }
            });
        }
    }
}

function drawWaveform(canvas, audioBuffer, clip) {
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    
    // Clear canvas
    ctx.clearRect(0, 0, width, height);
    
    // Get audio data (use left channel)
    const fullData = audioBuffer.getChannelData(0);
    
    // Calculate which portion of the audio to display based on trim
    const trimStart = clip.trimStart || 0;
    // Use reference tempo (120 BPM) for consistent waveform display
    const referenceBarsPerSecond = 120 / 60 / 4; // 0.5 bars per second at 120 BPM
    const sampleRate = audioBuffer.sampleRate;
    
    // Calculate sample range to display (always at reference tempo for visual consistency)
    const trimStartSamples = Math.floor((trimStart / referenceBarsPerSecond) * sampleRate);
    const clipDurationSeconds = clip.length / referenceBarsPerSecond;
    const clipLengthSamples = Math.floor(clipDurationSeconds * sampleRate);
    
    // Extract the trimmed portion
    const endSample = Math.min(trimStartSamples + clipLengthSamples, fullData.length);
    const actualSamples = endSample - trimStartSamples;
    
    const step = Math.ceil(actualSamples / width);
    const amp = height / 2;
    
    // Draw waveform
    ctx.fillStyle = 'rgba(255, 255, 255, 0.3)';
    ctx.strokeStyle = 'rgba(255, 255, 255, 0.8)';
    ctx.lineWidth = 1;
    
    ctx.beginPath();
    ctx.moveTo(0, amp);
    
    for (let i = 0; i < width; i++) {
        let min = 1.0;
        let max = -1.0;
        
        for (let j = 0; j < step; j++) {
            const sampleIndex = trimStartSamples + (i * step) + j;
            if (sampleIndex >= endSample) break;
            const datum = fullData[sampleIndex];
            if (datum < min) min = datum;
            if (datum > max) max = datum;
        }
        
        const yMin = (1 + min) * amp;
        const yMax = (1 + max) * amp;
        
        // Draw vertical line for this sample
        ctx.fillRect(i, yMin, 1, yMax - yMin);
    }
    
    ctx.stroke();
}

function renderPatternClip(clipEl, clip) {
    // Create canvas for piano roll visualization
    const canvas = document.createElement('canvas');
    const clipWidth = clip.length * 100 * arrangementState.zoom - 4;
    canvas.width = clipWidth;
    canvas.height = 50;
    canvas.style.width = '100%';
    canvas.style.height = '100%';
    canvas.style.position = 'absolute';
    canvas.style.top = '0';
    canvas.style.left = '0';
    canvas.style.pointerEvents = 'none';
    
    // Add label
    const label = document.createElement('div');
    label.style.position = 'absolute';
    label.style.top = '5px';
    label.style.left = '5px';
    label.style.fontSize = '10px';
    label.style.fontWeight = 'bold';
    label.style.color = 'white';
    label.style.textShadow = '1px 1px 2px rgba(0,0,0,0.8)';
    label.style.zIndex = '1';
    label.textContent = clip.data;
    
    clipEl.appendChild(canvas);
    clipEl.appendChild(label);
    
    // Draw piano roll
    const pattern = arrangementState.patterns[clip.data];
    if (pattern && pattern.notes) {
        drawPianoRoll(canvas, pattern, clip);
    }
}

function drawPianoRoll(canvas, pattern, clip) {
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    
    // Clear canvas with black background
    ctx.fillStyle = '#0a0a0a';
    ctx.fillRect(0, 0, width, height);
    
    // Calculate pattern dimensions
    const patternLengthBars = pattern.length || 1;
    const patternSteps = patternLengthBars * 16; // 16 steps per bar
    const clipSteps = clip.length * 16;
    const stepWidth = width / clipSteps;
    
    // Draw subtle grid background
    ctx.strokeStyle = 'rgba(255, 255, 255, 0.05)';
    ctx.lineWidth = 1;
    
    // Vertical grid lines (steps) - every 4 steps (quarter note)
    for (let i = 0; i <= clipSteps; i += 4) {
        const x = i * stepWidth;
        ctx.beginPath();
        ctx.moveTo(x, 0);
        ctx.lineTo(x, height);
        ctx.stroke();
    }
    
    // Draw notes
    const noteNames = ['C5', 'B4', 'A4', 'G4', 'F4', 'E4', 'D4', 'C4', 'B3', 'A3', 'G3', 'F3'];
    const noteHeight = height / noteNames.length;
    
    // Calculate how many times to repeat the pattern
    const repetitions = Math.ceil(clip.length / patternLengthBars);
    
    // Draw each repetition
    for (let rep = 0; rep < repetitions; rep++) {
        const repOffsetSteps = rep * patternSteps;
        
        pattern.notes.forEach(note => {
            const noteIndex = noteNames.indexOf(note.note);
            if (noteIndex === -1) return;
            
            const globalStep = repOffsetSteps + note.step;
            
            // Only draw if within clip bounds
            if (globalStep >= clipSteps) return;
            
            const x = globalStep * stepWidth;
            const y = noteIndex * noteHeight;
            
            // Draw note - bright with subtle gradient
            const gradient = ctx.createLinearGradient(x, y, x, y + noteHeight);
            gradient.addColorStop(0, 'rgba(255, 255, 255, 0.9)');
            gradient.addColorStop(1, 'rgba(200, 200, 200, 0.9)');
            
            ctx.fillStyle = gradient;
            ctx.fillRect(x + 1, y + 1, stepWidth - 2, noteHeight - 2);
            
            // Add subtle border to notes
            ctx.strokeStyle = 'rgba(150, 150, 150, 0.6)';
            ctx.lineWidth = 0.5;
            ctx.strokeRect(x + 1, y + 1, stepWidth - 2, noteHeight - 2);
            
            // Draw note border
            ctx.strokeStyle = 'rgba(255, 255, 255, 0.9)';
            ctx.lineWidth = 1;
            ctx.strokeRect(x + 1, y + 1, stepWidth - 2, noteHeight - 2);
        });
    }
}

function renderAllClips() {
    // Clear all clips from DOM
    tracksContainer.querySelectorAll('.clip').forEach(el => el.remove());
    
    // Re-render all clips
    arrangementState.clips.forEach(clip => renderClip(clip));
}

function deleteClip(clipId) {
    arrangementState.clips = arrangementState.clips.filter(c => c.id !== clipId);
    const clipEl = tracksContainer.querySelector(`[data-clip-id="${clipId}"]`);
    if (clipEl) clipEl.remove();
    saveArrangement(false);
}

// ========== NEW SAMPLE ==========
function handleNewSample() {
    // Show options: Upload or Record
    const choice = confirm('Click OK to upload an audio file, or Cancel to record from microphone');
    
    if (choice) {
        // Upload file
        document.getElementById('arr-sample-file-input').click();
    } else {
        // Record audio
        startRecording();
    }
}

function handleSampleFileUpload(event) {
    const file = event.target.files[0];
    if (!file) return;
    
    // Initialize audio context if needed
    if (!audioContext) {
        initAudioContext();
    }
    
    if (!audioContext) {
        alert('Could not initialize audio. Please try again.');
        return;
    }
    
    const reader = new FileReader();
    reader.onload = async (e) => {
        try {
            const arrayBuffer = e.target.result;
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Find next available custom sample number (starting from 101)
            let customNum = 101;
            while (sampleBuffers[`custom_${customNum}`]) {
                customNum++;
            }
            
            const sampleKey = `custom_${customNum}`;
            const sampleName = file.name.replace(/\.[^/.]+$/, ''); // Remove extension
            
            // Add to sampleBuffers
            sampleBuffers[sampleKey] = audioBuffer;
            
            // Update dropdown
            updateSampleDropdown();
            
            // AUTO-SELECT the newly uploaded sample
            const sampleSelect = document.getElementById('arr-sample-select');
            sampleSelect.value = sampleKey;
            
            // Activate place mode for the sample
            arrangementState.placeMode = {type: 'sample', data: sampleKey};
            patternDropdown.value = ''; // Clear pattern dropdown
            
            console.log(`âœ… Sample "${sampleName}" uploaded and auto-selected as ${sampleKey} - Place mode activated`);
            alert(`Sample "${sampleName}" added successfully!`);
        } catch (error) {
            console.error('Error loading sample:', error);
            alert('Error loading audio file. Please try a different file.');
        }
    };
    reader.readAsArrayBuffer(file);
    
    // Reset input
    event.target.value = '';
}

let mediaRecorder = null;
let recordedChunks = [];

function startRecording() {
    // Initialize audio context if needed
    if (!audioContext) {
        initAudioContext();
    }
    
    if (!audioContext) {
        alert('Could not initialize audio. Please try again.');
        return;
    }
    
    navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
            recordedChunks = [];
            mediaRecorder = new MediaRecorder(stream);
            
            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    recordedChunks.push(e.data);
                }
            };
            
            mediaRecorder.onstop = async () => {
                const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                const arrayBuffer = await blob.arrayBuffer();
                
                try {
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    
                    // Find next available recording number
                    let recordNum = 1;
                    while (sampleBuffers[`recording_${recordNum}`]) {
                        recordNum++;
                    }
                    
                    const sampleKey = `recording_${recordNum}`;
                    
                    // Add to sampleBuffers
                    sampleBuffers[sampleKey] = audioBuffer;
                    
                    // Update dropdown
                    updateSampleDropdown();
                    
                    // AUTO-SELECT the newly recorded sample
                    const sampleSelect = document.getElementById('arr-sample-select');
                    sampleSelect.value = sampleKey;
                    
                    // Activate place mode for the recording
                    arrangementState.placeMode = {type: 'sample', data: sampleKey};
                    patternDropdown.value = ''; // Clear pattern dropdown
                    
                    console.log(`âœ… Recording ${recordNum} saved and auto-selected - Place mode activated`);
                    alert(`Recording ${recordNum} added successfully!`);
                } catch (error) {
                    console.error('Error processing recording:', error);
                    alert('Error processing recording. Please try again.');
                }
                
                // Stop all tracks
                stream.getTracks().forEach(track => track.stop());
            };
            
            mediaRecorder.start();
            console.log('ðŸŽ¤ Recording started...');
            
            // Show stop button with proper timing
            setTimeout(() => {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    const stopRecording = confirm('Recording in progress... Click OK to stop.');
                    if (stopRecording) {
                        mediaRecorder.stop();
                        console.log('â¹ï¸ Recording stopped');
                    }
                }
            }, 100);
        })
        .catch(error => {
            console.error('Error accessing microphone:', error);
            alert('Could not access microphone. Please check permissions.');
        });
}

function updateSampleDropdown() {
    const dropdown = document.getElementById('arr-sample-select');
    
    // Clear existing options except the first one
    dropdown.innerHTML = '<option value="">-- Select Sample --</option>';
    
    // Add numbered samples 1-100
    for (let i = 1; i <= 100; i++) {
        const option = document.createElement('option');
        option.value = i;
        option.textContent = `Sample ${i}`;
        dropdown.appendChild(option);
    }
    
    // Add custom uploaded samples
    Object.keys(sampleBuffers).forEach(key => {
        if (key.startsWith('custom_')) {
            const option = document.createElement('option');
            option.value = key;
            option.textContent = `Custom ${key.replace('custom_', '')}`;
            dropdown.appendChild(option);
        }
    });
    
    // Add recorded samples
    Object.keys(sampleBuffers).forEach(key => {
        if (key.startsWith('recording_')) {
            const option = document.createElement('option');
            option.value = key;
            option.textContent = `Recording ${key.replace('recording_', '')}`;
            dropdown.appendChild(option);
        }
    });
}

// ========== PATTERN EDITOR ==========
// Save pattern as MIDI file
async function savePatternAsMIDI(data) {
    // Save pattern as a new entry in arrangementState.patterns
    const patternName = `Pattern ${Object.keys(arrangementState.patterns).length + 1}`;
    arrangementState.patterns[patternName] = {
        notes: JSON.parse(JSON.stringify(data.notes)),
        soundSource: data.soundSource,
        soundDesign: data.soundDesign ? JSON.parse(JSON.stringify(data.soundDesign)) : undefined,
        gridWidth: data.gridWidth,
        length: Math.ceil(data.gridWidth / 16),
        effects: data.effects ? JSON.parse(JSON.stringify(data.effects)) : undefined
    };
    updatePatternDropdown();
    // Auto-select and activate place mode for pattern
    const patternDropdown = document.getElementById('arr-pattern-select');
    patternDropdown.value = patternName;
    arrangementState.placeMode = {type: 'pattern', data: patternName};
    sampleDropdown.value = '';
    alert(`Pattern saved as "${patternName}" and ready to place as a pattern clip.`);
}

// Dynamically load Tonejs/Midi library
function loadTonejsMidiLibrary() {
    return new Promise((resolve, reject) => {
        if (window.Tone && window.Tone.Midi) return resolve();
        const script = document.createElement('script');
        script.src = 'https://cdn.jsdelivr.net/npm/@tonejs/midi@2.0.27/build/Midi.min.js';
        script.onload = () => {
            window.Tone = window.Tone || {};
            window.Tone.Midi = window.Midi;
            resolve();
        };
        script.onerror = reject;
        document.head.appendChild(script);
    });
}

// Save pattern as audio sample file
async function savePatternAsSample(data) {
    // Render pattern to audio and save as a new sample in sampleBuffers
    const sampleRate = 44100;
    // Calculate timing based on current tempo
    const tempo = arrangementState.tempo || 120;
    const beatDuration = 60 / tempo;
    const stepDuration = beatDuration / 4; // 16th note
    // Find the end time of the last note
    let lastNoteEnd = 0;
    data.notes.forEach(note => {
        const noteEnd = (note.col * stepDuration) + ((note.length || 1) * stepDuration);
        if (noteEnd > lastNoteEnd) lastNoteEnd = noteEnd;
    });
    // If no notes, fallback to gridWidth
    const duration = lastNoteEnd > 0 ? lastNoteEnd : data.gridWidth * stepDuration;
    const offlineCtx = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(1, sampleRate * duration, sampleRate);
    const gain = offlineCtx.createGain();
    gain.connect(offlineCtx.destination);
    data.notes.forEach(note => {
        const time = note.col * stepDuration;
        const noteDuration = (note.length || 1) * stepDuration;
        const freq = rowToFrequency(note.row);
        const osc = offlineCtx.createOscillator();
        osc.type = 'sine';
        osc.frequency.value = freq;
        osc.connect(gain);
        osc.start(time);
        osc.stop(time + noteDuration);
    });
// Convert piano roll row to frequency (C0-B6)
function rowToFrequency(row) {
    const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
    const octave = Math.floor(row / 12);
    const noteIndex = row % 12;
    const noteFrequencies = {
        'C': 16.35, 'C#': 17.32, 'D': 18.35, 'D#': 19.45,
        'E': 20.60, 'F': 21.83, 'F#': 23.12, 'G': 24.50,
        'G#': 25.96, 'A': 27.50, 'A#': 29.14, 'B': 30.87
    };
    const noteName = noteNames[noteIndex];
    const baseFreq = noteFrequencies[noteName];
    return baseFreq * Math.pow(2, octave);
}
    const renderedBuffer = await offlineCtx.startRendering();
    // Find next available custom sample number
    let customNum = 101;
    while (sampleBuffers[`custom_${customNum}`]) {
        customNum++;
    }
    const sampleKey = `custom_${customNum}`;
    sampleBuffers[sampleKey] = renderedBuffer;
    updateSampleDropdown();
    // Calculate bar length for the sample using current tempo
    const barDuration = beatDuration * 4;
    const sampleBarLength = duration / barDuration;
    // Auto-select and activate place mode for sample, with default clip length
    const sampleSelect = document.getElementById('arr-sample-select');
    sampleSelect.value = sampleKey;
    arrangementState.placeMode = {type: 'sample', data: sampleKey, length: sampleBarLength};
    patternDropdown.value = '';
    alert(`Sample rendered and saved as "${sampleKey}". Ready to place as a sample clip.`);
}
// Update pattern dropdown UI
function updatePatternDropdown() {
    const patternDropdown = document.getElementById('arr-pattern-select');
    patternDropdown.innerHTML = '<option value="">-- Select Pattern --</option>';
    Object.keys(arrangementState.patterns).forEach(name => {
        const option = document.createElement('option');
        option.value = name;
        option.textContent = name;
        patternDropdown.appendChild(option);
    });
}

// Convert AudioBuffer to WAV Blob
function audioBufferToWavBlob(buffer) {
    // Basic WAV encoding for mono
    const numChannels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    const length = buffer.length * numChannels * 2 + 44;
    const arrayBuffer = new ArrayBuffer(length);
    const view = new DataView(arrayBuffer);
    // WAV header
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + buffer.length * numChannels * 2, true);
    writeString(view, 8, 'WAVE');
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * 2, true);
    view.setUint16(32, numChannels * 2, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, 'data');
    view.setUint32(40, buffer.length * numChannels * 2, true);
    // PCM samples
    let offset = 44;
    for (let i = 0; i < buffer.length; i++) {
        for (let ch = 0; ch < numChannels; ch++) {
            let sample = buffer.getChannelData(ch)[i];
            sample = Math.max(-1, Math.min(1, sample));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }
    }
    return new Blob([arrayBuffer], { type: 'audio/wav' });
}

function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}
function createNewPattern() {
    const popup = document.getElementById('pattern-popup');
    const nameInput = document.getElementById('pattern-name-input');
    
    const patternName = `Pattern ${Object.keys(arrangementState.patterns).length + 1}`;
    nameInput.value = patternName;
    currentSampleForPopup = patternName;
    
    // Always start with a fresh empty pattern, even if pianoRollData already exists
    pianoRollData[patternName] = {
        notes: [],
        soundSource: "synth",
        gridWidth: 16,
        gridHeight: 84, // 7 octaves * 12 notes
        scrollX: 0,
        scrollY: 0,
        soundDesign: {
            osc1: { wave: 'sine', detune: 0, level: 50 },
            osc2: { wave: 'sawtooth', detune: 0, level: 50 },
            filter: { type: 'lowpass', cutoff: 2000, resonance: 0 },
            envelope: { attack: 10, decay: 100, sustain: 70, release: 200 }
        }
    };
    
    initPianoRoll();
    initPianoRollVisualizer();
    initSoundDesignControls();
    popup.classList.add('active');
    
    // Save Pattern button
    document.getElementById('pattern-save-btn').onclick = () => {
        const name = nameInput.value.trim() || patternName;
        const data = pianoRollData[currentSampleForPopup];
        arrangementState.patterns[name] = {
            notes: JSON.parse(JSON.stringify(data.notes)),
            soundSource: data.soundSource,
            soundDesign: data.soundDesign ? JSON.parse(JSON.stringify(data.soundDesign)) : undefined,
            gridWidth: data.gridWidth,
            length: Math.ceil(data.gridWidth / 16),
            effects: (arrangementState.patterns[name] && arrangementState.patterns[name].effects)
                ? JSON.parse(JSON.stringify(arrangementState.patterns[name].effects))
                : (data.effects ? JSON.parse(JSON.stringify(data.effects)) : undefined)
        };
        popup.classList.remove('active');
        stopPianoRollPreview();
        const patternDropdown = document.getElementById('arr-pattern-select');
        const existingOption = patternDropdown.querySelector(`option[value="${name}"]`);
        if (!existingOption) {
            const option = document.createElement('option');
            option.value = name;
            option.textContent = name;
            patternDropdown.appendChild(option);
        }
        patternDropdown.value = name;
        arrangementState.placeMode = {type: 'pattern', data: name};
        sampleDropdown.value = '';
        console.log(`âœ… Pattern "${name}" saved and auto-selected with ${data.notes.length} notes - Place mode activated`);
        if (isEditingPattern && currentEditingPatternName) {
            arrangementState.clips.forEach(clip => {
                if (clip.type === 'pattern' && clip.data === currentEditingPatternName) {
                    clip.length = Math.ceil(data.gridWidth / 16);
                }
            });
            renderTimeline();
        }
        isEditingPattern = false;
        currentEditingPatternName = null;
        console.log(`âœ… Pattern "${name}" saved with ${data.notes.length} notes`);
    };

    // Save as MIDI button
    document.getElementById('pattern-save-midi-btn').onclick = () => {
        const data = pianoRollData[currentSampleForPopup];
        savePatternAsMIDI(data);
    };

    // Save as Sample button
    document.getElementById('pattern-save-sample-btn').onclick = () => {
        const data = pianoRollData[currentSampleForPopup];
        savePatternAsSample(data);
    };
    
    // Cancel button
    document.getElementById('pattern-cancel-btn').onclick = () => {
        popup.classList.remove('active');
        stopPianoRollPreview();
        
        // Clear editing state
        isEditingPattern = false;
        currentEditingPatternName = null;
        
        console.log('âŒ Pattern editing cancelled');
    };
}

function initPianoRoll() {
    if (!currentSampleForPopup) return;
    
    const pianoKeys = document.getElementById('piano-keys');
    const pianoRollGrid = document.getElementById('piano-roll-grid');
    const pianoRollBarNumbers = document.getElementById('piano-roll-bar-numbers');
    const pianoRollScrollable = document.getElementById('piano-roll-scrollable');
    const soundSourceSelect = document.getElementById('piano-roll-sound-source');
    const gridSizeDecreaseBtn = document.getElementById('piano-roll-grid-decrease');
    const gridSizeIncreaseBtn = document.getElementById('piano-roll-grid-increase');
    const gridSizeDisplay = document.getElementById('piano-roll-grid-display');
    const noteLengthDecreaseBtn = document.getElementById('piano-roll-note-decrease');
    const noteLengthIncreaseBtn = document.getElementById('piano-roll-note-increase');
    const noteLengthDisplay = document.getElementById('piano-roll-note-display');
    
    // Clear existing content
    pianoKeys.innerHTML = "";
    pianoRollBarNumbers.innerHTML = "";
    pianoRollGrid.innerHTML = "";
    
    const data = pianoRollData[currentSampleForPopup];
    
    // Set grid display
    gridSizeDisplay.textContent = data.gridWidth;
    
    // Create bar/beat labels
    const stepsPerBeat = 4;
    const totalBeats = Math.ceil(data.gridWidth / stepsPerBeat);
    for (let beatIdx = 0; beatIdx < totalBeats; beatIdx++) {
        const barNumber = Math.floor(beatIdx / 4) + 1;
        const beatNumber = (beatIdx % 4) + 1;
        const beatDiv = document.createElement("div");
        beatDiv.className = "piano-roll-bar-number";
        if (beatNumber === 1) beatDiv.classList.add("bar-start");
        
        const cellWidth = 20 * pianoRollZoomLevel;
        beatDiv.style.width = `${stepsPerBeat * cellWidth}px`;
        
        const span = document.createElement("span");
        span.textContent = `${barNumber}.${beatNumber}`;
        beatDiv.appendChild(span);
        pianoRollBarNumbers.appendChild(beatDiv);
    }
    
    // Create piano keys (7 octaves)
    const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
    const octaves = 7;
    for (let octave = octaves - 1; octave >= 0; octave--) {
        for (let i = 0; i < 12; i++) {
            const key = document.createElement("div");
            key.className = `piano-key ${noteNames[i].includes("#") ? "black" : "white"}`;
            key.textContent = noteNames[i] + octave;
            key.dataset.note = noteNames[i];
            key.dataset.octave = octave;
            
            key.addEventListener("click", function() {
                // Initialize audio context if needed
                if (!audioContext) {
                    initAudioContext();
                }
                
                if (audioContext && audioContext.state === "suspended") {
                    audioContext.resume().then(() => playPianoKey(noteNames[i], octave));
                } else if (audioContext) {
                    playPianoKey(noteNames[i], octave);
                }
            });
            
            pianoKeys.appendChild(key);
        }
    }
    
    // Set grid template columns
    pianoRollGrid.style.gridTemplateColumns = `repeat(${data.gridWidth}, ${20 * pianoRollZoomLevel}px)`;
    
    // Create grid cells
    const fragment = document.createDocumentFragment();
    
    // Pre-calculate note positions
    const noteMap = new Map();
    data.notes.forEach(note => {
        for (let c = note.col; c < note.col + (note.length || 1); c++) {
            const key = `${note.row}-${c}`;
            noteMap.set(key, { isStart: c === note.col, isPart: true });
        }
    });
    
    for (let row = data.gridHeight - 1; row >= 0; row--) {
        for (let col = 0; col < data.gridWidth; col++) {
            const cell = document.createElement("div");
            cell.className = "piano-roll-cell";
            
            // Mark beat boundaries (every 4 steps = 1 beat)
            if (col % 4 === 0) cell.classList.add("beat-start");
            
            // Mark bar boundaries (every 16 steps = 1 bar = 4 beats)
            if (col % 16 === 0) cell.classList.add("bar-start");
            if ((col + 1) % 16 === 0) cell.classList.add("bar-end");
            
            cell.dataset.row = row;
            cell.dataset.col = col;
            
            const noteInfo = noteMap.get(`${row}-${col}`);
            if (noteInfo) {
                cell.classList.add("active");
                if (!noteInfo.isStart) {
                    cell.classList.add("note-long");
                }
            }
            
            fragment.appendChild(cell);
        }
    }
    
    pianoRollGrid.appendChild(fragment);
    
    // Event delegation for cell clicks (only add once)
    if (!pianoRollGrid.hasAttribute('data-listener-added')) {
        pianoRollGrid.setAttribute('data-listener-added', 'true');
        pianoRollGrid.addEventListener("click", function(e) {
            if (e.target.classList.contains("piano-roll-cell")) {
                const row = parseInt(e.target.dataset.row);
                const col = parseInt(e.target.dataset.col);
                togglePianoRollCell(row, col);
            }
        });
    }
    
    // Sound source selector
    soundSourceSelect.value = data.soundSource;
    soundSourceSelect.addEventListener("change", function() {
        data.soundSource = this.value;
        
        // Show/hide sound design controls
        const sdPanel = document.getElementById('sound-design-controls');
        if (data.soundSource === 'synth') {
            sdPanel.style.display = 'block';
            // Draw ADSR canvas when panel becomes visible
            setTimeout(() => {
                drawADSRCanvas();
            }, 50);
        } else {
            sdPanel.style.display = 'none';
        }
    });
    
    // Trigger the change event to set initial visibility
    soundSourceSelect.dispatchEvent(new Event('change'));
    
    // Grid size controls
    gridSizeDecreaseBtn.onclick = () => {
        if (data.gridWidth > 4) {
            data.gridWidth /= 2;
            initPianoRoll(); // Recreate grid
        }
    };
    
    gridSizeIncreaseBtn.onclick = () => {
        if (data.gridWidth < 128) {
            data.gridWidth *= 2;
            initPianoRoll(); // Recreate grid
        }
    };
    
    // Note length controls
    const currentNoteLength = noteLengths.find(nl => nl.value === pianoRollNoteLength);
    if (currentNoteLength) {
        noteLengthDisplay.textContent = currentNoteLength.display;
    }
    
    noteLengthDecreaseBtn.onclick = () => {
        const currentIndex = noteLengths.findIndex(nl => nl.value === pianoRollNoteLength);
        if (currentIndex > 0) {
            pianoRollNoteLength = noteLengths[currentIndex - 1].value;
            noteLengthDisplay.textContent = noteLengths[currentIndex - 1].display;
        }
    };
    
    noteLengthIncreaseBtn.onclick = () => {
        const currentIndex = noteLengths.findIndex(nl => nl.value === pianoRollNoteLength);
        if (currentIndex < noteLengths.length - 1) {
            pianoRollNoteLength = noteLengths[currentIndex + 1].value;
            noteLengthDisplay.textContent = noteLengths[currentIndex + 1].display;
        }
    };
    
    // Preview/Stop/Clear controls
    document.getElementById('piano-roll-preview-btn').onclick = previewPianoRoll;
    document.getElementById('piano-roll-stop-btn').onclick = stopPianoRollPreview;
    document.getElementById('piano-roll-clear-btn').onclick = clearPianoRoll;
    
    // Sync horizontal scroll between bar numbers and grid
    // Remove old scroll listener if exists
    if (pianoRollScrollable._scrollSyncHandler) {
        pianoRollScrollable.removeEventListener('scroll', pianoRollScrollable._scrollSyncHandler);
    }
    
    // Calculate and apply scrollbar width offset
    const scrollbarWidth = pianoRollScrollable.offsetWidth - pianoRollScrollable.clientWidth;
    pianoRollBarNumbers.style.paddingRight = scrollbarWidth + 'px';
    
    // Create new scroll handler
    pianoRollScrollable._scrollSyncHandler = function() {
        pianoRollBarNumbers.scrollLeft = pianoRollScrollable.scrollLeft;
    };
    
    // Add scroll listener
    pianoRollScrollable.addEventListener('scroll', pianoRollScrollable._scrollSyncHandler);
}

function togglePianoRollCell(row, col) {
    const data = pianoRollData[currentSampleForPopup];
    if (!data) return;
    
    // Find existing note at this position
    const existingNoteIndex = data.notes.findIndex(n => n.row === row && n.col === col);
    
    if (existingNoteIndex >= 0) {
        // Remove note
        const note = data.notes[existingNoteIndex];
        data.notes.splice(existingNoteIndex, 1);
        
        // Remove visual cells
        for (let c = note.col; c < note.col + (note.length || 1); c++) {
            const cell = document.querySelector(`.piano-roll-cell[data-row="${row}"][data-col="${c}"]`);
            if (cell) {
                cell.classList.remove("active", "note-long");
            }
        }
    } else {
        // Add note with current length
        const length = pianoRollNoteLength || 1;
        data.notes.push({ row, col, length, velocity: 100 });
        
        // Add visual cells
        for (let c = col; c < col + length && c < data.gridWidth; c++) {
            const cell = document.querySelector(`.piano-roll-cell[data-row="${row}"][data-col="${c}"]`);
            if (cell) {
                cell.classList.add("active");
                if (c > col) {
                    cell.classList.add("note-long");
                }
            }
        }
    }
}

function clearPianoRoll() {
    const data = pianoRollData[currentSampleForPopup];
    if (!data) return;
    
    data.notes = [];
    
    // Clear all active cells
    document.querySelectorAll('.piano-roll-cell.active').forEach(cell => {
        cell.classList.remove('active', 'note-long');
    });
}

function previewPianoRoll() {
    if (isPreviewingPianoRoll) return;
    
    // Initialize audio context if needed
    if (!audioContext) {
        initAudioContext();
    }
    
    const data = pianoRollData[currentSampleForPopup];
    if (!data || data.notes.length === 0) {
        alert('No notes to preview!');
        return;
    }
    
    isPreviewingPianoRoll = true;
    startPianoRollVisualizerAnimation();
    
    const tempo = arrangementState.tempo;
    const beatDuration = 60 / tempo;
    const stepDuration = beatDuration / 4; // 16th note duration
    
    let currentStep = 0;
    const maxSteps = data.gridWidth;
    
    pianoRollLoopInterval = setInterval(() => {
        // Find notes at current step
        const notesAtStep = data.notes.filter(n => n.col === currentStep);
        
        notesAtStep.forEach(note => {
            const noteDuration = (note.length || 1) * stepDuration;
            playPianoNoteForPreview(note.row, audioContext.currentTime, noteDuration);
        });
        
        currentStep++;
        if (currentStep >= maxSteps) {
            currentStep = 0; // Loop
        }
    }, stepDuration * 1000);
}

function stopPianoRollPreview() {
    isPreviewingPianoRoll = false;
    
    if (pianoRollLoopInterval) {
        clearInterval(pianoRollLoopInterval);
        pianoRollLoopInterval = null;
    }
    
    // Stop all active notes
    Object.values(pianoRollPreviewActiveVoices).forEach(voice => {
        if (voice && voice.source) {
            try {
                voice.source.stop();
            } catch (e) {}
        }
    });
    pianoRollPreviewActiveVoices = {};
    
    stopPianoRollVisualizerAnimation();
}

function playPianoKey(noteName, octave) {
    // Initialize audio context if needed
    if (!audioContext) {
        initAudioContext();
    }
    if (!audioContext) return;
    
    const noteFrequencies = {
        'C': 16.35, 'C#': 17.32, 'D': 18.35, 'D#': 19.45,
        'E': 20.60, 'F': 21.83, 'F#': 23.12, 'G': 24.50,
        'G#': 25.96, 'A': 27.50, 'A#': 29.14, 'B': 30.87
    };
    
    const baseFreq = noteFrequencies[noteName];
    const frequency = baseFreq * Math.pow(2, octave);
    
    const data = pianoRollData[currentSampleForPopup];
    const soundSource = data ? data.soundSource : 'synth';
    
    if (soundSource === 'sample') {
        // Play sample at pitch
        playPianoSample(frequency, 0.3);
    } else {
        // Play synth note
        playSynthNote(frequency, 0.3);
    }
}

function playPianoNoteForPreview(row, time, duration) {
    if (!audioContext) return;
    
    const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
    const octave = Math.floor(row / 12);
    const noteIndex = row % 12;
    const noteName = noteNames[noteIndex];
    
    const noteFrequencies = {
        'C': 16.35, 'C#': 17.32, 'D': 18.35, 'D#': 19.45,
        'E': 20.60, 'F': 21.83, 'F#': 23.12, 'G': 24.50,
        'G#': 25.96, 'A': 27.50, 'A#': 29.14, 'B': 30.87
    };
    
    const baseFreq = noteFrequencies[noteName];
    const frequency = baseFreq * Math.pow(2, octave);
    
    const data = pianoRollData[currentSampleForPopup];
    const soundSource = data ? data.soundSource : 'synth';
    
    if (soundSource === 'sample') {
        playPianoSample(frequency, duration, time);
    } else {
        playSynthNote(frequency, duration, time);
    }
}

function playPianoSample(frequency, duration, startTime = null) {
    // Simple sample playback at pitch
    if (!audioContext) {
        console.error('âŒ AudioContext not initialized in playPianoSample');
        return;
    }
    if (startTime === null) {
        startTime = audioContext.currentTime;
    }
    
    // Patch: Use correct sample for pattern note
    let sampleNum = 1;
    if (effects && effects.sampleNum !== undefined) {
        sampleNum = effects.sampleNum;
    } else if (effects && effects.sample && typeof effects.sample === 'number') {
        sampleNum = effects.sample;
    }
    if (!sampleBuffers[sampleNum]) return;

    const source = audioContext.createBufferSource();
    source.buffer = sampleBuffers[sampleNum];
    
    const gainNode = audioContext.createGain();
    gainNode.gain.value = 0.5;
    
    // Pitch shift
    const basePitch = 440; // A4
    source.playbackRate.value = frequency / basePitch;
    
    source.connect(gainNode);
    
    if (pianoRollVisualizerAnalyzer) {
        gainNode.connect(pianoRollVisualizerAnalyzer);
    }
    
    gainNode.connect(audioContext.destination);
    
    source.start(startTime);
    source.stop(startTime + duration);
}

function playSynthNote(frequency, duration, startTime = null) {
    if (!audioContext) {
        console.error('âŒ AudioContext not initialized in playSynthNote');
        return;
    }
    if (startTime === null) {
        startTime = audioContext.currentTime;
    }
    
    const data = pianoRollData[currentSampleForPopup];
    const sd = data && data.soundDesign ? data.soundDesign : {
        osc1: { wave: 'sine', detune: 0, level: 50 },
        osc2: { wave: 'sawtooth', detune: 0, level: 50 },
        filter: { type: 'lowpass', cutoff: 2000, resonance: 0 },
        envelope: { attack: 10, decay: 100, sustain: 70, release: 200 }
    };
    
    // Create dual oscillators
    const osc1 = audioContext.createOscillator();
    const osc2 = audioContext.createOscillator();
    const osc1Gain = audioContext.createGain();
    const osc2Gain = audioContext.createGain();
    const filter = audioContext.createBiquadFilter();
    const env = audioContext.createGain();
    
    // Configure oscillators
    osc1.type = sd.osc1.wave;
    osc2.type = sd.osc2.wave;
    osc1.frequency.value = frequency;
    osc2.frequency.value = frequency;
    osc1.detune.value = sd.osc1.detune;
    osc2.detune.value = sd.osc2.detune;
    
    // Set oscillator levels
    osc1Gain.gain.value = (sd.osc1.level || 0) / 100 * 0.3; // Scale down for overall volume
    osc2Gain.gain.value = (sd.osc2.level || 0) / 100 * 0.3;
    
    // Configure filter
    filter.type = sd.filter.type;
    filter.frequency.value = Math.max(20, sd.filter.cutoff || 2000);
    filter.Q.value = (sd.filter.resonance || 0) / 10;
    
    // Connect audio graph
    osc1.connect(osc1Gain);
    osc2.connect(osc2Gain);
    osc1Gain.connect(filter);
    osc2Gain.connect(filter);
    filter.connect(env);
    
    if (pianoRollVisualizerAnalyzer) {
        env.connect(pianoRollVisualizerAnalyzer);
    }
    
    env.connect(audioContext.destination);
    
    // ADSR Envelope
    const now = Math.max(startTime, audioContext.currentTime);
    const attack = (sd.envelope.attack || 0) / 1000;
    const decay = (sd.envelope.decay || 0) / 1000;
    const sustain = (sd.envelope.sustain || 0) / 100;
    const release = (sd.envelope.release || 0) / 1000;
    
    env.gain.setValueAtTime(0, now);
    env.gain.linearRampToValueAtTime(1, now + attack);
    env.gain.linearRampToValueAtTime(sustain, now + attack + decay);
    env.gain.setValueAtTime(sustain, now + duration);
    env.gain.linearRampToValueAtTime(0.001, now + duration + release);
    
    // Apply Envelope â†’ Pitch Modulation (if enabled in sound design)
    if (sd.envelope.pitchMod && sd.envelope.pitchMod.enabled && sd.envelope.pitchMod.amount !== 0) {
        const pitchAmount = sd.envelope.pitchMod.amount; // semitones
        const maxDetune = pitchAmount * 100; // cents (100 cents = 1 semitone)
        
        console.log(`ðŸŽµ PIANO ROLL: Applying pitch mod: ${pitchAmount} semitones = ${maxDetune} cents`);
        
        // Pitch starts high and bends down during attack phase
        const osc1BaseDetune = sd.osc1.detune || 0;
        const osc2BaseDetune = sd.osc2.detune || 0;
        
        osc1.detune.setValueAtTime(osc1BaseDetune + maxDetune, now);
        osc1.detune.linearRampToValueAtTime(osc1BaseDetune, now + attack);
        
        osc2.detune.setValueAtTime(osc2BaseDetune + maxDetune, now);
        osc2.detune.linearRampToValueAtTime(osc2BaseDetune, now + attack);
    }
    
    // Start oscillators
    osc1.start(now);
    osc2.start(now);
    const stopAt = now + duration + release;
    osc1.stop(stopAt);
    osc2.stop(stopAt);
    
    // Store voice for potential manipulation
    const voiceId = Date.now() + Math.random();
    pianoRollPreviewActiveVoices[voiceId] = {
        osc1, osc2,
        g1: osc1Gain, g2: osc2Gain,
        filter, env,
        source: osc1 // For compatibility with cleanup
    };
    
    // Clean up after note ends
    setTimeout(() => {
        delete pianoRollPreviewActiveVoices[voiceId];
    }, stopAt - audioContext.currentTime + 100);
}

function initPianoRollVisualizer() {
    pianoRollVisualizer = document.getElementById('piano-roll-visualizer');
    if (!pianoRollVisualizer) return;
    
    pianoRollVisualizerCtx = pianoRollVisualizer.getContext('2d');
    
    if (!pianoRollVisualizerAnalyzer && audioContext) {
        pianoRollVisualizerAnalyzer = audioContext.createAnalyser();
        pianoRollVisualizerAnalyzer.fftSize = 256;
    }
}

function drawPianoRollVisualizer() {
    if (!pianoRollVisualizer || !pianoRollVisualizerCtx || !pianoRollVisualizerAnalyzer) return;
    
    const width = pianoRollVisualizer.width;
    const height = pianoRollVisualizer.height;
    
    pianoRollVisualizerCtx.fillStyle = "#0a0a0a";
    pianoRollVisualizerCtx.fillRect(0, 0, width, height);
    
    const bufferLength = pianoRollVisualizerAnalyzer.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    pianoRollVisualizerAnalyzer.getByteFrequencyData(dataArray);
    
    const barWidth = width / bufferLength;
    let x = 0;
    
    for (let i = 0; i < bufferLength; i++) {
        const barHeight = (dataArray[i] / 255) * height;
        
        const hue = (i / bufferLength) * 360;
        pianoRollVisualizerCtx.fillStyle = `hsl(${hue}, 100%, 50%)`;
        pianoRollVisualizerCtx.fillRect(x, height - barHeight, barWidth, barHeight);
        
        x += barWidth;
    }
}

function startPianoRollVisualizerAnimation() {
    if (pianoRollVisualizerAnimationId) return;
    
    function animate() {
        drawPianoRollVisualizer();
        pianoRollVisualizerAnimationId = requestAnimationFrame(animate);
    }
    
    animate();
}

function stopPianoRollVisualizerAnimation() {
    if (pianoRollVisualizerAnimationId) {
        cancelAnimationFrame(pianoRollVisualizerAnimationId);
        pianoRollVisualizerAnimationId = null;
    }
    
    // Clear visualizer
    if (pianoRollVisualizer && pianoRollVisualizerCtx) {
        pianoRollVisualizerCtx.fillStyle = "#0a0a0a";
        pianoRollVisualizerCtx.fillRect(0, 0, pianoRollVisualizer.width, pianoRollVisualizer.height);
    }
}

function initSoundDesignControls() {
    const data = pianoRollData[currentSampleForPopup];
    if (!data || !data.soundDesign) return;
    
    const sd = data.soundDesign;
    
    // Osc 1 controls
    const osc1Wave = document.getElementById('sd-osc1-wave');
    const osc1Level = document.getElementById('sd-osc1-level');
    const osc1LevelVal = document.getElementById('sd-osc1-level-val');
    const osc1Detune = document.getElementById('sd-osc1-detune');
    const osc1DetuneVal = document.getElementById('sd-osc1-detune-val');
    
    if (osc1Wave) {
        osc1Wave.value = sd.osc1.wave;
        osc1Wave.onchange = () => sd.osc1.wave = osc1Wave.value;
    }
    if (osc1Level) {
        osc1Level.value = sd.osc1.level;
        osc1LevelVal.textContent = sd.osc1.level + '%';
        osc1Level.oninput = () => {
            sd.osc1.level = +osc1Level.value;
            osc1LevelVal.textContent = sd.osc1.level + '%';
        };
    }
    if (osc1Detune) {
        osc1Detune.value = sd.osc1.detune;
        osc1DetuneVal.textContent = sd.osc1.detune + 'c';
        osc1Detune.oninput = () => {
            sd.osc1.detune = +osc1Detune.value;
            osc1DetuneVal.textContent = sd.osc1.detune + 'c';
        };
    }
    
    // Osc 2 controls
    const osc2Wave = document.getElementById('sd-osc2-wave');
    const osc2Level = document.getElementById('sd-osc2-level');
    const osc2LevelVal = document.getElementById('sd-osc2-level-val');
    const osc2Detune = document.getElementById('sd-osc2-detune');
    const osc2DetuneVal = document.getElementById('sd-osc2-detune-val');
    
    if (osc2Wave) {
        osc2Wave.value = sd.osc2.wave;
        osc2Wave.onchange = () => sd.osc2.wave = osc2Wave.value;
    }
    if (osc2Level) {
        osc2Level.value = sd.osc2.level;
        osc2LevelVal.textContent = sd.osc2.level + '%';
        osc2Level.oninput = () => {
            sd.osc2.level = +osc2Level.value;
            osc2LevelVal.textContent = sd.osc2.level + '%';
        };
    }
    if (osc2Detune) {
        osc2Detune.value = sd.osc2.detune;
        osc2DetuneVal.textContent = sd.osc2.detune + 'c';
        osc2Detune.oninput = () => {
            sd.osc2.detune = +osc2Detune.value;
            osc2DetuneVal.textContent = sd.osc2.detune + 'c';
        };
    }
    
    // Filter controls
    const filterType = document.getElementById('sd-filter-type');
    const filterCutoff = document.getElementById('sd-filter-cutoff');
    const filterCutoffVal = document.getElementById('sd-filter-cutoff-val');
    const filterRes = document.getElementById('sd-filter-res');
    const filterResVal = document.getElementById('sd-filter-res-val');
    
    if (filterType) {
        filterType.value = sd.filter.type;
        filterType.onchange = () => sd.filter.type = filterType.value;
    }
    if (filterCutoff) {
        filterCutoff.value = sd.filter.cutoff;
        filterCutoffVal.textContent = sd.filter.cutoff + ' Hz';
        filterCutoff.oninput = () => {
            sd.filter.cutoff = +filterCutoff.value;
            filterCutoffVal.textContent = sd.filter.cutoff + ' Hz';
        };
    }
    if (filterRes) {
        filterRes.value = sd.filter.resonance;
        filterResVal.textContent = sd.filter.resonance;
        filterRes.oninput = () => {
            sd.filter.resonance = +filterRes.value;
            filterResVal.textContent = sd.filter.resonance;
        };
    }
    
    // Envelope controls
    const envAttack = document.getElementById('sd-env-attack');
    const envAttackVal = document.getElementById('sd-env-attack-val');
    const envDecay = document.getElementById('sd-env-decay');
    const envDecayVal = document.getElementById('sd-env-decay-val');
    const envSustain = document.getElementById('sd-env-sustain');
    const envSustainVal = document.getElementById('sd-env-sustain-val');
    const envRelease = document.getElementById('sd-env-release');
    const envReleaseVal = document.getElementById('sd-env-release-val');
    
    if (envAttack) {
        envAttack.value = sd.envelope.attack;
        envAttackVal.textContent = sd.envelope.attack + ' ms';
        envAttack.oninput = () => {
            sd.envelope.attack = +envAttack.value;
            envAttackVal.textContent = sd.envelope.attack + ' ms';
        };
    }
    if (envDecay) {
        envDecay.value = sd.envelope.decay;
        envDecayVal.textContent = sd.envelope.decay + ' ms';
        envDecay.oninput = () => {
            sd.envelope.decay = +envDecay.value;
            envDecayVal.textContent = sd.envelope.decay + ' ms';
        };
    }
    if (envSustain) {
        envSustain.value = sd.envelope.sustain;
        envSustainVal.textContent = sd.envelope.sustain + '%';
        envSustain.oninput = () => {
            sd.envelope.sustain = +envSustain.value;
            envSustainVal.textContent = sd.envelope.sustain + '%';
        };
    }
    if (envRelease) {
        envRelease.value = sd.envelope.release;
        envReleaseVal.textContent = sd.envelope.release + ' ms';
        envRelease.oninput = () => {
            sd.envelope.release = +envRelease.value;
            envReleaseVal.textContent = sd.envelope.release + ' ms';
        };
    }
    
    // Initialize pitch modulation if not exists
    if (!sd.envelope.pitchMod) {
        sd.envelope.pitchMod = { enabled: false, amount: 0 };
    }
    
    // Pitch modulation controls
    const pitchEnable = document.getElementById('sd-env-pitch-enable');
    const pitchAmount = document.getElementById('sd-env-pitch-amount');
    const pitchAmountVal = document.getElementById('sd-env-pitch-amount-val');
    
    if (pitchEnable) {
        pitchEnable.checked = sd.envelope.pitchMod.enabled || false;
        pitchEnable.onchange = () => {
            sd.envelope.pitchMod.enabled = pitchEnable.checked;
            console.log('ðŸŽµ Pitch modulation:', pitchEnable.checked ? 'ENABLED' : 'DISABLED');
        };
    }
    if (pitchAmount) {
        pitchAmount.value = sd.envelope.pitchMod.amount || 0;
        pitchAmountVal.textContent = (sd.envelope.pitchMod.amount || 0) + '';
        pitchAmount.oninput = () => {
            sd.envelope.pitchMod.amount = +pitchAmount.value;
            pitchAmountVal.textContent = sd.envelope.pitchMod.amount + '';
        };
    }
    
    // Draw ADSR canvas initially
    setTimeout(() => {
        drawADSRCanvas();
        setupADSRCanvasInteraction();
    }, 100);
    
    // Redraw ADSR canvas when envelope sliders change
    ['sd-env-attack', 'sd-env-decay', 'sd-env-sustain', 'sd-env-release'].forEach(id => {
        const el = document.getElementById(id);
        if (el) {
            el.addEventListener('input', () => {
                drawADSRCanvas();
            });
        }
    });
}

// ========================================
// ADSR VISUAL CANVAS - Serum Style
// ========================================

function drawADSRCanvas() {
    const canvas = document.getElementById('adsr-canvas');
    if (!canvas) return;
    
    // Set canvas resolution to match display size
    const rect = canvas.getBoundingClientRect();
    
    if (rect.width === 0 || rect.height === 0) {
        console.log('âš ï¸ ADSR canvas not ready, retrying...');
        setTimeout(drawADSRCanvas, 50);
        return;
    }
    
    const dpr = window.devicePixelRatio || 1;
    canvas.width = rect.width * dpr;
    canvas.height = rect.height * dpr;
    
    const ctx = canvas.getContext('2d');
    ctx.scale(dpr, dpr);
    
    const width = rect.width;
    const height = rect.height;
    const s = pianoRollData[currentSampleForPopup]?.soundDesign;
    if (!s) return;
    
    const attack = s.envelope.attack || 0;
    const decay = s.envelope.decay || 0;
    const sustain = (s.envelope.sustain || 0) / 100;
    const release = s.envelope.release || 0;
    
    // Fixed time scale
    const FIXED_TOTAL_TIME = 10000; // 10 seconds
    const SUSTAIN_DISPLAY_TIME = 1000; // 1 second sustain display
    
    const padding = 40;
    const availableWidth = width - (padding * 2);
    
    // Calculate X positions
    const attackX = padding + (attack / FIXED_TOTAL_TIME) * availableWidth;
    const decayX = padding + ((attack + decay) / FIXED_TOTAL_TIME) * availableWidth;
    
    const sustainTime = s.envelope.sustainTime || 10;
    const minSustainDisplay = 50;
    const displaySustainTime = Math.max(sustainTime, minSustainDisplay);
    const sustainX = padding + ((attack + decay + displaySustainTime) / FIXED_TOTAL_TIME) * availableWidth;
    const releaseX = padding + ((attack + decay + displaySustainTime + release) / FIXED_TOTAL_TIME) * availableWidth;
    
    const maxReleaseX = width - padding;
    const clampedReleaseX = Math.min(releaseX, maxReleaseX);
    
    const marginTop = 40;
    const marginBottom = 40;
    const availableHeight = height - marginTop - marginBottom;
    
    const peakY = marginTop;
    const sustainY = marginTop + ((1 - sustain) * availableHeight);
    const endY = height - marginBottom;
    
    // Clear canvas
    ctx.clearRect(0, 0, width, height);
    
    // Grid lines
    ctx.strokeStyle = '#2a2a2a';
    ctx.lineWidth = 1;
    for (let i = 0; i <= 4; i++) {
        const y = marginTop + (i * availableHeight / 4);
        ctx.beginPath();
        ctx.moveTo(padding, y);
        ctx.lineTo(width - padding, y);
        ctx.stroke();
    }
    
    // Vertical grid lines (time markers every second)
    ctx.strokeStyle = '#222';
    for (let i = 1; i <= 10; i++) {
        const x = padding + (i * 1000 / FIXED_TOTAL_TIME) * availableWidth;
        ctx.beginPath();
        ctx.moveTo(x, marginTop);
        ctx.lineTo(x, height - marginBottom);
        ctx.stroke();
        
        // Time labels
        ctx.fillStyle = '#444';
        ctx.font = '9px Arial';
        ctx.textAlign = 'center';
        ctx.fillText(`${i}s`, x, height - marginBottom + 12);
    }
    
    // Draw envelope curve with gradient - PURPLE theme
    const gradient = ctx.createLinearGradient(0, peakY, 0, endY);
    gradient.addColorStop(0, '#B388FF');
    gradient.addColorStop(1, '#7C4DFF');
    
    ctx.strokeStyle = gradient;
    ctx.lineWidth = 4;
    ctx.lineCap = 'round';
    ctx.lineJoin = 'round';
    
    ctx.beginPath();
    ctx.moveTo(padding, endY);
    ctx.lineTo(attackX, peakY); // Attack
    ctx.lineTo(decayX, sustainY); // Decay
    ctx.lineTo(sustainX, sustainY); // Sustain
    ctx.lineTo(clampedReleaseX, endY); // Release
    ctx.stroke();
    
    // Draw glow effect
    ctx.shadowColor = '#B388FF';
    ctx.shadowBlur = 20;
    ctx.stroke();
    ctx.shadowBlur = 0;
    
    // Fill under curve
    ctx.fillStyle = 'rgba(179, 136, 255, 0.15)';
    ctx.beginPath();
    ctx.moveTo(padding, endY);
    ctx.lineTo(attackX, peakY);
    ctx.lineTo(decayX, sustainY);
    ctx.lineTo(sustainX, sustainY);
    ctx.lineTo(clampedReleaseX, endY);
    ctx.closePath();
    ctx.fill();
    
    // Draw control points with labels
    const points = [
        {x: attackX, y: peakY, label: 'A', color: '#FF4444'},
        {x: decayX, y: sustainY, label: 'D', color: '#FFAA44'},
        {x: sustainX, y: sustainY, label: 'S', color: '#44FF44'},
        {x: clampedReleaseX, y: endY, label: 'R', color: '#4444FF'}
    ];
    
    points.forEach(pt => {
        // Outer glow
        ctx.fillStyle = pt.color;
        ctx.shadowColor = pt.color;
        ctx.shadowBlur = 15;
        ctx.beginPath();
        ctx.arc(pt.x, pt.y, 8, 0, Math.PI * 2);
        ctx.fill();
        
        // Inner circle
        ctx.shadowBlur = 0;
        ctx.fillStyle = '#ffffff';
        ctx.beginPath();
        ctx.arc(pt.x, pt.y, 5, 0, Math.PI * 2);
        ctx.fill();
        
        // Label above point
        ctx.fillStyle = '#ffffff';
        ctx.font = 'bold 14px Arial';
        ctx.textAlign = 'center';
        ctx.fillText(pt.label, pt.x, pt.y - 18);
    });
    
    // Value labels
    ctx.fillStyle = '#aaa';
    ctx.font = '11px Arial';
    ctx.textAlign = 'center';
    
    if (attackX > padding + 20) {
        ctx.fillText(`${attack}ms`, attackX, height - 22);
    }
    if (decayX > attackX + 40) {
        ctx.fillText(`${decay}ms`, (attackX + decayX) / 2, height - 22);
    }
    ctx.fillText(`${Math.round(sustain * 100)}%`, (decayX + sustainX) / 2, sustainY - 8);
    if (sustainX > decayX + 20) {
        ctx.fillText(`${sustainTime}ms`, (decayX + sustainX) / 2, height - 22);
    }
    if (clampedReleaseX > sustainX + 40) {
        ctx.fillText(`${release}ms`, (sustainX + clampedReleaseX) / 2, height - 22);
    }
    
    // Stage labels at top
    ctx.fillStyle = '#666';
    ctx.font = 'bold 10px Arial';
    if (attackX > padding + 30) {
        ctx.fillText('ATTACK', (padding + attackX) / 2, 20);
    }
    if (decayX > attackX + 30) {
        ctx.fillText('DECAY', (attackX + decayX) / 2, 20);
    }
    if (sustainX > decayX + 30) {
        ctx.fillText('SUSTAIN', (decayX + sustainX) / 2, 20);
    }
    if (clampedReleaseX > sustainX + 30) {
        ctx.fillText('RELEASE', (sustainX + clampedReleaseX) / 2, 20);
    }
    
    // Warning if release is clamped
    if (releaseX > maxReleaseX) {
        ctx.fillStyle = '#FF4444';
        ctx.font = 'bold 11px Arial';
        ctx.textAlign = 'right';
        ctx.fillText('âš  Max', width - padding - 5, 20);
    }
}

// Interactive ADSR canvas
function setupADSRCanvasInteraction() {
    const canvas = document.getElementById('adsr-canvas');
    if (!canvas) return;
    
    // Remove old listeners if they exist (prevent duplicates)
    if (canvas._adsrMouseDownHandler) {
        canvas.removeEventListener('mousedown', canvas._adsrMouseDownHandler);
        canvas.removeEventListener('mousemove', canvas._adsrMouseMoveHandler);
        canvas.removeEventListener('mouseup', canvas._adsrMouseUpHandler);
        canvas.removeEventListener('mouseleave', canvas._adsrMouseLeaveHandler);
    }
    
    let dragging = null;
    let dragStartX = 0;
    let dragStartY = 0;
    let originalValue = 0;
    const FIXED_TOTAL_TIME = 10000;
    
    function getMousePos(e) {
        const rect = canvas.getBoundingClientRect();
        return {
            x: e.clientX - rect.left,
            y: e.clientY - rect.top
        };
    }
    
    const mouseDownHandler = (e) => {
        const pos = getMousePos(e);
        const s = pianoRollData[currentSampleForPopup]?.soundDesign;
        if (!s) return;
        
        const rect = canvas.getBoundingClientRect();
        const padding = 40;
        const marginTop = 40;
        const marginBottom = 40;
        const availableHeight = rect.height - marginTop - marginBottom;
        
        const attack = s.envelope.attack || 0;
        const decay = s.envelope.decay || 0;
        const sustain = (s.envelope.sustain || 0) / 100;
        const release = s.envelope.release || 0;
        const sustainTime = s.envelope.sustainTime || 10;
        
        const minSustainDisplay = 50;
        const displaySustainTime = Math.max(sustainTime, minSustainDisplay);
        
        const availableWidth = rect.width - (padding * 2);
        
        const attackX = padding + (attack / FIXED_TOTAL_TIME) * availableWidth;
        const decayX = padding + ((attack + decay) / FIXED_TOTAL_TIME) * availableWidth;
        const sustainX = padding + ((attack + decay + displaySustainTime) / FIXED_TOTAL_TIME) * availableWidth;
        const releaseX = Math.min(padding + ((attack + decay + displaySustainTime + release) / FIXED_TOTAL_TIME) * availableWidth, rect.width - padding);
        
        const peakY = marginTop;
        const sustainY = marginTop + ((1 - sustain) * availableHeight);
        const endY = rect.height - marginBottom;
        
        // Find closest point
        const points = [
            {name: 'attack', x: attackX, y: peakY, value: attack},
            {name: 'decay', x: decayX, y: sustainY, value: {decay: decay, sustain: sustain * 100}},
            {name: 'sustain-point', x: sustainX, y: sustainY, value: {sustainTime: sustainTime, sustain: sustain * 100}},
            {name: 'release', x: releaseX, y: endY, value: release}
        ];
        
        let closestPoint = null;
        let minDistance = 15;
        
        points.forEach(pt => {
            const distance = Math.sqrt(Math.pow(pos.x - pt.x, 2) + Math.pow(pos.y - pt.y, 2));
            if (distance < minDistance) {
                minDistance = distance;
                closestPoint = pt;
            }
        });
        
        if (closestPoint) {
            dragging = closestPoint.name;
            dragStartX = pos.x;
            dragStartY = pos.y;
            originalValue = closestPoint.value;
            e.preventDefault();
            canvas.style.cursor = 'grabbing';
        }
    };
    
    const mouseMoveHandler = (e) => {
        if (!dragging) return;
        
        const pos = getMousePos(e);
        const s = pianoRollData[currentSampleForPopup]?.soundDesign;
        if (!s) return;
        
        const rect = canvas.getBoundingClientRect();
        const padding = 40;
        const marginTop = 40;
        const marginBottom = 40;
        const availableHeight = rect.height - marginTop - marginBottom;
        const availableWidth = rect.width - (padding * 2);
        
        if (dragging === 'attack') {
            const deltaX = pos.x - dragStartX;
            const deltaTime = (deltaX / availableWidth) * FIXED_TOTAL_TIME;
            const newAttack = Math.max(0, Math.min(2000, originalValue + deltaTime));
            document.getElementById('sd-env-attack').value = newAttack;
            document.getElementById('sd-env-attack').dispatchEvent(new Event('input'));
            
        } else if (dragging === 'decay') {
            const deltaX = pos.x - dragStartX;
            const deltaY = pos.y - dragStartY;
            
            const deltaTime = (deltaX / availableWidth) * FIXED_TOTAL_TIME;
            const newDecay = Math.max(0, Math.min(4000, originalValue.decay + deltaTime));
            document.getElementById('sd-env-decay').value = newDecay;
            document.getElementById('sd-env-decay').dispatchEvent(new Event('input'));
            
            const deltaSustain = -(deltaY / availableHeight) * 100;
            const newSustain = Math.max(0, Math.min(100, originalValue.sustain + deltaSustain));
            document.getElementById('sd-env-sustain').value = newSustain;
            document.getElementById('sd-env-sustain').dispatchEvent(new Event('input'));
            
        } else if (dragging === 'sustain-point') {
            const deltaX = pos.x - dragStartX;
            const deltaTime = (deltaX / availableWidth) * FIXED_TOTAL_TIME;
            const newSustainTime = Math.max(0, Math.min(2000, originalValue.sustainTime + deltaTime));
            if (!s.envelope.sustainTime) s.envelope.sustainTime = 10;
            s.envelope.sustainTime = newSustainTime;
            drawADSRCanvas();
            
        } else if (dragging === 'release') {
            const deltaX = pos.x - dragStartX;
            const deltaTime = (deltaX / availableWidth) * FIXED_TOTAL_TIME;
            const newRelease = Math.max(0, Math.min(4000, originalValue + deltaTime));
            document.getElementById('sd-env-release').value = newRelease;
            document.getElementById('sd-env-release').dispatchEvent(new Event('input'));
        }
    };
    
    const mouseUpHandler = () => {
        dragging = null;
        canvas.style.cursor = 'crosshair';
    };
    
    const mouseLeaveHandler = () => {
        dragging = null;
        canvas.style.cursor = 'crosshair';
    };
    
    // Store handlers on canvas for cleanup
    canvas._adsrMouseDownHandler = mouseDownHandler;
    canvas._adsrMouseMoveHandler = mouseMoveHandler;
    canvas._adsrMouseUpHandler = mouseUpHandler;
    canvas._adsrMouseLeaveHandler = mouseLeaveHandler;
    
    // Attach event listeners
    canvas.addEventListener('mousedown', mouseDownHandler);
    canvas.addEventListener('mousemove', mouseMoveHandler);
    canvas.addEventListener('mouseup', mouseUpHandler);
    canvas.addEventListener('mouseleave', mouseLeaveHandler);
}

// ========== PLAYBACK ==========
function playArrangement() {
    if (arrangementState.isPlaying) {
        console.log('âš ï¸ Already playing');
        return;
    }
    
    console.log('â–¶ï¸ ============================================');
    console.log('â–¶ï¸ PLAY ARRANGEMENT CLICKED');
    console.log('â–¶ï¸ ============================================');
    console.log('Clips to play:', arrangementState.clips.length);
    console.log('Clips:', arrangementState.clips);
    
    if (arrangementState.clips.length === 0) {
        alert('No clips to play! Add some clips first by selecting a sample/pattern and clicking on a track.');
        return;
    }
    
    arrangementState.isPlaying = true;
    playheadLine.classList.add('playing');
    
    // Initialize audio context
    console.log('Initializing audio context...');
    initAudioContext();
    
    if (!audioContext) {
        console.error('âŒ Audio context failed to initialize');
        alert('Audio context failed to initialize');
        stopArrangement();
        return;
    }
    
    console.log('âœ… AudioContext ready, state:', audioContext.state);
    
    // Resume if suspended
    if (audioContext.state === 'suspended') {
        console.log('Resuming suspended context...');
        audioContext.resume().then(() => {
            console.log('âœ… AudioContext resumed, state:', audioContext.state);
            startPlayback();
        });
    } else {
        startPlayback();
    }
}

function startPlayback() {
    console.log('ðŸŽµ Starting playback...');
    console.log('   Current audio time:', audioContext.currentTime);
    
    // Start playback loop
    const startTime = audioContext.currentTime;
    arrangementState.startTime = startTime - arrangementState.currentTime;
    arrangementState.scheduledSources = []; // Track sources for cleanup
    arrangementState.lastUpdateTime = audioContext.currentTime; // Initialize for delta time calculation
    
    // Initialize bar position if not already set
    if (!arrangementState.currentBarPosition) {
        arrangementState.currentBarPosition = 0;
    }
    
    console.log('   Start time:', arrangementState.startTime);
    console.log('   Bar position:', arrangementState.currentBarPosition);
    console.log('   Scheduling clips...');
    
    animate();
    scheduleClips();
    
    console.log('âœ… Playback started!');
    console.log('â–¶ï¸ ============================================');
}

function stopArrangement() {
    if (!arrangementState.isPlaying) return;
    
    console.log('â¹ï¸ Stopping arrangement...');
    arrangementState.isPlaying = false;
    playheadLine.classList.remove('playing');
    
    if (arrangementState.animationId) {
        cancelAnimationFrame(arrangementState.animationId);
    }
    
    // Stop all scheduled sources
    if (arrangementState.scheduledSources) {
        arrangementState.scheduledSources.forEach(source => {
            try {
                source.stop();
            } catch (e) {
                // Already stopped
            }
        });
        arrangementState.scheduledSources = [];
    }
    
    // Clear active clip nodes
    arrangementState.activeClipNodes = {};
    
    // Clear all LFO and Automation intervals
    if (arrangementState.clipPlaybackData) {
        arrangementState.clipPlaybackData.forEach(clipData => {
            if (clipData.lfoIntervals) {
                clipData.lfoIntervals.forEach(id => clearInterval(id));
            }
            if (clipData.automationIntervals) {
                clipData.automationIntervals.forEach(id => clearInterval(id));
            }
        });
        arrangementState.clipPlaybackData = [];
    }
}

function animate() {
    if (!arrangementState.isPlaying) return;
    
    const currentTime = audioContext.currentTime;
    
    // Calculate delta time since last update
    if (!arrangementState.lastUpdateTime) {
        arrangementState.lastUpdateTime = currentTime;
    }
    const deltaTime = currentTime - arrangementState.lastUpdateTime;
    arrangementState.lastUpdateTime = currentTime;
    
    // Calculate how many bars have passed based on current tempo
    const beatDuration = 60 / arrangementState.tempo;
    const barDuration = beatDuration * 4;
    const barsPassed = deltaTime / barDuration;
    
    // Update bar position (tempo-independent counter)
    arrangementState.currentBarPosition += barsPassed;
    
    // Update elapsed time
    const elapsed = currentTime - arrangementState.startTime;
    arrangementState.currentTime = elapsed;
    
    // Update playhead position based on bar position (not time)
    const barWidth = 100 * arrangementState.zoom;
    const currentBar = Math.floor(arrangementState.currentBarPosition);
    const barPosition = arrangementState.currentBarPosition * barWidth;
    
    // Check if loop is enabled and we've reached the end
    if (arrangementState.loopEnabled && 
        arrangementState.loopStart !== null && 
        arrangementState.loopEnd !== null) {
        
        if (arrangementState.currentBarPosition >= arrangementState.loopEnd) {
            // Loop back to start
            console.log(`ðŸ” Looping back to bar ${arrangementState.loopStart}`);
            arrangementState.currentBarPosition = arrangementState.loopStart - 1;
            
            // Calculate new start time based on bar position
            arrangementState.startTime = currentTime - (arrangementState.currentBarPosition * barDuration);
            arrangementState.currentTime = arrangementState.currentBarPosition * barDuration;
            
            // Stop all current sources
            if (arrangementState.scheduledSources) {
                arrangementState.scheduledSources.forEach(source => {
                    try {
                        source.stop();
                    } catch (e) {
                        // Already stopped
                    }
                });
                arrangementState.scheduledSources = [];
            }
            
            // Clear all LFO and Automation intervals
            if (arrangementState.clipPlaybackData) {
                arrangementState.clipPlaybackData.forEach(clipData => {
                    if (clipData.lfoIntervals) {
                        clipData.lfoIntervals.forEach(id => clearInterval(id));
                    }
                    if (clipData.automationIntervals) {
                        clipData.automationIntervals.forEach(id => clearInterval(id));
                    }
                });
                arrangementState.clipPlaybackData = [];
            }
            
            // Reschedule clips from loop start
            scheduleClips();
            
            // Continue animation from loop start
            arrangementState.animationId = requestAnimationFrame(animate);
            return;
        }
    }
    
    playheadLine.style.left = barPosition + 'px';
    arrangementState.currentBar = currentBar + 1;
    document.getElementById('arr-current-bar').textContent = arrangementState.currentBar;
    
    // Auto-scroll timeline to follow playhead
    const timelineContainer = document.querySelector('.arrangement-timeline-container');
    if (timelineContainer) {
        const containerWidth = timelineContainer.clientWidth;
        const scrollLeft = timelineContainer.scrollLeft;
        const playheadPosition = barPosition;
        
        // Scroll when playhead is near the right edge (80% of visible area)
        const scrollThreshold = containerWidth * 0.8;
        const playheadRelativePosition = playheadPosition - scrollLeft;
        
        if (playheadRelativePosition > scrollThreshold) {
            // Smooth scroll to keep playhead centered
            const newScrollPosition = playheadPosition - (containerWidth / 2);
            timelineContainer.scrollTo({
                left: Math.max(0, newScrollPosition),
                behavior: 'smooth'
            });
        }
    }
    
    arrangementState.animationId = requestAnimationFrame(animate);
}

async function scheduleClips() {
    console.log('ðŸ“… Scheduling', arrangementState.clips.length, 'clips for playback...');
    console.log('   Current playback time:', arrangementState.currentTime.toFixed(2), 'seconds');
    
    if (!audioContext) {
        console.error('âŒ No audio context!');
        return;
    }
    
    const beatDuration = 60 / arrangementState.tempo;
    const barDuration = beatDuration * 4;
    const currentTimeInSong = arrangementState.currentTime; // Time elapsed in the song
    
    // Schedule all clips that should play from current position onwards OR are currently playing
    for (const clip of arrangementState.clips) {
        const clipStartTime = clip.startBar * barDuration;
        const clipEndTime = clipStartTime + (clip.length * barDuration);
        
        // Schedule if:
        // 1. Clip hasn't started yet (clipStartTime >= currentTimeInSong)
        // 2. Clip is currently playing (clipStartTime < currentTimeInSong < clipEndTime)
        if (clipStartTime >= currentTimeInSong || (clipStartTime < currentTimeInSong && currentTimeInSong < clipEndTime)) {
            // For clips already playing, calculate offset
            let scheduleAt, offset;
            
            if (clipStartTime >= currentTimeInSong) {
                // Clip hasn't started yet - schedule normally
                scheduleAt = arrangementState.startTime + clipStartTime;
                offset = 0;
            } else {
                // Clip is already playing - start immediately with offset
                scheduleAt = audioContext.currentTime;
                offset = currentTimeInSong - clipStartTime; // How far into the clip we are
            }
            
            if (clip.type === 'sample') {
                console.log(`  ðŸ“ Scheduling Sample ${clip.data} at bar ${clip.startBar + 1} (time: ${scheduleAt.toFixed(2)}s, offset: ${offset.toFixed(2)}s)`);
                await scheduleSampleClip(clip, scheduleAt, offset);
            } else if (clip.type === 'pattern') {
                console.log(`  ðŸ“ Scheduling Pattern "${clip.data}" at bar ${clip.startBar + 1} (time: ${scheduleAt.toFixed(2)}s, offset: ${offset.toFixed(2)}s)`);
                schedulePatternClip(clip, scheduleAt, offset);
            }
        } else {
            console.log(`  â­ï¸ Skipping clip at bar ${clip.startBar + 1} (already finished)`);
        }
    }
}

// LFO MODULATION HELPER - Calculate LFO value at a given time
function getLFOValue(lfo, time) {
    const phase = (time * lfo.rate * Math.PI * 2) % (Math.PI * 2);
    let modulation = 0;
    
    switch (lfo.waveform) {
        case 'sine':
            modulation = Math.sin(phase);
            break;
        case 'square':
            modulation = Math.sin(phase) > 0 ? 1 : -1;
            break;
        case 'triangle':
            const t = (phase / Math.PI) % 2;
            modulation = t < 1 ? 2 * t - 1 : 3 - 2 * t;
            break;
        case 'sawtooth':
            modulation = 2 * ((phase / Math.PI) % 1) - 1;
            break;
        default:
            modulation = 0;
    }
    
    return modulation * (lfo.depth / 100);
}

// AUTOMATION HELPER - Calculate automation value based on curve
function getAutomationValue(auto, clipStartTime, currentTime, clipDuration) {
    if (auto.target === 'none') return 0;
    
    // Use arrangementState.tempo for BPM/tempo reference (was using non-existent 'bpm')
    const elapsedBeats = (currentTime - clipStartTime) / (60 / arrangementState.tempo);
    const autoDurationBeats = auto.duration * 4; // duration is in bars (4 beats per bar)
    
    // Loop the automation if clip is longer than automation duration
    const t = (elapsedBeats % autoDurationBeats) / autoDurationBeats;
    
    let value;
    switch (auto.curve) {
        case 'linear':
            value = auto.start + (auto.end - auto.start) * t;
            break;
        case 'exponential':
            value = auto.start + (auto.end - auto.start) * (t * t);
            break;
        case 'logarithmic':
            value = auto.start + (auto.end - auto.start) * Math.sqrt(t);
            break;
        default:
            value = auto.start + (auto.end - auto.start) * t;
    }
    
    return value / 100; // Return as 0-1 range
}

// APPLY LFO MODULATION TO AUDIO PARAMS
function applyLFOsToSample(source, filterNode, gainNode, effects, startTime, clipData) {
    if (!effects.lfos || !Array.isArray(effects.lfos)) return;
    
    const updateInterval = 30; // Update every 30ms for smooth modulation
    
    // Store interval IDs so we can clear them later
    if (!clipData.lfoIntervals) {
        clipData.lfoIntervals = [];
    }
    
    // Store base values for modulation
    if (source && source.playbackRate) {
        clipData.basePitchRate = source.playbackRate.value;
    }
    if (gainNode && gainNode.gain) {
        clipData.baseGain = gainNode.gain.value;
    }
    
    effects.lfos.forEach((lfo, index) => {
        if (lfo.target === 'none' || lfo.depth === 0) return;
        
        const intervalId = setInterval(() => {
            const currentTime = audioContext.currentTime - startTime;
            if (currentTime < 0) return; // Not started yet
            
            const modulationValue = getLFOValue(lfo, audioContext.currentTime);
            
            try {
                switch (lfo.target) {
                    case 'pitch':
                        if (source && source.playbackRate) {
                            const basePitch = clipData.basePitchRate || 1;
                            const semitones = modulationValue * 12; // Â±1 octave
                            const pitchMultiplier = Math.pow(2, semitones / 12);
                            source.playbackRate.setValueAtTime(basePitch * pitchMultiplier, audioContext.currentTime);
                        }
                        break;
                        
                    case 'volume':
                        if (gainNode && gainNode.gain) {
                            const baseGain = clipData.baseGain || (effects.volume / 100);
                            const modulation = modulationValue * baseGain * 0.5; // Â±50% of base
                            gainNode.gain.setValueAtTime(Math.max(0, baseGain + modulation), audioContext.currentTime);
                        }
                        break;
                        
                    case 'filter':
                        if (filterNode && filterNode.frequency) {
                            const baseCutoff = effects.filter?.cutoff || 1000;
                            const modulation = modulationValue * baseCutoff; // Â±100% of base cutoff
                            const newCutoff = Math.max(20, Math.min(20000, baseCutoff + modulation));
                            filterNode.frequency.setValueAtTime(newCutoff, audioContext.currentTime);
                        }
                        break;
                        
                    case 'delay-time':
                        // Note: Would require delay node to be accessible
                        break;
                        
                    case 'pan':
                        // Would require StereoPannerNode
                        break;
                }
            } catch (e) {
                // Source may have stopped, clear the interval
                clearInterval(intervalId);
            }
        }, updateInterval);
        
        clipData.lfoIntervals.push(intervalId);
    });
}

// APPLY AUTOMATIONS TO SAMPLE
function applyAutomationsToSample(source, filterNode, gainNode, effects, startTime, clipDuration, clipData) {
    if (!effects.automations || !Array.isArray(effects.automations)) return;
    
    const updateInterval = 50; // Update every 50ms
    
    if (!clipData.automationIntervals) {
        clipData.automationIntervals = [];
    }
    
    effects.automations.forEach((auto, index) => {
        if (auto.target === 'none') return;
        
        const intervalId = setInterval(() => {
            const currentTime = audioContext.currentTime;
            const autoValue = getAutomationValue(auto, startTime, currentTime, clipDuration);
            
            try {
                switch (auto.target) {
                    case 'volume':
                        if (gainNode && gainNode.gain) {
                            gainNode.gain.setValueAtTime(autoValue, currentTime);
                        }
                        break;
                        
                    case 'pitch':
                        if (source && source.playbackRate) {
                            // Map 0-1 to 0.5x - 2x playback rate
                            const pitchRate = 0.5 + (autoValue * 1.5);
                            source.playbackRate.setValueAtTime(pitchRate, currentTime);
                        }
                        break;
                        
                    case 'filter':
                        if (filterNode && filterNode.frequency) {
                            // Map 0-1 to 20Hz - 20kHz
                            const cutoff = 20 + (autoValue * 19980);
                            filterNode.frequency.setValueAtTime(cutoff, currentTime);
                        }
                        break;
                        
                    case 'pan':
                        // Would require StereoPannerNode
                        break;
                }
            } catch (e) {
                clearInterval(intervalId);
            }
        }, updateInterval);
        
        clipData.automationIntervals.push(intervalId);
    });
}

async function scheduleSampleClip(clip, startTime, offset = 0) {
    // Try to get sample buffer from sampleBuffers
    let buffer = sampleBuffers[clip.data];
    
    // If not loaded, try to load it now (only for numbered samples)
    if (!buffer && typeof clip.data === 'number') {
        console.log(`  ðŸ“¦ Sample ${clip.data} not in cache, loading...`);
        await loadSampleBuffer(clip.data);
        buffer = sampleBuffers[clip.data];
    }
    
    if (!buffer) {
        console.warn(`âš ï¸ Sample ${clip.data} not available. Playing test tone instead.`);
        playTestToneAt(startTime, 440, 0.5);
        return;
    }
    
    // Get effects for this clip
    const effects = clip.effects || getDefaultEffects();
    
    // Create buffer source
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    
    // Apply speed (playback rate)
    let playbackRate = effects.speed || 1;
    
    // Apply pitch shift if specified (multiply with speed)
    if (effects.pitch && effects.pitch !== 0) {
        // Convert semitones to playback rate and multiply with speed
        playbackRate *= Math.pow(2, effects.pitch / 12);
    }
    
    // Apply tempo multiplier (120 BPM is the reference tempo = 1.0x speed)
    // This makes samples play faster/slower with BPM changes
    const tempoMultiplier = arrangementState.tempo / 120;
    playbackRate *= tempoMultiplier;
    
    source.playbackRate.value = playbackRate;
    
    // Create audio processing chain: source -> eq -> filter -> delay -> reverb -> gain -> destination
    let currentNode = source;
    
    // --- Patch: Use interactive EQ points for real-time EQ ---
    let eqNodes = {};
    if (effects.eq && Array.isArray(effects.eq)) {
        // Create up to 12 peaking filters from EQ points
        let lastNode = currentNode;
        effects.eq.forEach((point, idx) => {
            const eqNode = audioContext.createBiquadFilter();
            eqNode.type = point.type || (point.frequency <= 200 ? 'lowshelf' : point.frequency >= 8000 ? 'highshelf' : 'peaking');
            eqNode.frequency.value = point.frequency;
            eqNode.gain.value = point.gain;
            eqNode.Q.value = point.q || 1;
            lastNode.connect(eqNode);
            lastNode = eqNode;
            eqNodes[`band${idx}`] = eqNode;
        });
        currentNode = lastNode;
    } else {
        // Fallback to 5-band object
        const eqLow = audioContext.createBiquadFilter();
        eqLow.type = 'lowshelf';
        eqLow.frequency.value = 200;
        eqLow.gain.value = effects.eq ? (effects.eq.low || 0) : 0;
        eqNodes.low = eqLow;

        const eqLowMid = audioContext.createBiquadFilter();
        eqLowMid.type = 'peaking';
        eqLowMid.frequency.value = 500;
        eqLowMid.Q.value = 1;
        eqLowMid.gain.value = effects.eq ? (effects.eq.lowmid || 0) : 0;
        eqNodes.lowmid = eqLowMid;

        const eqMid = audioContext.createBiquadFilter();
        eqMid.type = 'peaking';
        eqMid.frequency.value = 1500;
        eqMid.Q.value = 1;
        eqMid.gain.value = effects.eq ? (effects.eq.mid || 0) : 0;
        eqNodes.mid = eqMid;

        const eqHighMid = audioContext.createBiquadFilter();
        eqHighMid.type = 'peaking';
        eqHighMid.frequency.value = 4000;
        eqHighMid.Q.value = 1;
        eqHighMid.gain.value = effects.eq ? (effects.eq.highmid || 0) : 0;
        eqNodes.highmid = eqHighMid;

        const eqHigh = audioContext.createBiquadFilter();
        eqHigh.type = 'highshelf';
        eqHigh.frequency.value = 8000;
        eqHigh.gain.value = effects.eq ? (effects.eq.high || 0) : 0;
        eqNodes.high = eqHigh;

        // Chain EQ filters
        currentNode.connect(eqLow);
        eqLow.connect(eqLowMid);
        eqLowMid.connect(eqMid);
        eqMid.connect(eqHighMid);
        eqHighMid.connect(eqHigh);
        currentNode = eqHigh;
    }
    
    // ALWAYS create filter node for real-time updates (start with type that passes through)
    const filterNode = audioContext.createBiquadFilter();
    filterNode.type = (effects.filter && effects.filter.type !== 'none') ? effects.filter.type : 'allpass';
    filterNode.frequency.value = effects.filter ? effects.filter.cutoff : 1000;
    filterNode.Q.value = effects.filter ? effects.filter.resonance : 0;
    currentNode.connect(filterNode);
    currentNode = filterNode;
    
    // Store delay nodes for real-time updates
    let delayNode = null;
    let delayGainNode = null;
    let feedbackGainNode = null;
    
    // Apply delay if specified
    if (effects.delay && effects.delay.time > 0) {
        delayNode = audioContext.createDelay();
        delayGainNode = audioContext.createGain();
        feedbackGainNode = audioContext.createGain();
        
        delayNode.delayTime.value = effects.delay.time / 1000; // Convert ms to seconds
        feedbackGainNode.gain.value = effects.delay.feedback / 100;
        
        currentNode.connect(delayNode);
        delayNode.connect(delayGainNode);
        delayNode.connect(feedbackGainNode);
        feedbackGainNode.connect(delayNode); // Feedback loop
        
        // Mix wet and dry
        currentNode.connect(delayGainNode); // Dry signal
        currentNode = delayGainNode;
    }
    
    // Apply reverb if specified (simplified convolver-based reverb)
    if (effects.reverb && effects.reverb.mix > 0) {
        // Create a simple impulse response for reverb
        const reverbTime = effects.reverb.decay;
        const sampleRate = audioContext.sampleRate;
        const length = sampleRate * reverbTime;
        const impulse = audioContext.createBuffer(2, length, sampleRate);
        const impulseL = impulse.getChannelData(0);
        const impulseR = impulse.getChannelData(1);
        
        for (let i = 0; i < length; i++) {
            const n = length - i;
            impulseL[i] = (Math.random() * 2 - 1) * Math.pow(n / length, effects.reverb.damping / 50);
            impulseR[i] = (Math.random() * 2 - 1) * Math.pow(n / length, effects.reverb.damping / 50);
        }
        
        const convolver = audioContext.createConvolver();
        convolver.buffer = impulse;
        
        const reverbGain = audioContext.createGain();
        reverbGain.gain.value = effects.reverb.mix / 100;
        
        const dryGain = audioContext.createGain();
        dryGain.gain.value = 1 - (effects.reverb.mix / 100);
        
        currentNode.connect(convolver);
        convolver.connect(reverbGain);
        currentNode.connect(dryGain);
        
        // Merge wet and dry
        const merger = audioContext.createGain();
        reverbGain.connect(merger);
        dryGain.connect(merger);
        currentNode = merger;
    }
    
    // Apply volume gain
    const gainNode = audioContext.createGain();
    gainNode.gain.value = (effects.volume / 100) * 0.7; // Scale to 0.7 max
    currentNode.connect(gainNode);
    
    // Connect to destination
    gainNode.connect(audioContext.destination);
    
    // Create clip data object for LFO/Automation tracking
    const clipPlaybackData = {
        source: source,
        gainNode: gainNode,
        filterNode: filterNode,
        lfoIntervals: [],
        automationIntervals: [],
        basePitchRate: source.playbackRate.value,
        baseGain: gainNode.gain.value
    };
    
    // Store audio nodes for real-time effect updates
    arrangementState.activeClipNodes[clip.id] = {
        gainNode: gainNode,
        filterNode: filterNode,
        eqNodes: eqNodes,
        delayNode: delayNode,
        delayGainNode: delayGainNode,
        feedbackGainNode: feedbackGainNode,
        source: source
    };
    
    // Clean up nodes when clip finishes
    source.onended = () => {
        delete arrangementState.activeClipNodes[clip.id];
    };
    
    // Apply LFO modulation
    applyLFOsToSample(source, clipPlaybackData.filterNode, gainNode, effects, startTime, clipPlaybackData);
    
    // Apply Automation
    applyAutomationsToSample(source, clipPlaybackData.filterNode, gainNode, effects, startTime, buffer.duration, clipPlaybackData);
    
    // Calculate trim offset and add the playback offset
    const trimStart = clip.trimStart || 0;
    const trimOffsetSeconds = trimStart; // Trim is in seconds, not bars
    
    // IMPORTANT: When tempo changes, both the playback rate AND the timeline change
    // At 240 BPM (2x tempo), the playhead moves through bars 2x faster, and audio plays 2x faster
    // If playhead is 4 seconds into the song:
    //   - At 120 BPM: That's 2 bars, skip 4 seconds of buffer (plays at 1x)
    //   - At 240 BPM: That's 4 bars, skip 8 seconds of buffer (plays at 2x)
    // So: bufferOffset = songOffset * tempoMultiplier
    const bufferOffset = offset * tempoMultiplier;
    const totalOffsetSeconds = trimOffsetSeconds + bufferOffset;
    
    console.log(`  ðŸ” Offset calc: songOffset=${offset.toFixed(2)}s, tempo=${arrangementState.tempo}BPM, tempoMult=${tempoMultiplier.toFixed(2)}x, bufferOffset=${bufferOffset.toFixed(2)}s, total=${totalOffsetSeconds.toFixed(2)}s`);
    
    // Schedule playback
    const scheduleTime = Math.max(startTime, audioContext.currentTime);
    
    // Use the stretchMode flag to determine playback method
    if (clip.stretchMode === true) {
        // Stretch mode - use playbackRate to time-stretch to fit bars
        const beatDuration = 60 / arrangementState.tempo;
        const barDuration = beatDuration * 4;
        const targetDuration = clip.length * barDuration; // How long it should play in seconds
        const audioPortionDuration = buffer.duration - trimStart; // How much audio we have
        source.playbackRate.value *= (audioPortionDuration / targetDuration); // Adjust rate to fit
        source.start(scheduleTime, totalOffsetSeconds);
        console.log(`  ðŸŽµ Stretched playback: rate=${source.playbackRate.value.toFixed(2)}, offset=${totalOffsetSeconds.toFixed(2)}s`);
    } else {
        // Trim mode (default) - play at original speed, but stop at clip end
        source.start(scheduleTime, totalOffsetSeconds);
        // Calculate when to stop playback (clip.length in bars)
        const beatDuration = 60 / arrangementState.tempo;
        const barDuration = beatDuration * 4;
        const clipPlayDuration = clip.length * barDuration;
        source.stop(scheduleTime + clipPlayDuration);
        console.log(`  âœ‚ï¸ Natural playback: bufferOffset=${totalOffsetSeconds.toFixed(2)}s, playbackRate=${source.playbackRate.value.toFixed(2)}x, songOffset=${offset.toFixed(2)}s, will stop after ${clipPlayDuration.toFixed(2)}s`);
    }
    
    // Track for cleanup
    if (!arrangementState.scheduledSources) {
        arrangementState.scheduledSources = [];
    }
    arrangementState.scheduledSources.push(source);
    
    // Store clip data for later cleanup
    if (!arrangementState.clipPlaybackData) {
        arrangementState.clipPlaybackData = [];
    }
    arrangementState.clipPlaybackData.push(clipPlaybackData);
    
    // Clear intervals when source ends
    source.onended = () => {
        clipPlaybackData.lfoIntervals.forEach(id => clearInterval(id));
        clipPlaybackData.automationIntervals.forEach(id => clearInterval(id));
    };
    
    console.log(`  âœ… Sample ${clip.data} scheduled for ${scheduleTime.toFixed(2)}s (${buffer.duration.toFixed(2)}s long)`);
}

async function scheduleClipWithOffset(clip, startTime, offsetSeconds) {
    // Similar to scheduleSampleClip but starts from a specific offset
    let buffer = sampleBuffers[clip.data];
    
    // Only try to load if it's a numbered sample
    if (!buffer && typeof clip.data === 'number') {
        await loadSampleBuffer(clip.data);
        buffer = sampleBuffers[clip.data];
    }
    
    if (!buffer) {
        console.warn(`âš ï¸ Sample ${clip.data} not available`);
        return;
    }
    
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    
    const gainNode = audioContext.createGain();
    gainNode.gain.value = 0.7;
    
    source.connect(gainNode);
    gainNode.connect(audioContext.destination);
    
    // Add the user offset to trimStart
    const trimStart = (clip.trimStart || 0);
    const barsPerSecond = arrangementState.tempo / 60 / 4;
    const totalOffsetSeconds = (trimStart / barsPerSecond) + offsetSeconds;
    
    const remainingDuration = (clip.length / barsPerSecond) - offsetSeconds;
    
    const scheduleTime = Math.max(startTime, audioContext.currentTime);
    
    const originalDurationBars = buffer.duration * barsPerSecond;
    
    // Use the stretchMode flag to determine playback method
    if (clip.stretchMode === true) {
        const audioPortionBars = originalDurationBars - trimStart;
        source.playbackRate.value = audioPortionBars / clip.length;
        source.start(scheduleTime, totalOffsetSeconds);
    } else {
        source.start(scheduleTime, totalOffsetSeconds, remainingDuration);
    }
    
    if (!arrangementState.scheduledSources) {
        arrangementState.scheduledSources = [];
    }
    arrangementState.scheduledSources.push(source);
    
    console.log(`  âœ… Sample ${clip.data} scheduled mid-playback at ${scheduleTime.toFixed(2)}s with offset ${offsetSeconds.toFixed(2)}s`);
}

function schedulePatternClip(clip, startTime, offset = 0) {
    // Force reload of pattern object from arrangementState before playback
    const pattern = arrangementState.patterns[clip.data];
    if (!pattern || !pattern.notes || pattern.notes.length === 0) {
        console.warn(`âš ï¸ Pattern "${clip.data}" has no notes`);
        return;
    }
    // Debug: Confirm reference and effects
    console.log('ðŸ”„ Reloaded pattern object for playback:', pattern);
    // For pattern clips, always use effects from the pattern object (canonical source)
    // Use array of EQ points if present, fallback to object for legacy
    let effects = pattern.effects || getDefaultEffects();
    // Patch: Pass interactive EQ array directly to playback functions for real-time EQ
    // (No conversion to 5-band object; playback functions now support array format)
    console.log(`ðŸŽµ Scheduling pattern clip ${clip.id} with effects from pattern object:`);
    console.log('   FULL EFFECTS OBJECT:', JSON.stringify(effects, null, 2));
    
    const beatDuration = 60 / arrangementState.tempo;
    const stepDuration = beatDuration / 4; // 16th notes
    const patternDurationBars = pattern.length || 1; // Pattern length in bars
    const patternDurationSteps = pattern.gridWidth || (patternDurationBars * 16); // Use gridWidth if available
    
    // Calculate how many times to repeat the pattern
    const clipDurationBars = clip.length;
    const repetitions = Math.ceil(clipDurationBars / patternDurationBars);
    
    // Schedule each repetition
    for (let rep = 0; rep < repetitions; rep++) {
        const repOffset = rep * patternDurationSteps * stepDuration;
        
        // Schedule each note in this repetition
        pattern.notes.forEach(note => {
            // New piano roll format: note has {row, col, length, velocity}
            const noteCol = note.col !== undefined ? note.col : note.step; // Support both formats
            const noteTime = startTime + repOffset + (noteCol * stepDuration) - offset;
            const noteDuration = (note.length || 1) * stepDuration;
            
            // Skip notes that would have already played due to offset
            if (noteTime < audioContext.currentTime) {
                return; // Skip this note
            }
            
            // Calculate frequency from row number
            let frequency;
            if (note.row !== undefined) {
                // New format: row number (0-83 for 7 octaves)
                frequency = rowToFrequency(note.row);
            } else if (note.note) {
                // Old format: note name like "C4"
                frequency = noteToFrequency(note.note);
            } else {
                frequency = 440; // Default
            }
            
            // Only play if within clip duration
            if (repOffset + (noteCol * stepDuration) < clipDurationBars * 4 * beatDuration) {
                // Check sound source
                if (pattern.soundSource === 'sample') {
                    // Play sample at pitch (with effects)
                    playPatternSampleScheduled(noteTime, frequency, noteDuration, effects);
                } else {
                    // Play synth note with sound design (with effects)
                    playPatternSynthScheduled(noteTime, frequency, noteDuration, pattern.soundDesign, effects);
                }
            }
        });
    }
    
    console.log(`  âœ… Pattern "${clip.data}" scheduled with ${pattern.notes.length} notes x ${repetitions} repetitions`);
}

function rowToFrequency(row) {
    // Calculate frequency from piano roll row (0-83 for C0-B6)
    const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
    const octave = Math.floor(row / 12);
    const noteIndex = row % 12;
    
    const noteFrequencies = {
        'C': 16.35, 'C#': 17.32, 'D': 18.35, 'D#': 19.45,
        'E': 20.60, 'F': 21.83, 'F#': 23.12, 'G': 24.50,
        'G#': 25.96, 'A': 27.50, 'A#': 29.14, 'B': 30.87
    };
    
    const noteName = noteNames[noteIndex];
    const baseFreq = noteFrequencies[noteName];
    return baseFreq * Math.pow(2, octave);
}

function getNoteFrequency(noteName, octave) {
    const noteFrequencies = {
        'C': 16.35, 'C#': 17.32, 'D': 18.35, 'D#': 19.45,
        'E': 20.60, 'F': 21.83, 'F#': 23.12, 'G': 24.50,
        'G#': 25.96, 'A': 27.50, 'A#': 29.14, 'B': 30.87
    };
    const baseFreq = noteFrequencies[noteName];
    return baseFreq * Math.pow(2, octave);
}

function playPatternSampleScheduled(time, frequency, duration, effects) {
    if (!audioContext) return;
    
    console.log(`ðŸŽµ playPatternSampleScheduled at time=${time.toFixed(3)}s, freq=${frequency.toFixed(2)}Hz`);
    console.log('   Effects:', effects);
    if (effects) {
        console.log('   - Speed:', effects.speed);
        console.log('   - LFOs:', effects.lfos);
        console.log('   - Automations:', effects.automations);
    }
    
    const sampleNum = 1; // Default kick sample
    if (!sampleBuffers[sampleNum]) return;
    
    const source = audioContext.createBufferSource();
    source.buffer = sampleBuffers[sampleNum];
    
    // Pitch shift
    const basePitch = 440; // A4
    let playbackRate = frequency / basePitch;
    
    // Apply speed effect
    if (effects && effects.speed) {
        playbackRate *= effects.speed;
    }
    
    // Apply pitch shift effect if specified
    if (effects && effects.pitch && effects.pitch !== 0) {
        playbackRate *= Math.pow(2, effects.pitch / 12);
    }
    
    // Apply LFO pitch modulation (calculate value at this specific time)
    if (effects && effects.lfos && Array.isArray(effects.lfos)) {
        effects.lfos.forEach(lfo => {
            if (lfo.enabled && lfo.target === 'pitch' && lfo.depth > 0) {
                const lfoValue = getLFOValue(lfo, time);
                const semitones = lfoValue * 12; // Â±1 octave range
                const pitchMultiplier = Math.pow(2, semitones / 12);
                playbackRate *= pitchMultiplier;
            }
        });
    }
    
    // Apply Automation pitch modulation (calculate value at this specific time)
    if (effects && effects.automations && Array.isArray(effects.automations)) {
        const clipDuration = 16; // TODO: Get actual clip duration
        const clipStartTime = 0; // TODO: Get actual clip start time
        effects.automations.forEach(auto => {
            if (auto.enabled && auto.target === 'pitch') {
                const autoValue = getAutomationValue(auto, clipStartTime, time, clipDuration);
                // autoValue is 0-1, convert to -1 to +1 range, then to semitones
                const normalizedValue = (autoValue - 0.5) * 2; // -1 to +1
                const semitones = normalizedValue * 12; // Â±1 octave
                const pitchMultiplier = Math.pow(2, semitones / 12);
                playbackRate *= pitchMultiplier;
            }
        });
    }
    
    // Apply tempo multiplier (120 BPM is the reference tempo = 1.0x speed)
    const tempoMultiplier = arrangementState.tempo / 120;
    playbackRate *= tempoMultiplier;
    
    source.playbackRate.value = playbackRate;
    
    // Create audio processing chain
    let currentNode = source;
    
    // Apply EQ if specified
    if (effects && effects.eq) {
        const eqLow = audioContext.createBiquadFilter();
        eqLow.type = 'lowshelf';
        eqLow.frequency.value = 200;
        eqLow.gain.value = effects.eq.low || 0;
        
        const eqLowMid = audioContext.createBiquadFilter();
        eqLowMid.type = 'peaking';
        eqLowMid.frequency.value = 500;
        eqLowMid.Q.value = 1;
        eqLowMid.gain.value = effects.eq.lowmid || 0;
        
        const eqMid = audioContext.createBiquadFilter();
        eqMid.type = 'peaking';
        eqMid.frequency.value = 1500;
        eqMid.Q.value = 1;
        eqMid.gain.value = effects.eq.mid || 0;
        
        const eqHighMid = audioContext.createBiquadFilter();
        eqHighMid.type = 'peaking';
        eqHighMid.frequency.value = 4000;
        eqHighMid.Q.value = 1;
        eqHighMid.gain.value = effects.eq.highmid || 0;
        
        const eqHigh = audioContext.createBiquadFilter();
        eqHigh.type = 'highshelf';
        eqHigh.frequency.value = 8000;
        eqHigh.gain.value = effects.eq.high || 0;
        
        // Chain EQ filters
        currentNode.connect(eqLow);
        eqLow.connect(eqLowMid);
        eqLowMid.connect(eqMid);
        eqMid.connect(eqHighMid);
        eqHighMid.connect(eqHigh);
        currentNode = eqHigh;
    }
    
    // Apply filter if specified
    if (effects && effects.filter && effects.filter.type !== 'none') {
        const filterNode = audioContext.createBiquadFilter();
        filterNode.type = effects.filter.type;
        filterNode.frequency.value = effects.filter.cutoff;
        filterNode.Q.value = effects.filter.resonance;
        currentNode.connect(filterNode);
        currentNode = filterNode;
    }
    
    // --- Patch: Use parallel wet/dry routing for delay and reverb (preview style) ---
    // Delay
    let delayNode = audioContext.createDelay(5.0);
    let feedbackNode = audioContext.createGain();
    let delayWetGain = audioContext.createGain();
    delayNode.delayTime.value = effects && effects.delay ? effects.delay.time / 1000 : 0;
    feedbackNode.gain.value = effects && effects.delay ? effects.delay.feedback / 100 : 0;
    delayWetGain.gain.value = (effects && effects.delay && effects.delay.time > 0) ? 0.5 : 0;
    currentNode.connect(delayNode);
    delayNode.connect(delayWetGain);
    delayNode.connect(feedbackNode);
    feedbackNode.connect(delayNode); // Feedback loop
    // Dry path
    let dryNode = audioContext.createGain();
    dryNode.gain.value = 1.0;
    currentNode.connect(dryNode);

    // Reverb
    let reverbWetGain = audioContext.createGain();
    reverbWetGain.gain.value = effects && effects.reverb ? effects.reverb.mix / 100 : 0;
    let reverbConvolver = null;
    if (effects && effects.reverb && effects.reverb.mix > 0 && effects.reverb.decay > 0) {
        const reverbTime = effects.reverb.decay;
        const sampleRate = audioContext.sampleRate;
        const length = Math.max(sampleRate * 0.1, sampleRate * reverbTime);
        const impulse = audioContext.createBuffer(2, length, sampleRate);
        const impulseL = impulse.getChannelData(0);
        const impulseR = impulse.getChannelData(1);
        for (let i = 0; i < length; i++) {
            const n = length - i;
            const decay = Math.pow(n / length, (effects.reverb.damping || 50) / 50);
            impulseL[i] = (Math.random() * 2 - 1) * decay;
            impulseR[i] = (Math.random() * 2 - 1) * decay;
        }
        reverbConvolver = audioContext.createConvolver();
        reverbConvolver.buffer = impulse;
        dryNode.connect(reverbConvolver);
        reverbConvolver.connect(reverbWetGain);
    }

    // Final gain node
    const finalGainNode = audioContext.createGain();
    const finalVolume = effects && effects.volume ? effects.volume / 100 : 1;
    finalGainNode.gain.value = 0.3 * finalVolume;
    // Connect wet/dry paths to final gain
    delayWetGain.connect(finalGainNode);
    dryNode.connect(finalGainNode);
    if (reverbWetGain) reverbWetGain.connect(finalGainNode);

    finalGainNode.connect(audioContext.destination);

    // Apply volume gain
    const gainNode = audioContext.createGain();
    const volume = effects && effects.volume ? effects.volume / 100 : 1;
    gainNode.gain.value = 0.3 * volume;
    currentNode.connect(gainNode);

    gainNode.connect(audioContext.destination);

    const scheduleTime = Math.max(time, audioContext.currentTime);
    source.start(scheduleTime);
    source.stop(scheduleTime + duration);
    
    if (!arrangementState.scheduledSources) {
        arrangementState.scheduledSources = [];
    }
    arrangementState.scheduledSources.push(source);
}

function playPatternSynthScheduled(time, frequency, duration, soundDesign, effects) {
    if (!audioContext) return;
    
    console.log(`ðŸŽ¹ playPatternSynthScheduled at time=${time.toFixed(3)}s, freq=${frequency.toFixed(2)}Hz`);
    console.log('   Effects:', effects);
    if (effects) {
        console.log('   - Speed:', effects.speed);
        console.log('   - LFOs:', effects.lfos);
        console.log('   - Automations:', effects.automations);
    }
    
    const sd = soundDesign || {
        osc1: { wave: 'sine', detune: 0, level: 50 },
        osc2: { wave: 'sawtooth', detune: 0, level: 50 },
        filter: { type: 'lowpass', cutoff: 2000, resonance: 0 },
        envelope: { attack: 10, decay: 100, sustain: 70, release: 200 }
    };
    
    // Create dual oscillators
    const osc1 = audioContext.createOscillator();
    const osc2 = audioContext.createOscillator();
    const osc1Gain = audioContext.createGain();
    const osc2Gain = audioContext.createGain();
    const filter = audioContext.createBiquadFilter();
    const env = audioContext.createGain();
    
    // Configure oscillators
    osc1.type = sd.osc1.wave;
    osc2.type = sd.osc2.wave;
    
    // Apply speed and pitch shift effects
    let finalFrequency = frequency;
    
    // Apply speed (affects frequency for synth)
    if (effects && effects.speed) {
        finalFrequency *= effects.speed;
    }
    
    // Apply pitch shift effect if specified
    if (effects && effects.pitch && effects.pitch !== 0) {
        finalFrequency *= Math.pow(2, effects.pitch / 12);
    }
    
    // Apply tempo multiplier (120 BPM is the reference tempo = 1.0x speed)
    const tempoMultiplier = arrangementState.tempo / 120;
    finalFrequency *= tempoMultiplier;
    
    osc1.frequency.value = finalFrequency;
    osc2.frequency.value = finalFrequency;
    
    // Calculate base detune from sound design
    let osc1BaseDetune = sd.osc1.detune || 0;
    let osc2BaseDetune = sd.osc2.detune || 0;
    
    // Apply LFO pitch modulation (calculate value at this specific time)
    if (effects && effects.lfos && Array.isArray(effects.lfos)) {
        effects.lfos.forEach(lfo => {
            if (lfo.enabled && lfo.target === 'pitch' && lfo.depth > 0) {
                const lfoValue = getLFOValue(lfo, time);
                const semitones = lfoValue * 12; // Â±1 octave range
                const additionalDetune = semitones * 100; // Convert to cents
                osc1BaseDetune += additionalDetune;
                osc2BaseDetune += additionalDetune;
            }
        });
    }
    
    // Apply Automation pitch modulation (calculate value at this specific time)
    if (effects && effects.automations && Array.isArray(effects.automations)) {
        const clipDuration = 16; // TODO: Get actual clip duration
        const clipStartTime = 0; // TODO: Get actual clip start time
        effects.automations.forEach(auto => {
            if (auto.enabled && auto.target === 'pitch') {
                const autoValue = getAutomationValue(auto, clipStartTime, time, clipDuration);
                // autoValue is 0-1, convert to -1 to +1 range, then to semitones
                const normalizedValue = (autoValue - 0.5) * 2; // -1 to +1
                const semitones = normalizedValue * 12; // Â±1 octave
                const additionalDetune = semitones * 100; // Convert to cents
                osc1BaseDetune += additionalDetune;
                osc2BaseDetune += additionalDetune;
            }
        });
    }
    
    osc1.detune.value = osc1BaseDetune;
    osc2.detune.value = osc2BaseDetune;
    
    // Apply volume effect
    const volumeMultiplier = effects && effects.volume ? effects.volume / 100 : 1;
    
    // Set oscillator levels
    // Match preview volume and log for debug
    const finalGain = 1.0 * volumeMultiplier; // Use 1.0 to match preview, or set to 0.3 for quieter
    osc1Gain.gain.value = (sd.osc1.level || 0) / 100 * finalGain;
    osc2Gain.gain.value = (sd.osc2.level || 0) / 100 * finalGain;
    console.log('ðŸ”Š Pattern arrangement playback volume:', finalGain, 'Effects:', effects);
    
    // Configure filter
    filter.type = sd.filter.type;
    filter.frequency.value = Math.max(20, sd.filter.cutoff || 2000);
    filter.Q.value = (sd.filter.resonance || 0) / 10;
    
    // Connect audio graph
    osc1.connect(osc1Gain);
    osc2.connect(osc2Gain);
    osc1Gain.connect(filter);
    osc2Gain.connect(filter);
    
    // Patch: Use interactive EQ points for real-time EQ
    let currentNode = filter;
    if (effects && effects.eq && Array.isArray(effects.eq)) {
        let lastNode = currentNode;
        effects.eq.forEach((point, idx) => {
            const eqNode = audioContext.createBiquadFilter();
            eqNode.type = point.type || (point.frequency <= 200 ? 'lowshelf' : point.frequency >= 8000 ? 'highshelf' : 'peaking');
            eqNode.frequency.value = point.frequency;
            eqNode.gain.value = point.gain;
            eqNode.Q.value = point.q || 1;
            lastNode.connect(eqNode);
            lastNode = eqNode;
        });
        currentNode = lastNode;
    } else {
        // Fallback to 5-band object
        const eqLow = audioContext.createBiquadFilter();
        eqLow.type = 'lowshelf';
        eqLow.frequency.value = 200;
        eqLow.gain.value = effects && effects.eq && typeof effects.eq.low === 'number' ? effects.eq.low : 0;
        const eqLowMid = audioContext.createBiquadFilter();
        eqLowMid.type = 'peaking';
        eqLowMid.frequency.value = 500;
        eqLowMid.Q.value = 1;
        eqLowMid.gain.value = effects && effects.eq && typeof effects.eq.lowmid === 'number' ? effects.eq.lowmid : 0;
        const eqMid = audioContext.createBiquadFilter();
        eqMid.type = 'peaking';
        eqMid.frequency.value = 1500;
        eqMid.Q.value = 1;
        eqMid.gain.value = effects && effects.eq && typeof effects.eq.mid === 'number' ? effects.eq.mid : 0;
        const eqHighMid = audioContext.createBiquadFilter();
        eqHighMid.type = 'peaking';
        eqHighMid.frequency.value = 4000;
        eqHighMid.Q.value = 1;
        eqHighMid.gain.value = effects && effects.eq && typeof effects.eq.highmid === 'number' ? effects.eq.highmid : 0;
        const eqHigh = audioContext.createBiquadFilter();
        eqHigh.type = 'highshelf';
        eqHigh.frequency.value = 8000;
        eqHigh.gain.value = effects && effects.eq && typeof effects.eq.high === 'number' ? effects.eq.high : 0;
        // Chain EQ filters
        currentNode.connect(eqLow);
        eqLow.connect(eqLowMid);
        eqLowMid.connect(eqMid);
        eqMid.connect(eqHighMid);
        eqHighMid.connect(eqHigh);
        currentNode = eqHigh;
    }
    
    // Apply additional filter effect if specified
    if (effects && effects.filter && effects.filter.type !== 'none') {
        const effectFilter = audioContext.createBiquadFilter();
        effectFilter.type = effects.filter.type;
        effectFilter.frequency.value = effects.filter.cutoff;
        effectFilter.Q.value = effects.filter.resonance;
        currentNode.connect(effectFilter);
        currentNode = effectFilter;
    }

    // --- Patch: Use parallel wet/dry routing for delay and reverb (preview style) ---
    // Delay
    let delayNode = audioContext.createDelay(5.0);
    let feedbackNode = audioContext.createGain();
    let delayWetGain = audioContext.createGain();
    delayNode.delayTime.value = effects && effects.delay ? effects.delay.time / 1000 : 0;
    feedbackNode.gain.value = effects && effects.delay ? effects.delay.feedback / 100 : 0;
    delayWetGain.gain.value = (effects && effects.delay && effects.delay.time > 0) ? 0.5 : 0;
    currentNode.connect(delayNode);
    delayNode.connect(delayWetGain);
    delayNode.connect(feedbackNode);
    feedbackNode.connect(delayNode); // Feedback loop
    // Dry path
    let dryNode = audioContext.createGain();
    dryNode.gain.value = 1.0;
    currentNode.connect(dryNode);

    // Reverb
    let reverbWetGain = audioContext.createGain();
    reverbWetGain.gain.value = effects && effects.reverb ? effects.reverb.mix / 100 : 0;
    let reverbConvolver = null;
    if (effects && effects.reverb && effects.reverb.mix > 0 && effects.reverb.decay > 0) {
        const reverbTime = effects.reverb.decay;
        const sampleRate = audioContext.sampleRate;
        const length = Math.max(sampleRate * 0.1, sampleRate * reverbTime);
        const impulse = audioContext.createBuffer(2, length, sampleRate);
        const impulseL = impulse.getChannelData(0);
        const impulseR = impulse.getChannelData(1);
        for (let i = 0; i < length; i++) {
            const n = length - i;
            const decay = Math.pow(n / length, (effects.reverb.damping || 50) / 50);
            impulseL[i] = (Math.random() * 2 - 1) * decay;
            impulseR[i] = (Math.random() * 2 - 1) * decay;
        }
        reverbConvolver = audioContext.createConvolver();
        reverbConvolver.buffer = impulse;
        dryNode.connect(reverbConvolver);
        reverbConvolver.connect(reverbWetGain);
    }

    // Final gain node
    const finalGainNode = audioContext.createGain();
    const finalVolume = effects && effects.volume ? effects.volume / 100 : 1;
    finalGainNode.gain.value = 0.3 * finalVolume;
    // Connect wet/dry paths to final gain
    delayWetGain.connect(finalGainNode);
    dryNode.connect(finalGainNode);
    if (reverbWetGain) reverbWetGain.connect(finalGainNode);

    finalGainNode.connect(env);
    env.connect(audioContext.destination);

    // Add master gain node after effects chain, apply volume from effects
    const masterGainNode = audioContext.createGain();
    const volume = effects && effects.volume ? effects.volume / 100 : 1;
    masterGainNode.gain.value = 0.3 * volume; // Consistent with preview chain
    currentNode.connect(masterGainNode);
    masterGainNode.connect(env);
    env.connect(audioContext.destination);

    // ADSR Envelope
    const now = Math.max(time, audioContext.currentTime);
    const attack = (sd.envelope.attack || 0) / 1000;
    const decay = (sd.envelope.decay || 0) / 1000;
    const sustain = (sd.envelope.sustain || 0) / 100;
    const release = (sd.envelope.release || 0) / 1000;

    env.gain.setValueAtTime(0, now);
    env.gain.linearRampToValueAtTime(1, now + attack);
    env.gain.linearRampToValueAtTime(sustain, now + attack + decay);
    env.gain.setValueAtTime(sustain, now + duration);
    env.gain.linearRampToValueAtTime(0.001, now + duration + release);
    
    // Apply Envelope â†’ Pitch Modulation (if enabled)
    if (sd.envelope.pitchMod && sd.envelope.pitchMod.enabled && sd.envelope.pitchMod.amount !== 0) {
        const pitchAmount = sd.envelope.pitchMod.amount; // semitones
        const maxDetune = pitchAmount * 100; // cents
        
        // Get the current detune values (which include LFO/Automation modulation)
        const currentOsc1Detune = osc1.detune.value;
        const currentOsc2Detune = osc2.detune.value;
        
        // Pitch starts at current + maxDetune and ramps down to current
        osc1.detune.setValueAtTime(currentOsc1Detune + maxDetune, now);
        osc1.detune.linearRampToValueAtTime(currentOsc1Detune, now + attack);
        osc1.detune.linearRampToValueAtTime(currentOsc1Detune, now + attack + decay);
        osc1.detune.setValueAtTime(currentOsc1Detune, now + duration);
        osc1.detune.linearRampToValueAtTime(currentOsc1Detune, now + duration + release);
        
        osc2.detune.setValueAtTime(currentOsc2Detune + maxDetune, now);
        osc2.detune.linearRampToValueAtTime(currentOsc2Detune, now + attack);
        osc2.detune.linearRampToValueAtTime(currentOsc2Detune, now + attack + decay);
        osc2.detune.setValueAtTime(currentOsc2Detune, now + duration);
        osc2.detune.linearRampToValueAtTime(currentOsc2Detune, now + duration + release);
    }
    
    // Start oscillators
    osc1.start(now);
    osc2.start(now);
    const stopAt = now + duration + release;
    osc1.stop(stopAt);
    osc2.stop(stopAt);
    
    if (!arrangementState.scheduledSources) {
        arrangementState.scheduledSources = [];
    }
    arrangementState.scheduledSources.push(osc1);
    arrangementState.scheduledSources.push(osc2);
}

function playTestToneAt(time, frequency, duration) {
    console.log(`ðŸŽµ Creating test tone: freq=${frequency}Hz, time=${time.toFixed(2)}s, duration=${duration}s`);
    console.log(`   Audio context time: ${audioContext.currentTime.toFixed(2)}s`);
    
    const osc = audioContext.createOscillator();
    const gain = audioContext.createGain();
    
    osc.frequency.value = frequency;
    osc.type = 'sine';
    
    const scheduleTime = Math.max(time, audioContext.currentTime);
    console.log(`   Scheduled time: ${scheduleTime.toFixed(2)}s`);
    
    gain.gain.setValueAtTime(0.3, scheduleTime);
    gain.gain.exponentialRampToValueAtTime(0.01, scheduleTime + duration);
    
    osc.connect(gain);
    gain.connect(audioContext.destination);
    
    try {
        osc.start(scheduleTime);
        osc.stop(scheduleTime + duration);
        console.log(`   âœ… Oscillator started and scheduled to stop`);
    } catch (e) {
        console.error(`   âŒ Failed to start oscillator:`, e);
    }
    
    if (!arrangementState.scheduledSources) {
        arrangementState.scheduledSources = [];
    }
    arrangementState.scheduledSources.push(osc);
}

function noteToFrequency(noteName) {
    const noteMap = {
        'C5': 523.25, 'B4': 493.88, 'A4': 440.00, 'G4': 392.00,
        'F4': 349.23, 'E4': 329.63, 'D4': 293.66, 'C4': 261.63,
        'B3': 246.94, 'A3': 220.00, 'G3': 196.00, 'F3': 174.61
    };
    return noteMap[noteName] || 440;
}

function initAudioContext() {
    if (!audioContext) {
        try {
            const AudioContext = window.AudioContext || window.webkitAudioContext;
            audioContext = new AudioContext();
            console.log('âœ… AudioContext initialized');
            console.log('   State:', audioContext.state);
            console.log('   Sample rate:', audioContext.sampleRate);
            console.log('   Current time:', audioContext.currentTime);
        } catch (e) {
            console.error('âŒ Failed to create AudioContext:', e);
            alert('Audio not supported in this browser');
            return;
        }
    }
    
    if (audioContext.state === 'suspended') {
        console.log('â¸ï¸ AudioContext suspended, resuming...');
        audioContext.resume().then(() => {
            console.log('âœ… AudioContext resumed, state:', audioContext.state);
        });
    }
}

function playSimpleBeep() {
    console.log('ðŸ”Š Playing simple beep test...');
    console.log('   AudioContext state:', audioContext.state);
    console.log('   Current time:', audioContext.currentTime);
    
    const osc = audioContext.createOscillator();
    const gain = audioContext.createGain();
    
    osc.frequency.value = 880; // A5
    osc.type = 'sine';
    
    gain.gain.value = 0.3;
    
    osc.connect(gain);
    gain.connect(audioContext.destination);
    
    const now = audioContext.currentTime;
    osc.start(now);
    osc.stop(now + 0.3);
    
    console.log('âœ… Beep scheduled to play now');
}

// ========== ZOOM ==========
function renderTrackGrid(canvas) {
    const ctx = canvas.getContext('2d');
    const zoom = arrangementState.zoom;
    
    // Calculate width needed for 50 bars at current zoom (adjustable)
    const numBars = 50;
    const barWidth = Math.round(100 * zoom);
    const totalWidth = numBars * barWidth;
    
    // Set CSS size for layout - leave 2px for border at bottom
    canvas.style.width = totalWidth + 'px';
    canvas.style.height = '58px';
    
    // Use higher resolution for crisp rendering
    const dpr = window.devicePixelRatio || 1;
    const minResolution = 5000;
    const canvasWidth = Math.max(totalWidth * dpr, minResolution);
    canvas.width = canvasWidth;
    canvas.height = 58 * dpr; // 58px instead of 60px to show border
    
    // Calculate scale factor
    const scale = canvasWidth / totalWidth;
    
    const width = canvasWidth;
    const height = 60 * dpr;
    
    const scaledBarWidth = barWidth * scale;
    const beatWidth = scaledBarWidth / 4;
    const stepWidth = beatWidth / 4;
    
    // Clear canvas
    ctx.fillStyle = '#1a1a2e';
    ctx.fillRect(0, 0, width, height);
    
    // Draw bar lines (thick purple)
    ctx.strokeStyle = '#533483';
    ctx.lineWidth = 2 * dpr;
    for (let bar = 0; bar < numBars; bar++) {
        const x = bar * scaledBarWidth;
        ctx.beginPath();
        ctx.moveTo(x, 0);
        ctx.lineTo(x, height);
        ctx.stroke();
    }
    
    // Draw beat lines (medium blue-gray) - only if zoomed in enough
    if (beatWidth > 5 * dpr) {
        ctx.strokeStyle = '#2d3561';
        ctx.lineWidth = 1 * dpr;
        for (let beat = 1; beat * beatWidth < width; beat++) {
            if (beat % 4 === 0) continue; // Skip bar lines
            const x = beat * beatWidth;
            ctx.beginPath();
            ctx.moveTo(x, 0);
            ctx.lineTo(x, height);
            ctx.stroke();
        }
    }
    
    // Draw step lines (subtle dark blue) - only if zoomed in enough
    if (stepWidth > 2 * dpr) {
        ctx.strokeStyle = '#1e2347';
        ctx.lineWidth = 0.5 * dpr;
        for (let step = 1; step * stepWidth < width; step++) {
            if (step % 4 === 0) continue; // Skip beat lines
            const x = step * stepWidth;
            ctx.beginPath();
            ctx.moveTo(x, 0);
            ctx.lineTo(x, height);
            ctx.stroke();
        }
    }
}

function updateTrackBackgrounds() {
    const zoom = arrangementState.zoom;
    const numBars = 50;
    const barWidth = Math.round(100 * zoom);
    const totalWidth = numBars * barWidth;
    
    // Update container width
    const container = document.getElementById('arrangement-tracks');
    container.style.minWidth = totalWidth + 'px';
    
    // Re-render all track grids with current zoom
    const lanes = tracksContainer.querySelectorAll('.track-lane');
    lanes.forEach(lane => {
        // Update lane width
        lane.style.minWidth = totalWidth + 'px';
        
        const canvas = lane.querySelector('.track-lane-canvas');
        if (canvas) {
            renderTrackGrid(canvas);
        }
    });
}

function adjustZoom(factor) {
    arrangementState.zoom = Math.max(0.25, Math.min(4, arrangementState.zoom * factor));
    updateZoomDisplay();
    updateTrackBackgrounds();
    renderTimeline();
    renderAllClips();
}

// ========== SAVE/LOAD ==========
function saveArrangement(showAlert = true) {
    // Create comprehensive save data including samples and patterns
    const data = {
        version: '1.0',
        tracks: arrangementState.tracks,
        clips: arrangementState.clips,
        patterns: arrangementState.patterns,
        tempo: arrangementState.tempo,
        zoom: arrangementState.zoom,
        customSamples: {} // Will store custom/recorded samples as base64
    };
    
    // Save custom samples and recordings to the file
    Object.keys(sampleBuffers).forEach(key => {
        if (key.startsWith('custom_') || key.startsWith('recording_')) {
            const buffer = sampleBuffers[key];
            // Convert AudioBuffer to serializable format
            const channels = [];
            for (let i = 0; i < buffer.numberOfChannels; i++) {
                const channelData = buffer.getChannelData(i);
                channels.push(Array.from(channelData));
            }
            data.customSamples[key] = {
                sampleRate: buffer.sampleRate,
                length: buffer.length,
                numberOfChannels: buffer.numberOfChannels,
                channels: channels
            };
        }
    });
    
    // Save to localStorage for auto-recovery (skip if data is too large)
    try {
        localStorage.setItem('arrangement-data', JSON.stringify(data));
        console.log('ðŸ’¾ Arrangement auto-saved to localStorage');
    } catch (e) {
        if (e.name === 'QuotaExceededError') {
            console.warn('âš ï¸ localStorage quota exceeded, skipping auto-save. Use Save button to download file.');
            // Clear the old data to free up space
            try {
                localStorage.removeItem('arrangement-data');
            } catch (clearError) {
                console.error('Failed to clear localStorage:', clearError);
            }
        } else {
            console.error('Error saving to localStorage:', e);
        }
    }
    
    // Only download file if explicitly requested (showAlert = true means user clicked Save button)
    if (showAlert) {
        const dataStr = JSON.stringify(data, null, 2);
        const blob = new Blob([dataStr], { type: 'application/json' });
        const url = URL.createObjectURL(blob);
        
        const a = document.createElement('a');
        a.href = url;
        a.download = `arrangement_${Date.now()}.json`;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        
        alert('Arrangement saved and downloaded!');
        console.log('ðŸ’¾ Arrangement saved to file with', Object.keys(data.customSamples).length, 'custom samples');
    }
}

function loadArrangement() {
    // Create file input
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = '.json';
    
    input.onchange = (e) => {
        const file = e.target.files[0];
        if (!file) return;
        
        const reader = new FileReader();
        reader.onload = (event) => {
            try {
                const parsed = JSON.parse(event.target.result);
                
                // Validate and load data
                arrangementState.tracks = parsed.tracks || [];
                arrangementState.clips = parsed.clips || [];
                arrangementState.patterns = parsed.patterns || {};
                arrangementState.tempo = parsed.tempo || 120;
                arrangementState.zoom = parsed.zoom || 1;
                
                // Restore custom samples
                if (parsed.customSamples) {
                    Object.keys(parsed.customSamples).forEach(key => {
                        const sampleData = parsed.customSamples[key];
                        // Reconstruct AudioBuffer from saved data
                        const audioBuffer = audioContext.createBuffer(
                            sampleData.numberOfChannels,
                            sampleData.length,
                            sampleData.sampleRate
                        );
                        
                        // Copy channel data back
                        for (let i = 0; i < sampleData.numberOfChannels; i++) {
                            const channelData = audioBuffer.getChannelData(i);
                            const savedData = sampleData.channels[i];
                            for (let j = 0; j < savedData.length; j++) {
                                channelData[j] = savedData[j];
                            }
                        }
                        
                        sampleBuffers[key] = audioBuffer;
                        console.log(`âœ… Restored custom sample: ${key}`);
                    });
                }
                
                // Rebuild UI
                rebuildTrackList();
                renderAllClips();
                renderTimeline();
                
                // Update sample dropdown to include loaded custom samples
                updateSampleDropdown();
                
                // Populate pattern dropdown
                patternDropdown.innerHTML = '<option value="">-- Select Pattern --</option>';
                Object.keys(arrangementState.patterns).forEach(name => {
                    const option = document.createElement('option');
                    option.value = name;
                    option.textContent = name;
                    patternDropdown.appendChild(option);
                });
                
                // Update tempo display if element exists
                const tempoDisplay = document.getElementById('arr-tempo-value');
                if (tempoDisplay) {
                    tempoDisplay.textContent = arrangementState.tempo;
                }
                
                // Update zoom display if element exists
                const zoomDisplay = document.getElementById('arr-zoom-display');
                if (zoomDisplay) {
                    zoomDisplay.textContent = Math.round(arrangementState.zoom * 100) + '%';
                }
                
                // Update BPM slider
                const bpmSlider = document.getElementById('arr-bpm-slider');
                if (bpmSlider) {
                    bpmSlider.value = arrangementState.tempo;
                }
                
                // Save to localStorage for auto-recovery
                localStorage.setItem('arrangement-data', JSON.stringify(parsed));
                
                const customCount = parsed.customSamples ? Object.keys(parsed.customSamples).length : 0;
                alert(`Arrangement loaded successfully!\n${customCount} custom samples restored.`);
                console.log('ðŸ“‚ Arrangement loaded from file with', customCount, 'custom samples');
            } catch (e) {
                console.error('âŒ Failed to load arrangement:', e);
                alert('Failed to load arrangement! Invalid file format.');
            }
        };
        
        reader.readAsText(file);
    };
    
    input.click();
}

function loadArrangementData() {
    const data = localStorage.getItem('arrangement-data');
    if (data) {
        try {
            const parsed = JSON.parse(data);
            arrangementState.tracks = parsed.tracks || [];
            arrangementState.clips = parsed.clips || [];
            arrangementState.patterns = parsed.patterns || {};
            arrangementState.tempo = parsed.tempo || 120;
            
            if (arrangementState.tracks.length > 0) {
                rebuildTrackList();
                renderAllClips();
            }
            
            // Populate pattern dropdown
            Object.keys(arrangementState.patterns).forEach(name => {
                const option = document.createElement('option');
                option.value = name;
                option.textContent = name;
                patternDropdown.appendChild(option);
            });
            
            console.log('ðŸ“‚ Auto-loaded arrangement data');
        } catch (e) {
            console.error('âŒ Failed to auto-load:', e);
        }
    }
}

function clearArrangement() {
    if (!confirm('Clear entire arrangement? This cannot be undone!')) return;
    
    arrangementState.tracks = [];
    arrangementState.clips = [];
    arrangementState.patterns = {};
    
    rebuildTrackList();
    
    // Create 10 empty tracks
    for (let i = 1; i <= 10; i++) {
        addTrack(`Track ${i}`);
    }
    
    patternDropdown.innerHTML = '<option value="">-- Select Pattern --</option>';
    
    saveArrangement(false);
    console.log('ðŸ—‘ï¸ Arrangement cleared and reset with 10 tracks');
}

// ========== LOAD SAMPLES FROM MAIN APP ==========
function loadSamplesFromMainApp() {
    // Load folder info
    loadSamplesFromStorage();
    
    console.log(`ðŸ“ Sample folder: ${currentSampleFolder}`);
    console.log('â„¹ï¸ Samples will be loaded on-demand when clips are placed');
    
    // Populate dropdown with sample numbers 1-100
    for (let i = 1; i <= 100; i++) {
        const option = document.createElement('option');
        option.value = i;
        option.textContent = `Sample ${i}`;
        sampleDropdown.appendChild(option);
    }
    
    console.log('âœ… Sample dropdown populated (1-100)');
}

async function loadSampleBuffer(sampleNum) {
    try {
        // Initialize audio context if needed
        if (!audioContext) {
            initAudioContext();
        }
        
        if (!audioContext) {
            console.error('Failed to initialize audio context');
            return;
        }
        
        // Build the file path like the main app does
        const filePath = `./${currentSampleFolder}/${sampleNum}.wav`;
        console.log(`ðŸ“¥ Loading sample ${sampleNum} from: ${filePath}`);
        
        try {
            const response = await fetch(filePath);
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
            }
            
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            sampleBuffers[sampleNum] = audioBuffer;
            console.log(`âœ… Sample ${sampleNum} loaded successfully (${audioBuffer.duration.toFixed(2)}s)`);
        } catch (fetchError) {
            console.warn(`âš ï¸ Could not load sample ${sampleNum}:`, fetchError.message);
            // Don't store anything - will play test tone instead
        }
    } catch (e) {
        console.error(`âŒ Failed to load sample ${sampleNum}:`, e);
    }
}

// ========== CONTEXT MENU & EFFECTS POPUP ==========
let contextMenu = null;
let effectsPopup = null;
let currentClipForContext = null;
let currentClipEffects = null;
let originalClipEffects = null;

function initContextMenu() {
    contextMenu = document.getElementById('clip-context-menu');
    effectsPopup = document.getElementById('arr-effects-popup');
    
    console.log('ðŸŽ›ï¸ Initializing context menu and effects popup');
    console.log('Context menu element:', contextMenu);
    console.log('Effects popup element:', effectsPopup);
    
    // Hide context menu when clicking elsewhere
    document.addEventListener('click', (e) => {
        if (contextMenu && !contextMenu.contains(e.target)) {
            contextMenu.style.display = 'none';
        }
    });
    
    // Context menu item click handlers
    contextMenu.addEventListener('click', (e) => {
        const item = e.target.closest('.context-menu-item');
        if (!item || !currentClipForContext) return;
        
        const action = item.dataset.action;
        
        if (action === 'delete') {
            deleteClipById(currentClipForContext.id);
            contextMenu.style.display = 'none';
            currentClipForContext = null;
        } else if (action === 'effects') {
            showEffectsPopup(currentClipForContext);
            contextMenu.style.display = 'none';
            // DO NOT clear currentClipForContext here - it's needed for Apply/Reset buttons
        } else if (action === 'edit') {
            console.log('ðŸ“ Edit action triggered for clip:', currentClipForContext);
            openPatternEditor(currentClipForContext);
            contextMenu.style.display = 'none';
            currentClipForContext = null;
        }
    });
    
    // Setup effects controls (sliders, etc)
    setupEffectsControls();
    
    // Setup LFO and Automation tabs
    setupLFOTabs();
    setupAutomationTabs();
    
    // Setup LFO and Automation listeners
    setupAllLFOListeners();
    setupAllAutomationListeners();
    
    console.log('âœ… Context menu and effects controls initialized');
}

function showContextMenu(clip, x, y) {
    currentClipForContext = clip;
    
    // Show/hide edit option for patterns only
    const editOption = contextMenu.querySelector('[data-action="edit"]');
    if (clip.type === 'pattern') {
        editOption.style.display = 'block';
    } else {
        editOption.style.display = 'none';
    }
    
    contextMenu.style.display = 'block';
    contextMenu.style.left = x + 'px';
    contextMenu.style.top = y + 'px';
    
    // Ensure menu doesn't go off-screen
    const rect = contextMenu.getBoundingClientRect();
    if (rect.right > window.innerWidth) {
        contextMenu.style.left = (x - rect.width) + 'px';
    }
    if (rect.bottom > window.innerHeight) {
        contextMenu.style.top = (y - rect.height) + 'px';
    }
}

function deleteClipById(clipId) {
    const index = arrangementState.clips.findIndex(c => c.id === clipId);
    if (index !== -1) {
        arrangementState.clips.splice(index, 1);
        renderAllClips();
        saveArrangement(false);
        console.log('ðŸ—‘ï¸ Clip deleted:', clipId);
    }
}

function showEffectsPopup(clip) {
    console.log('ðŸŽ¬ showEffectsPopup called for clip:', clip.id);
    
    // STOP MAIN ARRANGEMENT PLAYBACK if it's playing
    if (arrangementState.isPlaying) {
        console.log('â¸ï¸ Pausing main arrangement to preview effects');
        stopArrangement();
    }
    
    currentClipForContext = clip;
    
    // Set currentSampleForPopup for pattern clips (needed for sound design access)
    if (clip.type === 'pattern') {
        currentSampleForPopup = clip.data; // Pattern name
        console.log(`ðŸ“Œ Set currentSampleForPopup to: "${currentSampleForPopup}"`);
    }
    
    // Initialize effects if they don't exist
    if (!clip.effects) {
        clip.effects = getDefaultEffects();
    }
    
    // For pattern clips, load effects from the pattern object if available
    if (clip.type === 'pattern' && arrangementState.patterns[clip.data] && arrangementState.patterns[clip.data].effects) {
        originalClipEffects = JSON.parse(JSON.stringify(arrangementState.patterns[clip.data].effects));
        currentClipEffects = JSON.parse(JSON.stringify(arrangementState.patterns[clip.data].effects));
    } else {
        originalClipEffects = JSON.parse(JSON.stringify(clip.effects));
        currentClipEffects = JSON.parse(JSON.stringify(clip.effects));
    }

    // Ensure EQ is in array format for interactive editing
    if (currentClipEffects.eq && !Array.isArray(currentClipEffects.eq)) {
        // Convert from object format to array format
        const eqObj = currentClipEffects.eq;
        currentClipEffects.eq = [];
        // Convert each band to a point
        if (eqObj.low !== undefined && eqObj.low !== 0) {
            currentClipEffects.eq.push({ frequency: 200, gain: eqObj.low, type: 'lowshelf', q: 1 });
        }
        if (eqObj.lowmid !== undefined && eqObj.lowmid !== 0) {
            currentClipEffects.eq.push({ frequency: 500, gain: eqObj.lowmid, type: 'peaking', q: 1 });
        }
        if (eqObj.mid !== undefined && eqObj.mid !== 0) {
            currentClipEffects.eq.push({ frequency: 1500, gain: eqObj.mid, type: 'peaking', q: 1 });
        }
        if (eqObj.highmid !== undefined && eqObj.highmid !== 0) {
            currentClipEffects.eq.push({ frequency: 4000, gain: eqObj.highmid, type: 'peaking', q: 1 });
        }
        if (eqObj.high !== undefined && eqObj.high !== 0) {
            currentClipEffects.eq.push({ frequency: 8000, gain: eqObj.high, type: 'highshelf', q: 1 });
        }
        // If no points were added (all zero), add default points
        if (currentClipEffects.eq.length === 0) {
            currentClipEffects.eq = [
                { frequency: 200, gain: 0, type: 'lowshelf', q: 1 },
                { frequency: 500, gain: 0, type: 'peaking', q: 1 },
                { frequency: 1500, gain: 0, type: 'peaking', q: 1 },
                { frequency: 4000, gain: 0, type: 'peaking', q: 1 },
                { frequency: 8000, gain: 0, type: 'highshelf', q: 1 }
            ];
        }
        console.log('ðŸ“Š Converted EQ from object to array format for editing:', currentClipEffects.eq);
    } else if (!currentClipEffects.eq) {
        // Initialize with default EQ points if none exist
        currentClipEffects.eq = [
            { frequency: 200, gain: 0, type: 'lowshelf', q: 1 },
            { frequency: 500, gain: 0, type: 'peaking', q: 1 },
            { frequency: 1500, gain: 0, type: 'peaking', q: 1 },
            { frequency: 4000, gain: 0, type: 'peaking', q: 1 },
            { frequency: 8000, gain: 0, type: 'highshelf', q: 1 }
        ];
        console.log('ðŸ“Š Initialized default EQ points:', currentClipEffects.eq);
    }
    
    // Update popup title
    const clipName = clip.type === 'sample' ? `Sample ${clip.data}` : `Pattern "${clip.data}"`;
    document.getElementById('arr-popup-clip-name').textContent = clipName;
    
    // Load effects values into controls
    loadEffectsIntoControls(currentClipEffects);
    
    // Start preview playback
    startEffectsPreview(clip);
    
    // Initialize ALL interactive systems with small delays to ensure canvases are rendered
    setTimeout(() => {
        initVisualEQ();
    }, 100);
    
    setTimeout(() => {
        setupLFOTabs();
        setupAllLFOEventListeners();
        initAllLFOVisualizers();
    }, 150);
    
    setTimeout(() => {
        setupAutomationTabs();
        setupAllAutomationEventListeners();
        initAllAutomationVisualizers();
        setupInteractiveAutomation(); // Make automation canvases interactive
    }, 200);
    
    // Position and show popup
    const popupWidth = Math.min(500, window.innerWidth * 0.9);
    const popupHeight = Math.min(600, window.innerHeight * 0.9);
    
    effectsPopup.style.width = popupWidth + 'px';
    effectsPopup.style.height = popupHeight + 'px';
    effectsPopup.style.left = ((window.innerWidth - popupWidth) / 2) + 'px';
    effectsPopup.style.top = ((window.innerHeight - popupHeight) / 2) + 'px';
    effectsPopup.style.display = 'flex';
    
    // Reset scroll position
    const popupContent = effectsPopup.querySelector('.popup-content');
    if (popupContent) {
        popupContent.scrollTop = 0;
    }
    
    // Set up button event listeners (do this each time popup opens to ensure they work)
    const closeBtn = document.getElementById('arr-effects-close-btn');
    const applyBtn = document.getElementById('arr-effects-apply-btn');
    const resetBtn = document.getElementById('arr-effects-reset-btn');
    
    console.log('ðŸ”˜ Button elements:', { closeBtn, applyBtn, resetBtn });
    console.log('ðŸ“‹ Current state:', { 
        currentClipForContext, 
        currentClipEffects: currentClipEffects ? 'exists' : 'null',
        clipFromParam: clip
    });
    
    // Remove old listeners by cloning and replacing (prevents duplicate listeners)
    if (closeBtn) {
        const newCloseBtn = closeBtn.cloneNode(true);
        closeBtn.parentNode.replaceChild(newCloseBtn, closeBtn);
        newCloseBtn.addEventListener('click', (e) => {
            e.preventDefault();
            e.stopPropagation();
            console.log('âœ–ï¸ Close button clicked');
            hideEffectsPopup();
        });
    }
    
    if (applyBtn) {
        const newApplyBtn = applyBtn.cloneNode(true);
        applyBtn.parentNode.replaceChild(newApplyBtn, applyBtn);
        newApplyBtn.addEventListener('click', (e) => {
            e.preventDefault();
            e.stopPropagation();
            console.log('âœ… Apply button clicked');
            console.log('   State before applyEffects:', {
                currentClipForContext,
                currentClipEffects: currentClipEffects ? 'exists' : 'null'
            });
            try {
                applyEffects();
                console.log('âœ… applyEffects() completed successfully');
            } catch (error) {
                console.error('âŒ Error in applyEffects():', error);
            }
        });
    }
    
    if (resetBtn) {
        const newResetBtn = resetBtn.cloneNode(true);
        resetBtn.parentNode.replaceChild(newResetBtn, resetBtn);
        newResetBtn.addEventListener('click', (e) => {
            e.preventDefault();
            e.stopPropagation();
            console.log('ðŸ”„ Reset button clicked');
            console.log('   State before resetEffects:', {
                currentClipForContext
            });
            resetEffects();
        });
    }
    
    console.log('ðŸŽ›ï¸ Effects popup opened for clip:', clipName);
}

// Start looping preview playback for effects popup
async function startEffectsPreview(clip) {
    console.log('ðŸŽ¬ startEffectsPreview called for clip:', clip.id);
    
    // Stop any existing preview FIRST
    stopEffectsPreview();
    
    // Wait a tiny bit to ensure cleanup completed
    await new Promise(resolve => setTimeout(resolve, 50));
    
    // Handle pattern clips differently
    if (clip.type === 'pattern') {
        console.log('ðŸŽ¹ Starting pattern preview for effects...');
        startPatternEffectsPreview(clip);
        return;
    }
    
    if (clip.type !== 'sample') {
        console.log('âš ï¸ Preview only works for sample and pattern clips');
        return;
    }
    
    // Load the sample buffer
    let buffer = sampleBuffers[clip.data];
    if (!buffer && typeof clip.data === 'number') {
        await loadSampleBuffer(clip.data);
        buffer = sampleBuffers[clip.data];
    }
    
    if (!buffer) {
        console.warn(`âš ï¸ Sample ${clip.data} not available for preview`);
        return;
    }
    
    // Calculate clip duration in seconds based on timeline grid
    const clipDurationInBeats = clip.duration || 4; // Default to 4 beats if not set
    const secondsPerBeat = 60 / arrangementState.tempo;
    const clipDurationInSeconds = clipDurationInBeats * secondsPerBeat;
    
    // Validate duration
    if (!isFinite(clipDurationInSeconds) || clipDurationInSeconds <= 0) {
        console.error('âŒ Invalid clip duration:', clipDurationInSeconds);
        return;
    }
    
    console.log(`ðŸŽµ Preview clip duration: ${clipDurationInBeats} beats = ${clipDurationInSeconds.toFixed(2)}s at ${arrangementState.tempo} BPM`);
    
    // Create effect chain ONCE (outside the loop function)
    // Create EQ nodes
    previewEqNodes = {
        low: audioContext.createBiquadFilter(),
        lowmid: audioContext.createBiquadFilter(),
        mid: audioContext.createBiquadFilter(),
        highmid: audioContext.createBiquadFilter(),
        high: audioContext.createBiquadFilter()
    };
    
    previewEqNodes.low.type = 'lowshelf';
    previewEqNodes.low.frequency.value = 200;
    previewEqNodes.lowmid.type = 'peaking';
    previewEqNodes.lowmid.frequency.value = 500;
    previewEqNodes.lowmid.Q.value = 1;
    previewEqNodes.mid.type = 'peaking';
    previewEqNodes.mid.frequency.value = 1500;
    previewEqNodes.mid.Q.value = 1;
    previewEqNodes.highmid.type = 'peaking';
    previewEqNodes.highmid.frequency.value = 4000;
    previewEqNodes.highmid.Q.value = 1;
    previewEqNodes.high.type = 'highshelf';
    previewEqNodes.high.frequency.value = 8000;
    
    // Chain EQ nodes
    previewEqNodes.low.connect(previewEqNodes.lowmid);
    previewEqNodes.lowmid.connect(previewEqNodes.mid);
    previewEqNodes.mid.connect(previewEqNodes.highmid);
    previewEqNodes.highmid.connect(previewEqNodes.high);
    
    // Create filter node
    previewFilterNode = audioContext.createBiquadFilter();
    previewFilterNode.type = 'allpass';
    previewEqNodes.high.connect(previewFilterNode);
    
    // Create delay nodes (ALWAYS create them, even if delay is 0)
    previewDelayNode = audioContext.createDelay(5.0); // Max 5 second delay
    previewFeedbackNode = audioContext.createGain();
    previewFeedbackNode.gain.value = 0; // Start with no feedback
    const delayWetGain = audioContext.createGain();
    delayWetGain.gain.value = 0; // Start with no delay wet signal
    
    // Create gain node for dry signal
    previewGainNode = audioContext.createGain();
    previewGainNode.gain.value = 1.0; // Full volume by default
    previewDryNode = audioContext.createGain(); // Dry path 
    previewDryNode.gain.value = 1.0; // Full dry signal by default
    
    // Create reverb nodes (simple mix control)
    previewReverbNode = audioContext.createGain();
    previewReverbMixNode = audioContext.createGain();
    previewReverbMixNode.gain.value = 1.0; // Pass signal through (reverb controlled by dry gain)
    
    // Setup audio routing:
    // Filter -> Delay -> DelayWet -----> Gain -> Destination
    //       \                           /
    //        +-> Dry ------------------+
    // Feedback: Delay -> Feedback -> Delay (loop)
    
    previewFilterNode.connect(previewDelayNode);
    previewDelayNode.connect(delayWetGain);
    previewDelayNode.connect(previewFeedbackNode);
    previewFeedbackNode.connect(previewDelayNode); // Feedback loop
    
    // Connect dry path (always passes through)
    previewFilterNode.connect(previewDryNode);
    
    // Both wet and dry connect to final gain
    delayWetGain.connect(previewGainNode);
    previewDryNode.connect(previewGainNode);
    
    // Store the wet gain for later control
    previewDelayWetGain = delayWetGain;
    
    // Connect gain to destination (or to analyzer first for visualization)
    // We'll connect via analyzer for the visual EQ
    // Disconnect first to avoid double connections
    if (waveformAnalyzer) {
        try {
            waveformAnalyzer.disconnect();
        } catch (e) {}
    } else {
        waveformAnalyzer = audioContext.createAnalyser();
        waveformAnalyzer.fftSize = 4096;
        waveformAnalyzer.smoothingTimeConstant = 0.7;
    }
    
    previewGainNode.connect(waveformAnalyzer);
    waveformAnalyzer.connect(audioContext.destination);
    
    // Apply initial effects
    // Use the saved effects from the pattern object if available
    if (arrangementState.patterns[clip.data] && arrangementState.patterns[clip.data].effects) {
        currentClipEffects = JSON.parse(JSON.stringify(arrangementState.patterns[clip.data].effects));
        console.log('ðŸ”Š Loaded pattern effects for preview:', currentClipEffects);
    }
    updatePreviewEffects();
    
    // Create and start the source with NATIVE LOOPING
    previewSource = audioContext.createBufferSource();
    previewSource.buffer = buffer;
    
    // Apply speed (playbackRate)
    const effects = currentClipEffects || clip.effects;
    const speed = effects.speed || 1;
    previewSource.playbackRate.value = speed;
    
    // Use native looping instead of manual restarts
    previewSource.loop = true;
    previewSource.loopStart = 0;
    previewSource.loopEnd = Math.min(clipDurationInSeconds, buffer.duration);
    
    // Connect source to effect chain
    previewSource.connect(previewEqNodes.low);
    
    // Start playback (will loop automatically)
    const startTime = audioContext.currentTime;
    previewSource.start(startTime);
    
    console.log(`ðŸŽµ Preview started at time ${startTime.toFixed(3)}`);
    console.log(`   Buffer duration: ${buffer.duration.toFixed(2)}s`);
    console.log(`   Clip duration: ${clipDurationInSeconds.toFixed(2)}s (${clipDurationInBeats} beats @ ${arrangementState.tempo} BPM)`);
    console.log(`   Loop: ${previewSource.loop}, Start: ${previewSource.loopStart}s, End: ${previewSource.loopEnd.toFixed(2)}s`);
    console.log(`   Speed (playbackRate): ${speed}x`);
    console.log(`   Source: ${previewSource ? 'CREATED' : 'NULL'}`);
    
    // Initialize LFOs and Automations
    initializePreviewLFOs();
    initializePreviewAutomations();
    
    // Set flag
    previewInterval = true;
}

// Update preview effects in real-time
function updatePreviewEffects() {
    if (!currentClipEffects || !previewGainNode) return;
    
    const effects = currentClipEffects;
    const now = audioContext.currentTime;
    
    // Update Volume - match scheduled playback scaling (scale to 0.7 max)
    if (previewGainNode) {
        const scaledVolume = (effects.volume / 100) * 0.7;
        previewGainNode.gain.setValueAtTime(scaledVolume, now);
        console.log(`ðŸ”Š Volume updated (scaled): ${effects.volume}% -> ${scaledVolume.toFixed(3)}`);
    }
    
    // Update Filter
    if (previewFilterNode) {
        if (effects.filter.type !== 'none') {
            previewFilterNode.type = effects.filter.type;
            previewFilterNode.frequency.setValueAtTime(
                effects.filter.cutoff,
                now
            );
            previewFilterNode.Q.setValueAtTime(
                effects.filter.resonance,
                now
            );
            console.log(`ðŸ”Š Filter updated: type=${effects.filter.type}, cutoff=${effects.filter.cutoff}Hz, Q=${effects.filter.resonance}`);
        } else {
            previewFilterNode.type = 'allpass';
        }
    }
    
    // Update EQ (using array of points - interactive EQ)
    if (previewEqNodes.low && effects.eq) {
        // If EQ is an array (interactive EQ), apply points to the 5 filter bands
        if (Array.isArray(effects.eq)) {
            // Apply the first 5 points to the 5 bands (or defaults)
            const p1 = effects.eq[0] || { frequency: 200, gain: 0 };
            const p2 = effects.eq[1] || { frequency: 500, gain: 0 };
            const p3 = effects.eq[2] || { frequency: 1500, gain: 0 };
            const p4 = effects.eq[3] || { frequency: 4000, gain: 0 };
            const p5 = effects.eq[4] || { frequency: 8000, gain: 0 };
            
            previewEqNodes.low.frequency.setValueAtTime(p1.frequency, now);
            previewEqNodes.low.gain.setValueAtTime(p1.gain, now);
            
            previewEqNodes.lowmid.frequency.setValueAtTime(p2.frequency, now);
            previewEqNodes.lowmid.gain.setValueAtTime(p2.gain, now);
            
            previewEqNodes.mid.frequency.setValueAtTime(p3.frequency, now);
            previewEqNodes.mid.gain.setValueAtTime(p3.gain, now);
            
            previewEqNodes.highmid.frequency.setValueAtTime(p4.frequency, now);
            previewEqNodes.highmid.gain.setValueAtTime(p4.gain, now);
            
            previewEqNodes.high.frequency.setValueAtTime(p5.frequency, now);
            previewEqNodes.high.gain.setValueAtTime(p5.gain, now);
            
            console.log(`ðŸ”Š EQ updated: [${p1.gain.toFixed(1)}, ${p2.gain.toFixed(1)}, ${p3.gain.toFixed(1)}, ${p4.gain.toFixed(1)}, ${p5.gain.toFixed(1)}] dB`);
        } 
        // If EQ is an object (legacy format), apply old way
        else if (effects.eq.low !== undefined) {
            previewEqNodes.low.gain.setValueAtTime(effects.eq.low, now);
            previewEqNodes.lowmid.gain.setValueAtTime(effects.eq.lowmid || 0, now);
            previewEqNodes.mid.gain.setValueAtTime(effects.eq.mid || 0, now);
            previewEqNodes.highmid.gain.setValueAtTime(effects.eq.highmid || 0, now);
            previewEqNodes.high.gain.setValueAtTime(effects.eq.high || 0, now);
            console.log(`ðŸ”Š EQ updated (legacy): low=${effects.eq.low}dB`);
        }
    }
    
    // Update Delay
    if (previewDelayNode && effects.delay) {
        const delayTime = effects.delay.time / 1000; // Convert ms to seconds
        const feedback = effects.delay.feedback / 100;
        
        previewDelayNode.delayTime.setValueAtTime(delayTime, now);
        
        if (previewFeedbackNode) {
            previewFeedbackNode.gain.setValueAtTime(feedback, now);
        }
        
        // Control wet/dry mix: if delay time is 0, set wet gain to 0
        if (previewDelayWetGain) {
            const wetLevel = delayTime > 0 ? 0.5 : 0; // 50% wet when delay is active
            previewDelayWetGain.gain.setValueAtTime(wetLevel, now);
        }
        
        console.log(`ðŸ”Š Delay updated: time=${delayTime.toFixed(3)}s, feedback=${(feedback*100).toFixed(0)}%`);
    }
    
    // Update Reverb Mix (simple wet/dry control)
    if (previewDryNode && effects.reverb) {
        const reverbMix = effects.reverb.mix / 100; // 0 to 1
        
        // Only create reverb if mix > 0 and decay > 0
        if (effects.reverb.mix > 0 && effects.reverb.decay > 0) {
            // Need to recreate the reverb with new decay
            // This is expensive but necessary for real-time decay changes
            if (!previewReverbConvolver || previewLastReverbDecay !== effects.reverb.decay) {
                createPreviewReverb(effects.reverb.decay, effects.reverb.damping || 50);
                previewLastReverbDecay = effects.reverb.decay;
            }
            
            // Update wet gain (dry is always full volume at previewDryNode)
            if (previewReverbWetGain) {
                previewReverbWetGain.gain.setValueAtTime(reverbMix, now);
            }
        } else {
            // No reverb needed, just dry signal
            if (previewReverbWetGain) {
                previewReverbWetGain.gain.setValueAtTime(0, now);
            }
        }
        
        console.log(`ðŸ”Š Reverb updated: mix=${effects.reverb.mix}%, decay=${effects.reverb.decay}s`);
    }
    
    // Update Pitch (via source playbackRate if needed)
    // Note: Pitch shift requires resampling, typically done via playbackRate
    // For BufferSourceNode with looping, we can't change playbackRate dynamically
    // This would need to be applied when creating the source
    
    console.log('ðŸ”„ Effects updated in real-time');
}

// Create reverb convolver for preview
function createPreviewReverb(decayTime, damping) {
    console.log(`ðŸŽšï¸ Creating reverb: decay=${decayTime}s, damping=${damping}`);
    
    // Don't recreate if decay is very short (< 0.1s)
    if (decayTime < 0.1) {
        if (previewReverbWetGain) {
            previewReverbWetGain.gain.setValueAtTime(0, audioContext.currentTime);
        }
        return;
    }
    
    // Disconnect old reverb if it exists
    if (previewReverbConvolver) {
        try {
            previewReverbConvolver.disconnect();
        } catch (e) {}
    }
    
    // Create impulse response
    const sampleRate = audioContext.sampleRate;
    const length = Math.max(sampleRate * 0.1, sampleRate * decayTime); // Minimum 0.1s
    const impulse = audioContext.createBuffer(2, length, sampleRate);
    const impulseL = impulse.getChannelData(0);
    const impulseR = impulse.getChannelData(1);
    
    for (let i = 0; i < length; i++) {
        const n = length - i;
        const decay = Math.pow(n / length, damping / 50);
        impulseL[i] = (Math.random() * 2 - 1) * decay;
        impulseR[i] = (Math.random() * 2 - 1) * decay;
    }
    
    // Create or update convolver
    if (!previewReverbConvolver) {
        previewReverbConvolver = audioContext.createConvolver();
    }
    previewReverbConvolver.buffer = impulse;
    
    // Create wet gain if it doesn't exist
    if (!previewReverbWetGain) {
        previewReverbWetGain = audioContext.createGain();
        previewReverbWetGain.gain.value = 0; // Start with no reverb
        
        // Setup reverb: DryNode -> Convolver -> WetGain -> MainGain
        // DryNode also connects directly to MainGain (parallel wet/dry)
        previewDryNode.connect(previewReverbConvolver);
        previewReverbConvolver.connect(previewReverbWetGain);
        previewReverbWetGain.connect(previewGainNode);
        
        console.log('âœ… Reverb chain created');
    } else {
        // Reconnect convolver with new impulse
        try {
            previewReverbConvolver.disconnect();
        } catch (e) {}
        
        previewDryNode.connect(previewReverbConvolver);
        previewReverbConvolver.connect(previewReverbWetGain);
        previewReverbWetGain.connect(previewGainNode);
        
        console.log('âœ… Reverb impulse updated');
    }
}

// ========================================
// LFO PROCESSING FOR PREVIEW
// ========================================

function initializePreviewLFOs() {
    if (!currentClipEffects || !currentClipEffects.lfos) return;
    
    console.log('ðŸŽ›ï¸ Initializing Preview LFOs...');
    
    // Stop any existing LFOs first
    stopPreviewLFOs();
    
    // Create LFO oscillators and gains for each of the 4 LFOs
    for (let i = 0; i < 4; i++) {
        const lfo = currentClipEffects.lfos[i];
        
        if (!lfo || lfo.target === 'none' || lfo.depth === 0) {
            previewLfoOscillators[i] = null;
            previewLfoGains[i] = null;
            continue;
        }
        
        // Create oscillator for this LFO
        const oscillator = audioContext.createOscillator();
        oscillator.type = lfo.waveform || 'sine';
        oscillator.frequency.value = lfo.rate || 1;
        
        // Create gain node to control LFO depth
        const lfoGain = audioContext.createGain();
        const depth = (lfo.depth || 0) / 100;
        
        // Connect oscillator to gain
        oscillator.connect(lfoGain);
        
        // Connect to target parameter
        connectLFOToTarget(i, lfo.target, lfoGain, depth);
        
        // Start the oscillator
        oscillator.start();
        
        previewLfoOscillators[i] = oscillator;
        previewLfoGains[i] = lfoGain;
        
        console.log(`âœ… LFO ${i+1} started: target=${lfo.target}, wave=${lfo.waveform}, rate=${lfo.rate}Hz, depth=${lfo.depth}%`);
    }
}

function connectLFOToTarget(lfoIndex, target, lfoGain, depth) {
    // Determine which parameter to modulate based on target
    switch(target) {
        case 'volume':
            if (previewGainNode) {
                // Scale the LFO output to modulate volume
                lfoGain.gain.value = depth * 0.5; // Max Â±50% volume modulation
                lfoGain.connect(previewGainNode.gain);
            }
            break;
            
        case 'filter':
            if (previewFilterNode && previewFilterNode.type !== 'allpass') {
                // Scale the LFO to modulate filter cutoff
                lfoGain.gain.value = depth * 2000; // Max Â±2000 Hz modulation
                lfoGain.connect(previewFilterNode.frequency);
            }
            break;
            
        case 'pitch':
            // Pitch modulation using detune (for synth) or playbackRate (for samples)
            if (previewSource && previewSource.detune) {
                // Synth: connect to detune (in cents, 100 cents = 1 semitone)
                lfoGain.gain.value = depth * 1200; // Max Â±12 semitones (1200 cents)
                lfoGain.connect(previewSource.detune);
                console.log(`âœ… LFO ${lfoIndex+1} connected to pitch (detune): depth=${depth}, range=Â±${(depth*12).toFixed(1)} semitones`);
            } else if (previewSource && previewSource.playbackRate) {
                // Sample: connect to playbackRate
                // Note: playbackRate uses linear scale (2.0 = double speed/octave up)
                // We'll use a small range to approximate semitone modulation
                lfoGain.gain.value = depth * 0.1; // Max Â±10% playback rate modulation (~1.7 semitones)
                lfoGain.connect(previewSource.playbackRate);
                console.log(`âœ… LFO ${lfoIndex+1} connected to pitch (playbackRate): depth=${depth}, range=Â±${(depth*10).toFixed(1)}%`);
            } else {
                console.warn('âš ï¸ Pitch LFO: neither detune nor playbackRate available on source');
            }
            break;
            
        case 'delay-time':
            if (previewDelayNode) {
                lfoGain.gain.value = depth * 0.1; // Max Â±100ms modulation
                lfoGain.connect(previewDelayNode.delayTime);
            }
            break;
            
        case 'delay-feedback':
            if (previewFeedbackNode) {
                lfoGain.gain.value = depth * 0.3; // Max Â±30% feedback modulation
                lfoGain.connect(previewFeedbackNode.gain);
            }
            break;
            
        case 'pan':
            // Panning would require a stereo panner node
            console.warn('âš ï¸ Pan LFO not implemented for preview');
            break;
    }
}

function updatePreviewLFOs() {
    if (!currentClipEffects || !currentClipEffects.lfos) return;
    
    // Re-initialize all LFOs with new settings
    initializePreviewLFOs();
}

function stopPreviewLFOs() {
    // Stop and disconnect all LFO oscillators
    for (let i = 0; i < previewLfoOscillators.length; i++) {
        if (previewLfoOscillators[i]) {
            try {
                previewLfoOscillators[i].stop();
                previewLfoOscillators[i].disconnect();
            } catch (e) {
                console.warn(`âš ï¸ Error stopping LFO ${i+1}:`, e);
            }
        }
        
        if (previewLfoGains[i]) {
            try {
                previewLfoGains[i].disconnect();
            } catch (e) {}
        }
    }
    
    previewLfoOscillators = [];
    previewLfoGains = [];
}

// ========================================
// AUTOMATION PROCESSING FOR PREVIEW
// ========================================

function initializePreviewAutomations() {
    if (!currentClipEffects || !currentClipEffects.automations) return;
    
    console.log('ðŸŽ›ï¸ Initializing Preview Automations...');
    
    // Stop any existing automations first
    stopPreviewAutomations();
    
    // Get clip duration for automation timing
    const clipDurationInBeats = currentClipForContext?.duration || 4;
    const secondsPerBeat = 60 / arrangementState.tempo;
    const clipDurationInSeconds = clipDurationInBeats * secondsPerBeat;
    
    // Start each automation
    for (let i = 0; i < 4; i++) {
        const auto = currentClipEffects.automations[i];
        
        if (!auto || auto.target === 'none') {
            continue;
        }
        
        // Start automation loop
        startAutomationLoop(i, auto, clipDurationInSeconds);
        
        console.log(`âœ… Automation ${i+1} started: target=${auto.target}, ${auto.start}â†’${auto.end}, duration=${auto.duration}bars, curve=${auto.curve}`);
    }
}

function startAutomationLoop(autoIndex, auto, clipDuration) {
    const duration = auto.duration || 1; // Duration in bars
    const secondsPerBeat = 60 / arrangementState.tempo;
    const automationDuration = duration * 4 * secondsPerBeat; // bars * 4 beats/bar * seconds/beat
    
    const startValue = auto.start !== undefined ? auto.start / 100 : 0.5;
    const endValue = auto.end !== undefined ? auto.end / 100 : 0.5;
    const curve = auto.curve || 'linear';
    
    let startTime = audioContext.currentTime;
    
    // Update function called repeatedly
    const updateAutomation = () => {
        const elapsed = audioContext.currentTime - startTime;
        const progress = (elapsed % automationDuration) / automationDuration; // 0 to 1
        
        // Calculate value based on curve
        let value;
        switch(curve) {
            case 'exponential':
            case 'easeIn':
                value = startValue + (endValue - startValue) * (progress * progress);
                break;
            case 'logarithmic':
            case 'easeOut':
                value = startValue + (endValue - startValue) * (1 - (1 - progress) * (1 - progress));
                break;
            case 'linear':
            default:
                value = startValue + (endValue - startValue) * progress;
                break;
        }
        
        // Apply to target
        applyAutomationToTarget(auto.target, value);
    };
    
    // Call update at ~60fps
    const intervalId = setInterval(updateAutomation, 16);
    previewAutomationIntervals[autoIndex] = intervalId;
}

function applyAutomationToTarget(target, value) {
    const now = audioContext.currentTime;
    
    switch(target) {
        case 'volume':
            if (previewGainNode) {
                previewGainNode.gain.setValueAtTime(value, now);
            }
            break;
            
        case 'filter':
            if (previewFilterNode && previewFilterNode.type !== 'allpass') {
                const minFreq = 20;
                const maxFreq = 20000;
                const frequency = minFreq + (maxFreq - minFreq) * value;
                previewFilterNode.frequency.setValueAtTime(frequency, now);
            }
            break;
            
        case 'pitch':
            // Pitch automation not possible with BufferSourceNode in real-time
            break;
            
        case 'delay-time':
            if (previewDelayNode) {
                const maxDelay = 1.0; // 1 second max
                previewDelayNode.delayTime.setValueAtTime(value * maxDelay, now);
            }
            break;
            
        case 'delay-feedback':
            if (previewFeedbackNode) {
                previewFeedbackNode.gain.setValueAtTime(value * 0.9, now); // Max 90% feedback
            }
            break;
            
        case 'reverb-mix':
            if (previewReverbMixNode) {
                previewReverbMixNode.gain.setValueAtTime(value, now);
            }
            break;
            
        case 'pan':
            // Panning would require stereo panner
            break;
    }
}

function updatePreviewAutomations() {
    // Re-initialize automations with new settings
    initializePreviewAutomations();
}

function stopPreviewAutomations() {
    // Clear all automation intervals
    for (let i = 0; i < previewAutomationIntervals.length; i++) {
        if (previewAutomationIntervals[i]) {
            clearInterval(previewAutomationIntervals[i]);
        }
    }
    
    previewAutomationIntervals = [];
}

// Stop preview playback
function stopEffectsPreview() {
    console.log('â¹ï¸ stopEffectsPreview called');
    console.log(`   pianoRollLoopInterval: ${pianoRollLoopInterval}`);
    console.log(`   Active voices: ${Object.keys(pianoRollPreviewActiveVoices || {}).length}`);
    
    // Stop LFOs and Automations FIRST
    stopPreviewLFOs();
    stopPreviewAutomations();
    
    // Stop pattern preview loop interval
    if (pianoRollLoopInterval) {
        clearInterval(pianoRollLoopInterval);
        console.log(`   âœ… Cleared interval ${pianoRollLoopInterval}`);
        pianoRollLoopInterval = null;
    }
    
    // Stop all active pattern voices
    if (pianoRollPreviewActiveVoices) {
        Object.values(pianoRollPreviewActiveVoices).forEach(voice => {
            if (voice && voice.source) {
                try {
                    voice.source.stop();
                    voice.source.disconnect();
                } catch (e) {}
            }
            if (voice && voice.source2) {
                try {
                    voice.source2.stop();
                    voice.source2.disconnect();
                } catch (e) {}
            }
            if (voice && voice.gain) {
                try {
                    voice.gain.disconnect();
                } catch (e) {}
            }
        });
        pianoRollPreviewActiveVoices = {};
    }
    
    previewInterval = null;
    
    // Stop and disconnect source (for sample clips)
    if (previewSource) {
        try {
            console.log('ðŸ›‘ Stopping audio source');
            previewSource.stop();
            previewSource.disconnect();
        } catch (e) {
            console.warn('âš ï¸ Error stopping source:', e);
        }
        previewSource = null;
    }
    
    // Disconnect all effect nodes
    if (previewGainNode) {
        try {
            previewGainNode.disconnect();
        } catch (e) {}
        previewGainNode = null;
    }
    
    if (previewFilterNode) {
        try {
            previewFilterNode.disconnect();
        } catch (e) {}
        previewFilterNode = null;
    }
    
    if (previewEqNodes.low) {
        try {
            previewEqNodes.low.disconnect();
            previewEqNodes.lowmid.disconnect();
            previewEqNodes.mid.disconnect();
            previewEqNodes.highmid.disconnect();
            previewEqNodes.high.disconnect();
        } catch (e) {}
        previewEqNodes = {};
    }
    
    if (previewDelayNode) {
        try {
            previewDelayNode.disconnect();
        } catch (e) {}
        previewDelayNode = null;
    }
    
    if (previewDelayWetGain) {
        try {
            previewDelayWetGain.disconnect();
        } catch (e) {}
        previewDelayWetGain = null;
    }
    
    if (previewFeedbackNode) {
        try {
            previewFeedbackNode.disconnect();
        } catch (e) {}
        previewFeedbackNode = null;
    }
    
    if (previewReverbNode) {
        try {
            previewReverbNode.disconnect();
        } catch (e) {}
        previewReverbNode = null;
    }
    
    if (previewReverbMixNode) {
        try {
            previewReverbMixNode.disconnect();
        } catch (e) {}
        previewReverbMixNode = null;
    }
    
    if (previewDryNode) {
        try {
            previewDryNode.disconnect();
        } catch (e) {}
        previewDryNode = null;
    }
    
    // Disconnect reverb convolver nodes
    if (previewReverbConvolver) {
        try {
            previewReverbConvolver.disconnect();
        } catch (e) {}
        previewReverbConvolver = null;
    }
    
    if (previewReverbWetGain) {
        try {
            previewReverbWetGain.disconnect();
        } catch (e) {}
        previewReverbWetGain = null;
    }
    
    previewLastReverbDecay = null;
    
    // Cleanup LFO
    cleanupLfo();
    
    console.log('âœ… Preview stopped and cleaned up');
}

// Start looping preview for pattern clips
function startPatternEffectsPreview(clip) {
    console.log('ðŸŽ¹ startPatternEffectsPreview for pattern:', clip.data);
    
    // IMPORTANT: Stop any existing preview COMPLETELY first
    stopEffectsPreview();
    
    if (!audioContext) {
        initAudioContext();
    }
    
    const pattern = arrangementState.patterns[clip.data];
    if (!pattern || !pattern.notes || pattern.notes.length === 0) {
        console.warn('âš ï¸ Pattern has no notes to preview');
        return;
    }
    
    // Log what's in the saved pattern
    console.log('ðŸ“¦ Loaded pattern from arrangementState:');
    console.log('   Pattern name:', clip.data);
    console.log('   Sound source:', pattern.soundSource);
    if (pattern.soundDesign && pattern.soundDesign.envelope && pattern.soundDesign.envelope.pitchMod) {
        console.log('   âœ… SAVED Pitch Mod:', pattern.soundDesign.envelope.pitchMod);
    } else {
        console.log('   âŒ NO Pitch Mod in saved pattern');
        if (pattern.soundDesign && pattern.soundDesign.envelope) {
            console.log('   Envelope keys:', Object.keys(pattern.soundDesign.envelope));
        }
    }
    
    // Initialize pianoRollData for this pattern if it doesn't exist
    // This ensures we have the latest sound design settings including pitch modulation
    if (!pianoRollData[clip.data]) {
        console.log('ðŸ“ Creating NEW pianoRollData for pattern:', clip.data);
        pianoRollData[clip.data] = {
            notes: pattern.notes || [],
            gridWidth: pattern.gridWidth || 16,
            soundSource: pattern.soundSource || 'synth',
            soundDesign: pattern.soundDesign || {
                osc1: { wave: 'sine', detune: 0, level: 50 },
                osc2: { wave: 'sawtooth', detune: 0, level: 50 },
                filter: { type: 'lowpass', cutoff: 2000, resonance: 0 },
                envelope: { 
                    attack: 10, 
                    decay: 100, 
                    sustain: 70, 
                    release: 200,
                    pitchMod: { enabled: false, amount: 0 }
                }
            }
        };
    } else {
        console.log('ðŸ“ UPDATING existing pianoRollData for pattern:', clip.data);
        // Update with latest pattern data from saved state
        pianoRollData[clip.data].notes = pattern.notes || [];
        pianoRollData[clip.data].gridWidth = pattern.gridWidth || 16;
        if (pattern.soundDesign) {
            pianoRollData[clip.data].soundDesign = JSON.parse(JSON.stringify(pattern.soundDesign));
            console.log('   âœ… Updated soundDesign from pattern');
        } else {
            console.log('   âš ï¸ No soundDesign in pattern, keeping existing');
        }
    }
    
    console.log('ðŸ“Š Pattern soundDesign loaded:');
    console.log('   OSC1:', pianoRollData[clip.data].soundDesign.osc1);
    console.log('   OSC2:', pianoRollData[clip.data].soundDesign.osc2);
    console.log('   ENV:', pianoRollData[clip.data].soundDesign.envelope);
    if (pianoRollData[clip.data].soundDesign.envelope.pitchMod) {
        console.log('   ðŸŽµ PITCH MOD:', pianoRollData[clip.data].soundDesign.envelope.pitchMod);
    } else {
        console.log('   âš ï¸ NO PITCH MOD DATA');
    }
    
    // Create master effects chain for pattern playback
    previewEqNodes = {
        low: audioContext.createBiquadFilter(),
        lowmid: audioContext.createBiquadFilter(),
        mid: audioContext.createBiquadFilter(),
        highmid: audioContext.createBiquadFilter(),
        high: audioContext.createBiquadFilter()
    };
    
    previewEqNodes.low.type = 'lowshelf';
    previewEqNodes.low.frequency.value = 200;
    previewEqNodes.lowmid.type = 'peaking';
    previewEqNodes.lowmid.frequency.value = 500;
    previewEqNodes.lowmid.Q.value = 1;
    previewEqNodes.mid.type = 'peaking';
    previewEqNodes.mid.frequency.value = 1500;
    previewEqNodes.mid.Q.value = 1;
    previewEqNodes.highmid.type = 'peaking';
    previewEqNodes.highmid.frequency.value = 4000;
    previewEqNodes.highmid.Q.value = 1;
    previewEqNodes.high.type = 'highshelf';
    previewEqNodes.high.frequency.value = 8000;
    
    // Chain EQ nodes
    previewEqNodes.low.connect(previewEqNodes.lowmid);
    previewEqNodes.lowmid.connect(previewEqNodes.mid);
    previewEqNodes.mid.connect(previewEqNodes.highmid);
    previewEqNodes.highmid.connect(previewEqNodes.high);
    
    // Create filter node
    previewFilterNode = audioContext.createBiquadFilter();
    previewFilterNode.type = 'allpass';
    previewEqNodes.high.connect(previewFilterNode);
    
    // Create delay nodes
    previewDelayNode = audioContext.createDelay(5.0);
    previewFeedbackNode = audioContext.createGain();
    previewFeedbackNode.gain.value = 0;
    const delayWetGain = audioContext.createGain();
    delayWetGain.gain.value = 0;
    
    // Create gain nodes
    previewGainNode = audioContext.createGain();
    previewGainNode.gain.value = 0.3; // Consistent with arrangement playback
    previewDryNode = audioContext.createGain();
    previewDryNode.gain.value = 1.0;
    
    // Setup audio routing
    previewFilterNode.connect(previewDelayNode);
    previewDelayNode.connect(delayWetGain);
    previewDelayNode.connect(previewFeedbackNode);
    previewFeedbackNode.connect(previewDelayNode);
    previewFilterNode.connect(previewDryNode);
    delayWetGain.connect(previewGainNode);
    previewDryNode.connect(previewGainNode);
    previewDelayWetGain = delayWetGain;
    
    // Connect through both analyzers for visualization
    // Disconnect first to avoid double connections
    if (waveformAnalyzer) {
        try {
            waveformAnalyzer.disconnect();
        } catch (e) {}
    } else {
        waveformAnalyzer = audioContext.createAnalyser();
        waveformAnalyzer.fftSize = 4096;
        waveformAnalyzer.smoothingTimeConstant = 0.7;
    }
    
    if (pianoRollVisualizerAnalyzer) {
        try {
            pianoRollVisualizerAnalyzer.disconnect();
        } catch (e) {}
    } else {
        pianoRollVisualizerAnalyzer = audioContext.createAnalyser();
        pianoRollVisualizerAnalyzer.fftSize = 256;
    }
    
    // Chain: previewGainNode -> pianoRollAnalyzer -> waveformAnalyzer -> destination
    previewGainNode.connect(pianoRollVisualizerAnalyzer);
    pianoRollVisualizerAnalyzer.connect(waveformAnalyzer);
    waveformAnalyzer.connect(audioContext.destination);
    
    // Apply initial effects
    updatePreviewEffects();
    
    // Calculate timing
    const tempo = arrangementState.tempo;
    const beatDuration = 60 / tempo;
    const stepDuration = beatDuration / 4; // 16th note
    const gridWidth = pattern.gridWidth || 16;
    
    let currentStep = 0;
    
    // Store active voices for cleanup
    pianoRollPreviewActiveVoices = {};
    
    // Store preview start time for LFO/Automation calculations
    const previewStartTime = audioContext.currentTime;
    
    // Create loop interval
    const loopPattern = () => {
        // Find notes at current step
        const notesAtStep = pattern.notes.filter(n => n.col === currentStep);
        
        notesAtStep.forEach(note => {
            const noteDuration = (note.length || 1) * stepDuration;
            playPatternNoteWithEffects(note.row, audioContext.currentTime, noteDuration, pattern, previewStartTime);
        });
        
        currentStep++;
        if (currentStep >= gridWidth) {
            currentStep = 0; // Loop
        }
    };
    
    // Start loop
    pianoRollLoopInterval = setInterval(loopPattern, stepDuration * 1000);
    previewInterval = pianoRollLoopInterval; // Store for cleanup
    
    console.log(`âœ… Pattern preview started:`);
    console.log(`   Grid: ${gridWidth} steps`);
    console.log(`   Tempo: ${tempo} BPM`);
    console.log(`   Step duration: ${stepDuration.toFixed(3)}s`);
    console.log(`   Interval ID: ${pianoRollLoopInterval}`);
    console.log(`   Pattern has ${pattern.notes.length} notes`);
    console.log(`   Sound source: ${pattern.soundSource}`);
}

// Play a single pattern note through the effects chain
function playPatternNoteWithEffects(noteRow, time, duration, pattern, previewStartTime) {
    // Calculate frequency from row using the SAME method as arrangement playback
    const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
    const octave = Math.floor(noteRow / 12);
    const noteIndex = noteRow % 12;
    
    const noteFrequencies = {
        'C': 16.35, 'C#': 17.32, 'D': 18.35, 'D#': 19.45,
        'E': 20.60, 'F': 21.83, 'F#': 23.12, 'G': 24.50,
        'G#': 25.96, 'A': 27.50, 'A#': 29.14, 'B': 30.87
    };
    
    const noteName = noteNames[noteIndex];
    const baseFreq = noteFrequencies[noteName];
    const frequency = baseFreq * Math.pow(2, octave);
    
    console.log(`ðŸŽµ Playing note: row=${noteRow}, note=${noteName}${octave}, freq=${frequency.toFixed(2)}Hz`);
    
    // ALWAYS use pattern.soundDesign and pattern.effects (canonical source)
    let soundDesign = pattern.soundDesign;
    let effects = pattern.effects || {};
    console.log('   Using pattern.soundDesign and pattern.effects (saved state)');
    if (soundDesign && soundDesign.envelope && soundDesign.envelope.pitchMod) {
        console.log('   ðŸŽµ Pitch Mod in soundDesign:', soundDesign.envelope.pitchMod);
    } else {
        console.log('   âš ï¸ No pitch mod in soundDesign');
    }
    
    if (pattern.soundSource === 'sample') {
        // Play sample at pitch through effects chain
        playPatternSampleWithEffects(frequency, duration, previewStartTime);
    } else {
        // Play synth note through effects chain
        playPatternSynthWithEffects(frequency, duration, soundDesign, previewStartTime);
    }
}

// Play sample through the effects chain
function playPatternSampleWithEffects(frequency, duration, previewStartTime) {
    const buffer = sampleBuffers[currentSampleNumber];
    if (!buffer) return;
    
    // Start with the note's frequency
    const baseFreq = 261.63; // Middle C
    let playbackRate = frequency / baseFreq;
    
    // Get effects for this clip
    // Use latest pattern.effects for preview
    const effects = soundDesign && soundDesign.effects ? soundDesign.effects : (pattern && pattern.effects ? pattern.effects : currentClipEffects || {});
    
    // Apply speed effect (this is the main pitch/speed setting)
    if (effects.speed) {
        playbackRate *= effects.speed;
        console.log(`   ðŸŽšï¸ Speed effect applied: ${effects.speed}x â†’ playbackRate=${playbackRate.toFixed(3)}`);
    }
    
    // Calculate LFO/Automation modulation
    const currentTime = audioContext.currentTime;
    const elapsedTime = previewStartTime ? (currentTime - previewStartTime) : 0;
    
    // Apply LFO pitch modulation
    if (effects.lfos && Array.isArray(effects.lfos)) {
        effects.lfos.forEach(lfo => {
            if (lfo.enabled && lfo.target === 'pitch' && lfo.depth > 0) {
                const lfoValue = getLFOValue(lfo, currentTime);
                const semitones = lfoValue * 12; // Â±1 octave range
                const pitchMultiplier = Math.pow(2, semitones / 12);
                playbackRate *= pitchMultiplier;
                console.log(`   ðŸŽµ LFO Pitch: value=${lfoValue.toFixed(3)} â†’ ${semitones.toFixed(2)}st â†’ rate=${playbackRate.toFixed(3)}`);
            }
        });
    }
    
    // Apply Automation pitch modulation
    if (effects.automations && Array.isArray(effects.automations)) {
        const clipDuration = 16; // Assuming 4 bars default
        effects.automations.forEach(auto => {
            if (auto.enabled && auto.target === 'pitch') {
                const autoValue = getAutomationValue(auto, previewStartTime || 0, currentTime, clipDuration);
                // autoValue is 0-1, convert to -1 to +1 range, then to semitones
                const normalizedValue = (autoValue - 0.5) * 2; // -1 to +1
                const semitones = normalizedValue * 12; // Â±1 octave
                const pitchMultiplier = Math.pow(2, semitones / 12);
                playbackRate *= pitchMultiplier;
                console.log(`   ðŸ“Š Auto Pitch: value=${autoValue.toFixed(3)} â†’ ${semitones.toFixed(2)}st â†’ rate=${playbackRate.toFixed(3)}`);
            }
        });
    }
    
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.playbackRate.value = playbackRate;
    
    // Connect to the master effects chain
    source.connect(previewEqNodes.low);
    
    // Start and schedule stop
    const now = audioContext.currentTime;
    source.start(now);
    source.stop(now + duration);
    
    // Track for cleanup
    const voiceId = `voice_${Date.now()}_${Math.random()}`;
    pianoRollPreviewActiveVoices[voiceId] = { source };
    
    source.onended = () => {
        try {
            source.disconnect();
        } catch (e) {}
        delete pianoRollPreviewActiveVoices[voiceId];
    };
}

// Play synth note through the effects chain
function playPatternSynthWithEffects(frequency, duration, soundDesign, previewStartTime) {
    // Check for too many active voices (indicates cleanup issue)
    const activeVoiceCount = Object.keys(pianoRollPreviewActiveVoices || {}).length;
    if (activeVoiceCount > 20) {
        console.error(`âŒ TOO MANY ACTIVE VOICES: ${activeVoiceCount} - something is wrong!`);
        // Force cleanup
        if (pianoRollPreviewActiveVoices) {
            Object.values(pianoRollPreviewActiveVoices).forEach(voice => {
                try {
                    if (voice.source) voice.source.stop();
                    if (voice.source2) voice.source2.stop();
                } catch (e) {}
            });
            pianoRollPreviewActiveVoices = {};
        }
        return; // Don't play more notes
    }
    
    console.log(`ðŸŽ¹ playPatternSynthWithEffects: freq=${frequency.toFixed(2)}Hz, duration=${duration.toFixed(3)}s (active voices: ${activeVoiceCount})`);
    console.log('   soundDesign:', soundDesign);
    
    const effects = currentClipEffects || {};
    console.log('ðŸ” Effects object:', effects);
    console.log('   LFOs:', effects.lfos);
    console.log('   Automations:', effects.automations);
    console.log('   Speed:', effects.speed);
    
    // Apply speed effect to match playback
    let finalFrequency = frequency;
    if (effects.speed) {
        finalFrequency *= effects.speed;
        console.log(`   ðŸŽšï¸ Speed effect applied: ${effects.speed}x â†’ ${finalFrequency.toFixed(2)}Hz`);
    }
    
    // Calculate LFO/Automation modulation for pitch
    const currentTime = audioContext.currentTime;
    const elapsedTime = previewStartTime ? (currentTime - previewStartTime) : 0;
    
    console.log(`   Preview start time: ${previewStartTime}, current: ${currentTime}, elapsed: ${elapsedTime.toFixed(3)}s`);
    
    // Calculate automation detune (static value at note start)
    let additionalDetune = 0; // In cents
    
    // Apply Automation pitch modulation (calculated once at note start)
    if (effects.automations && Array.isArray(effects.automations)) {
        console.log(`   Checking ${effects.automations.length} Automations...`);
        const clipDuration = 16; // Assuming 4 bars default
        effects.automations.forEach((auto, i) => {
            console.log(`   Auto ${i}: target=${auto.target}, enabled=${auto.enabled}`);
            if (auto.enabled && auto.target === 'pitch') {
                const autoValue = getAutomationValue(auto, previewStartTime || 0, currentTime, clipDuration);
                // autoValue is 0-1, convert to -1 to +1 range, then to semitones
                const normalizedValue = (autoValue - 0.5) * 2; // -1 to +1
                const semitones = normalizedValue * 12; // Â±1 octave
                additionalDetune += semitones * 100; // Convert to cents
                console.log(`   ðŸŽµ Auto Pitch APPLIED: ${autoValue.toFixed(3)} â†’ ${semitones.toFixed(2)} semitones â†’ ${additionalDetune.toFixed(0)} cents`);
            }
        });
    } else {
        console.log('   âš ï¸ No Automations or not an array');
    }
    
    // Note: LFO pitch will be applied as real-time oscillator connections (see below)
    if (effects.lfos && Array.isArray(effects.lfos)) {
        const activeLFOs = effects.lfos.filter(lfo => lfo.enabled && lfo.target === 'pitch' && lfo.depth > 0);
        if (activeLFOs.length > 0) {
            console.log(`   ðŸŽ›ï¸ ${activeLFOs.length} real-time LFO(s) will be connected to oscillators`);
        }
    }
    
    console.log(`   ðŸ“Š TOTAL ADDITIONAL DETUNE: ${additionalDetune.toFixed(0)} cents`);
    
    const sd = soundDesign || {
        osc1: { wave: 'sine', detune: 0, level: 50 },
        osc2: { wave: 'sawtooth', detune: 0, level: 50 },
        envelope: { attack: 10, decay: 100, sustain: 70, release: 200 }
    };
    
    console.log(`   OSC1: ${sd.osc1.wave}, level=${sd.osc1.level}%, detune=${sd.osc1.detune}`);
    console.log(`   OSC2: ${sd.osc2.wave}, level=${sd.osc2.level}%, detune=${sd.osc2.detune}`);
    console.log(`   ENV: A=${sd.envelope.attack}ms, D=${sd.envelope.decay}ms, S=${sd.envelope.sustain}%, R=${sd.envelope.release}ms`);
    
    const now = audioContext.currentTime;
    
    // Create oscillators
    const osc1 = audioContext.createOscillator();
    const osc2 = audioContext.createOscillator();
    const osc1Gain = audioContext.createGain();
    const osc2Gain = audioContext.createGain();
    const masterGain = audioContext.createGain();
    
    osc1.type = sd.osc1.wave || 'sine';
    osc1.frequency.value = finalFrequency;
    osc1.detune.value = (sd.osc1.detune || 0) + additionalDetune; // Apply initial detune
    
    osc2.type = sd.osc2.wave || 'sawtooth';
    osc2.frequency.value = finalFrequency;
    osc2.detune.value = (sd.osc2.detune || 0) + additionalDetune; // Apply initial detune
    
    // Connect real-time LFO oscillators to detune for continuous modulation
    if (effects.lfos && Array.isArray(effects.lfos)) {
        effects.lfos.forEach((lfo, i) => {
            if (lfo.enabled && lfo.target === 'pitch' && lfo.depth > 0) {
                // Create a temporary LFO oscillator for this note
                const lfoOsc = audioContext.createOscillator();
                lfoOsc.type = lfo.waveform || 'sine';
                lfoOsc.frequency.value = lfo.rate || 1;
                
                const lfoGain = audioContext.createGain();
                const depth = lfo.depth / 100;
                lfoGain.gain.value = depth * 1200; // Â±12 semitones in cents
                
                lfoOsc.connect(lfoGain);
                lfoGain.connect(osc1.detune);
                lfoGain.connect(osc2.detune);
                
                lfoOsc.start(now);
                lfoOsc.stop(now + duration + 0.5); // Stop after note ends
                
                console.log(`   ðŸŽ›ï¸ Real-time LFO ${i+1} connected: rate=${lfo.rate}Hz, depth=${depth * 12}st`);
            }
        });
    }
    
    // Match the volume levels used in normal playback (0.3 = 30%)
    osc1Gain.gain.value = (sd.osc1.level || 50) / 100 * 0.3;
    osc2Gain.gain.value = (sd.osc2.level || 50) / 100 * 0.3;
    
    // Reduce master gain to prevent clipping when both oscillators are active
    // Two oscillators at 50% each = 100%, which can clip with effects
    const masterVolumeReduction = 0.5; // Reduce to 50% to prevent clipping
    
    osc1.connect(osc1Gain);
    osc2.connect(osc2Gain);
    osc1Gain.connect(masterGain);
    osc2Gain.connect(masterGain);
    
    // Connect to master effects chain
    masterGain.connect(previewEqNodes.low);
    
    // Apply ADSR envelope
    const env = sd.envelope || { attack: 10, decay: 100, sustain: 70, release: 200 };
    const attackTime = env.attack / 1000;
    const decayTime = env.decay / 1000;
    const sustainLevel = env.sustain / 100;
    const releaseTime = env.release / 1000;
    const volumeMultiplier = (effects.volume || 100) / 100 * masterVolumeReduction;
    
    masterGain.gain.setValueAtTime(0, now);
    masterGain.gain.linearRampToValueAtTime(volumeMultiplier, now + attackTime);
    masterGain.gain.linearRampToValueAtTime(volumeMultiplier * sustainLevel, now + attackTime + decayTime);
    masterGain.gain.setValueAtTime(volumeMultiplier * sustainLevel, now + duration);
    masterGain.gain.linearRampToValueAtTime(0, now + duration + releaseTime);
    
    // Apply Envelope â†’ Pitch Modulation (if enabled)
    if (env.pitchMod && env.pitchMod.enabled && env.pitchMod.amount !== 0) {
        const pitchAmount = env.pitchMod.amount; // semitones
        const maxDetune = pitchAmount * 100; // cents (100 cents = 1 semitone)
        
        console.log(`ðŸŽµ PITCH MOD ACTIVE: amount=${pitchAmount} semitones, detune=${maxDetune} cents`);
        console.log(`   Base detune: osc1=${sd.osc1.detune || 0}, osc2=${sd.osc2.detune || 0}`);
        console.log(`   Attack time: ${attackTime}s`);
        
        // Apply pitch bend: Start at base+maxDetune, ramp down to base over attack time
        const osc1BaseDetune = sd.osc1.detune || 0;
        const osc2BaseDetune = sd.osc2.detune || 0;
        
        // Osc1 pitch envelope
        osc1.detune.setValueAtTime(osc1BaseDetune + maxDetune, now);
        osc1.detune.linearRampToValueAtTime(osc1BaseDetune, now + attackTime);
        
        // Osc2 pitch envelope
        osc2.detune.setValueAtTime(osc2BaseDetune + maxDetune, now);
        osc2.detune.linearRampToValueAtTime(osc2BaseDetune, now + attackTime);
        
        console.log(`   Pitch envelope: ${osc1BaseDetune + maxDetune} cents â†’ ${osc1BaseDetune} cents`);
    } else {
        console.log(`ðŸŽµ Pitch mod: ${env.pitchMod ? `enabled=${env.pitchMod.enabled}, amount=${env.pitchMod.amount}` : 'NOT DEFINED'}`);
    }
    
    // Start oscillators
    osc1.start(now);
    osc2.start(now);
    osc1.stop(now + duration + releaseTime);
    osc2.stop(now + duration + releaseTime);
    
    // Track for cleanup
    const voiceId = `voice_${Date.now()}_${Math.random()}`;
    pianoRollPreviewActiveVoices[voiceId] = { source: osc1, source2: osc2, gain: masterGain };
    
    osc1.onended = () => {
        try {
            osc1.disconnect();
            osc2.disconnect();
            osc1Gain.disconnect();
            osc2Gain.disconnect();
            masterGain.disconnect();
        } catch (e) {}
        delete pianoRollPreviewActiveVoices[voiceId];
    };
}

function hideEffectsPopup() {
    console.log('ðŸšª hideEffectsPopup() called');
    console.log('   effectsPopup element:', effectsPopup);
    console.log('   effectsPopup.style.display before:', effectsPopup ? effectsPopup.style.display : 'null');
    
    stopEffectsPreview(); // Stop preview playback
    stopWaveformAnimation(); // Stop EQ waveform animation
    
    // Log final state before closing
    if (currentClipForContext) {
        const clip = arrangementState.clips.find(c => c.id === currentClipForContext.id);
        if (clip && clip.effects) {
            console.log('ðŸšª Closing effects popup - Final saved effects:', {
                clipId: clip.id,
                lfos: clip.effects.lfos,
                automations: clip.effects.automations,
                volume: clip.effects.volume,
                speed: clip.effects.speed
            });
        } else {
            console.warn('âš ï¸ Closing effects popup - NO EFFECTS SAVED ON CLIP!', clip);
        }
    }
    
    if (effectsPopup) {
        effectsPopup.style.display = 'none';
        console.log('   effectsPopup.style.display after:', effectsPopup.style.display);
    } else {
        console.error('âŒ effectsPopup is null!');
    }
    
    currentClipForContext = null;
    currentClipEffects = null;
    originalClipEffects = null;
    
    console.log('âœ… hideEffectsPopup() completed');
}

function getDefaultEffects() {
    return {
        volume: 100,
        speed: 1,
        delay: {
            time: 0,
            feedback: 0
        },
        reverb: {
            decay: 0,
            predelay: 0,
            diffusion: 50,
            lowcut: 20,
            highcut: 20000,
            damping: 50,
            mix: 0
        },
        // EQ as ARRAY of points (matching PsychologicalStudio format)
        eq: [
            { frequency: 200, gain: 0, type: 'lowshelf', q: 1 },
            { frequency: 500, gain: 0, type: 'peaking', q: 1 },
            { frequency: 1500, gain: 0, type: 'peaking', q: 1 },
            { frequency: 4000, gain: 0, type: 'peaking', q: 1 },
            { frequency: 8000, gain: 0, type: 'highshelf', q: 1 }
        ],
        filter: {
            type: 'none',
            cutoff: 1000,
            resonance: 0
        },
        pitch: 0,
        // Legacy LFO/Automation for compatibility
        lfo: {
            enabled: false,
            target: 'filter',
            waveform: 'sine',
            rate: 1,
            depth: 0
        },
        automation: {
            enabled: false,
            target: 'volume',
            points: [
                { time: 0, value: 50 },
                { time: 1, value: 50 }
            ]
        },
        // Arrays for 4 LFOs and 4 Automations (PsychologicalStudio format)
        lfos: [
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 },
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 },
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 },
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 }
        ],
        automations: [
            { enabled: false, target: 'none', start: 50, end: 50, duration: 1, curve: 'linear' },
            { enabled: false, target: 'none', start: 50, end: 50, duration: 1, curve: 'linear' },
            { enabled: false, target: 'none', start: 50, end: 50, duration: 1, curve: 'linear' },
            { enabled: false, target: 'none', start: 50, end: 50, duration: 1, curve: 'linear' }
        ]
    };
}

function loadEffectsIntoControls(effects) {
    // Volume
    document.getElementById('arr-sample-volume').value = effects.volume || 100;
    document.getElementById('arr-sample-volume-value').textContent = `${effects.volume || 100}%`;
    
    // Speed
    document.getElementById('arr-speed-select').value = effects.speed || 1;
    
    // Delay
    document.getElementById('arr-delay-time').value = effects.delay.time || 0;
    document.getElementById('arr-delay-time-value').textContent = effects.delay.time || 0;
    document.getElementById('arr-delay-feedback').value = effects.delay.feedback || 0;
    document.getElementById('arr-delay-feedback-value').textContent = effects.delay.feedback || 0;
    
    // Reverb
    document.getElementById('arr-reverb-decay').value = effects.reverb.decay || 0;
    document.getElementById('arr-reverb-decay-value').textContent = effects.reverb.decay || 0;
    document.getElementById('arr-reverb-predelay').value = effects.reverb.predelay || 0;
    document.getElementById('arr-reverb-predelay-value').textContent = effects.reverb.predelay || 0;
    document.getElementById('arr-reverb-diffusion').value = effects.reverb.diffusion || 50;
    document.getElementById('arr-reverb-diffusion-value').textContent = effects.reverb.diffusion || 50;
    document.getElementById('arr-reverb-lowcut').value = effects.reverb.lowcut || 20;
    document.getElementById('arr-reverb-lowcut-value').textContent = effects.reverb.lowcut || 20;
    document.getElementById('arr-reverb-highcut').value = effects.reverb.highcut || 20000;
    document.getElementById('arr-reverb-highcut-value').textContent = effects.reverb.highcut || 20000;
    document.getElementById('arr-reverb-damping').value = effects.reverb.damping || 50;
    document.getElementById('arr-reverb-damping-value').textContent = effects.reverb.damping || 50;
    document.getElementById('arr-reverb-mix').value = effects.reverb.mix || 0;
    document.getElementById('arr-reverb-mix-value').textContent = effects.reverb.mix || 0;
    
    // NOTE: EQ is now handled by interactive canvas - no sliders to load
    
    // Filter
    document.getElementById('arr-filter-type').value = effects.filter.type || 'none';
    document.getElementById('arr-filter-cutoff').value = effects.filter.cutoff || 1000;
    document.getElementById('arr-filter-cutoff-value').textContent = effects.filter.cutoff || 1000;
    document.getElementById('arr-filter-resonance').value = effects.filter.resonance || 0;
    document.getElementById('arr-filter-resonance-value').textContent = effects.filter.resonance || 0;
    
    // NOTE: Pitch Shift section removed - use Speed or LFO Pitch instead
    
    // Load LFOs (4 independent LFOs)
    if (effects.lfos && Array.isArray(effects.lfos)) {
        for (let i = 0; i < 4; i++) {
            const lfo = effects.lfos[i] || { target: 'none', waveform: 'sine', rate: 1, depth: 0 };
            const lfoNum = i + 1;
            
            const targetEl = document.getElementById(`arr-lfo-${lfoNum}-target`);
            const waveformEl = document.getElementById(`arr-lfo-${lfoNum}-waveform`);
            const rateEl = document.getElementById(`arr-lfo-${lfoNum}-rate`);
            const depthEl = document.getElementById(`arr-lfo-${lfoNum}-depth`);
            
            if (targetEl) targetEl.value = lfo.target || 'none';
            if (waveformEl) waveformEl.value = lfo.waveform || 'sine';
            if (rateEl) {
                rateEl.value = lfo.rate || 1;
                document.getElementById(`arr-lfo-${lfoNum}-rate-value`).textContent = (lfo.rate || 1).toFixed(1);
            }
            if (depthEl) {
                depthEl.value = lfo.depth || 0;
                document.getElementById(`arr-lfo-${lfoNum}-depth-value`).textContent = `${lfo.depth || 0}%`;
            }
        }
    }
    
    // Load Automations (4 independent automations)
    if (effects.automations && Array.isArray(effects.automations)) {
        for (let i = 0; i < 4; i++) {
            const auto = effects.automations[i] || { target: 'none', start: 50, end: 50, duration: 1, curve: 'linear' };
            const autoNum = i + 1;
            
            const targetEl = document.getElementById(`arr-automation-${autoNum}-target`);
            const startEl = document.getElementById(`arr-automation-${autoNum}-start`);
            const endEl = document.getElementById(`arr-automation-${autoNum}-end`);
            const durationEl = document.getElementById(`arr-automation-${autoNum}-duration`);
            const curveEl = document.getElementById(`arr-automation-${autoNum}-curve`);
            
            if (targetEl) targetEl.value = auto.target || 'none';
            if (startEl) {
                startEl.value = auto.start !== undefined ? auto.start : 50;
                document.getElementById(`arr-automation-${autoNum}-start-value`).textContent = startEl.value;
            }
            if (endEl) {
                endEl.value = auto.end !== undefined ? auto.end : 50;
                document.getElementById(`arr-automation-${autoNum}-end-value`).textContent = endEl.value;
            }
            if (durationEl) {
                durationEl.value = auto.duration !== undefined ? auto.duration : 1;
                document.getElementById(`arr-automation-${autoNum}-duration-value`).textContent = durationEl.value;
            }
            if (curveEl) curveEl.value = auto.curve || 'linear';
        }
    }
}

// Apply effects in real-time while adjusting (for live preview during playback)
function applyEffectsRealTime() {
    if (!currentClipForContext || !currentClipEffects) {
        return;
    }
    
    // Update the clip's effects in the arrangement state immediately
    const clip = arrangementState.clips.find(c => c.id === currentClipForContext.id);
    if (clip) {
        clip.effects = JSON.parse(JSON.stringify(currentClipEffects));
        console.log('ðŸ’¾ Effects saved to clip:', clip.id);
        console.log('   LFOs:', clip.effects.lfos);
        console.log('   Automations:', clip.effects.automations);
    }
    
    // Update preview playback in real-time
    updatePreviewEffects();
}

function setupEffectsControls() {
    // Volume
    const volumeSlider = document.getElementById('arr-sample-volume');
    const volumeValue = document.getElementById('arr-sample-volume-value');
    volumeSlider.oninput = () => {
        const val = volumeSlider.value;
        volumeValue.textContent = `${val}%`;
        if (currentClipEffects) {
            currentClipEffects.volume = +val;
            applyEffectsRealTime();
        }
    };
    
    // Speed
    const speedSelect = document.getElementById('arr-speed-select');
    speedSelect.onchange = () => {
        if (currentClipEffects) {
            currentClipEffects.speed = +speedSelect.value;
            applyEffectsRealTime();
            
            // Speed change requires restarting the audio source with new playbackRate
            if (currentClipForContext) {
                console.log('ðŸ”„ Speed changed, restarting preview...');
                startEffectsPreview(currentClipForContext);
            }
        }
    };
    
    // Delay Time
    const delayTimeSlider = document.getElementById('arr-delay-time');
    const delayTimeValue = document.getElementById('arr-delay-time-value');
    delayTimeSlider.oninput = () => {
        const val = delayTimeSlider.value;
        delayTimeValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.delay.time = +val;
            applyEffectsRealTime();
        }
    };
    
    // Delay Feedback
    const delayFeedbackSlider = document.getElementById('arr-delay-feedback');
    const delayFeedbackValue = document.getElementById('arr-delay-feedback-value');
    delayFeedbackSlider.oninput = () => {
        const val = delayFeedbackSlider.value;
        delayFeedbackValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.delay.feedback = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb Decay
    const reverbDecaySlider = document.getElementById('arr-reverb-decay');
    const reverbDecayValue = document.getElementById('arr-reverb-decay-value');
    reverbDecaySlider.oninput = () => {
        const val = reverbDecaySlider.value;
        reverbDecayValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.decay = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb Predelay
    const reverbPredelaySlider = document.getElementById('arr-reverb-predelay');
    const reverbPredelayValue = document.getElementById('arr-reverb-predelay-value');
    reverbPredelaySlider.oninput = () => {
        const val = reverbPredelaySlider.value;
        reverbPredelayValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.predelay = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb Diffusion
    const reverbDiffusionSlider = document.getElementById('arr-reverb-diffusion');
    const reverbDiffusionValue = document.getElementById('arr-reverb-diffusion-value');
    reverbDiffusionSlider.oninput = () => {
        const val = reverbDiffusionSlider.value;
        reverbDiffusionValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.diffusion = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb Low Cut
    const reverbLowcutSlider = document.getElementById('arr-reverb-lowcut');
    const reverbLowcutValue = document.getElementById('arr-reverb-lowcut-value');
    reverbLowcutSlider.oninput = () => {
        const val = reverbLowcutSlider.value;
        reverbLowcutValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.lowcut = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb High Cut
    const reverbHighcutSlider = document.getElementById('arr-reverb-highcut');
    const reverbHighcutValue = document.getElementById('arr-reverb-highcut-value');
    reverbHighcutSlider.oninput = () => {
        const val = reverbHighcutSlider.value;
        reverbHighcutValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.highcut = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb Damping
    const reverbDampingSlider = document.getElementById('arr-reverb-damping');
    const reverbDampingValue = document.getElementById('arr-reverb-damping-value');
    reverbDampingSlider.oninput = () => {
        const val = reverbDampingSlider.value;
        reverbDampingValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.damping = +val;
            applyEffectsRealTime();
        }
    };
    
    // Reverb Mix
    const reverbMixSlider = document.getElementById('arr-reverb-mix');
    const reverbMixValue = document.getElementById('arr-reverb-mix-value');
    reverbMixSlider.oninput = () => {
        const val = reverbMixSlider.value;
        reverbMixValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.reverb.mix = +val;
            applyEffectsRealTime();
        }
    };
    
    // Filter Type
    const filterTypeSelect = document.getElementById('arr-filter-type');
    filterTypeSelect.onchange = () => {
        if (currentClipEffects) {
            currentClipEffects.filter.type = filterTypeSelect.value;
            applyEffectsRealTime();
        }
    };
    
    // Filter Cutoff
    const filterCutoffSlider = document.getElementById('arr-filter-cutoff');
    const filterCutoffValue = document.getElementById('arr-filter-cutoff-value');
    filterCutoffSlider.oninput = () => {
        const val = filterCutoffSlider.value;
        filterCutoffValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.filter.cutoff = +val;
            applyEffectsRealTime();
        }
    };
    
    // Filter Resonance
    const filterResonanceSlider = document.getElementById('arr-filter-resonance');
    const filterResonanceValue = document.getElementById('arr-filter-resonance-value');
    filterResonanceSlider.oninput = () => {
        const val = filterResonanceSlider.value;
        filterResonanceValue.textContent = val;
        if (currentClipEffects) {
            currentClipEffects.filter.resonance = +val;
            applyEffectsRealTime();
        }
    };
    
    // NOTE: Old EQ sliders removed - now using interactive canvas
    // EQ is handled by initVisualEQ() and drag handlers
    
    // NOTE: Old single LFO/Automation controls removed - now using tabbed LFO MODULATORS system
    // Event listeners for LFO 1-4 and Automation 1-4 should be set up separately if needed
    
    // NOTE: Pitch Shift section removed - use Speed or LFO Pitch instead
    
    console.log('âœ… Effects controls setup complete');
}

// LFO TAB SWITCHING (Legacy - kept for compatibility)
function setupLFOTabs() {
    const tabs = document.querySelectorAll('.lfo-tab');
    const panels = document.querySelectorAll('.lfo-panel');
    
    tabs.forEach(tab => {
        tab.addEventListener('click', () => {
            const lfoNum = tab.dataset.lfo;
            
            // Remove active from all tabs and panels
            tabs.forEach(t => t.classList.remove('active'));
            panels.forEach(p => p.classList.remove('active'));
            
            // Activate clicked tab and corresponding panel
            tab.classList.add('active');
            document.getElementById(`arr-lfo-panel-${lfoNum}`).classList.add('active');
        });
    });
}

// AUTOMATION TAB SWITCHING
function setupAutomationTabs() {
    const tabs = document.querySelectorAll('.automation-tab');
    const panels = document.querySelectorAll('.automation-panel');
    
    tabs.forEach(tab => {
        tab.addEventListener('click', () => {
            const autoNum = tab.dataset.automation;
            
            // Remove active from all tabs and panels
            tabs.forEach(t => t.classList.remove('active'));
            panels.forEach(p => p.classList.remove('active'));
            
            // Activate clicked tab and corresponding panel
            tab.classList.add('active');
            document.getElementById(`arr-automation-panel-${autoNum}`).classList.add('active');
        });
    });
}

// DRAW LFO WAVEFORM
function drawLFOWaveform(lfoIndex) {
    const canvas = document.getElementById(`arr-lfo-${lfoIndex}-wave`);
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    const centerY = height / 2;
    
    // Clear canvas
    ctx.fillStyle = '#0a0a0a';
    ctx.fillRect(0, 0, width, height);
    
    // Get LFO settings
    const waveform = document.getElementById(`arr-lfo-${lfoIndex}-waveform`).value;
    const depth = parseFloat(document.getElementById(`arr-lfo-${lfoIndex}-depth`).value);
    
    if (depth === 0) return; // Don't draw if depth is 0
    
    // Draw grid
    ctx.strokeStyle = '#222';
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(0, centerY);
    ctx.lineTo(width, centerY);
    ctx.stroke();
    
    // Draw waveform
    ctx.strokeStyle = '#533483';
    ctx.lineWidth = 2;
    ctx.beginPath();
    
    const amplitude = (height / 2) * (depth / 100);
    const cycles = 2; // Show 2 cycles
    
    for (let x = 0; x < width; x++) {
        const phase = (x / width) * cycles * Math.PI * 2;
        let y;
        
        switch(waveform) {
            case 'sine':
                y = centerY - Math.sin(phase) * amplitude;
                break;
            case 'square':
                y = centerY - (Math.sin(phase) > 0 ? amplitude : -amplitude);
                break;
            case 'triangle':
                y = centerY - ((2 / Math.PI) * Math.asin(Math.sin(phase))) * amplitude;
                break;
            case 'sawtooth':
                y = centerY - ((phase % (Math.PI * 2)) / (Math.PI * 2) * 2 - 1) * amplitude;
                break;
            default:
                y = centerY;
        }
        
        if (x === 0) {
            ctx.moveTo(x, y);
        } else {
            ctx.lineTo(x, y);
        }
    }
    
    ctx.stroke();
}

// DRAW AUTOMATION CURVE
function drawAutomationCurve(autoIndex) {
    const canvas = document.getElementById(`arr-automation-${autoIndex}-canvas`);
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    
    // Clear canvas
    ctx.fillStyle = '#0a0a0a';
    ctx.fillRect(0, 0, width, height);
    
    // Get automation settings
    const startVal = parseFloat(document.getElementById(`arr-automation-${autoIndex}-start`).value);
    const endVal = parseFloat(document.getElementById(`arr-automation-${autoIndex}-end`).value);
    const curve = document.getElementById(`arr-automation-${autoIndex}-curve`).value;
    
    // Draw grid
    ctx.strokeStyle = '#222';
    ctx.lineWidth = 1;
    for (let i = 0; i <= 4; i++) {
        const y = (height / 4) * i;
        ctx.beginPath();
        ctx.moveTo(0, y);
        ctx.lineTo(width, y);
        ctx.stroke();
    }
    
    // Draw automation curve
    ctx.strokeStyle = '#533483';
    ctx.lineWidth = 2;
    ctx.beginPath();
    
    for (let x = 0; x < width; x++) {
        const t = x / width; // 0 to 1
        let value;
        
        switch(curve) {
            case 'linear':
                value = startVal + (endVal - startVal) * t;
                break;
            case 'exponential':
                value = startVal + (endVal - startVal) * (t * t);
                break;
            case 'logarithmic':
                value = startVal + (endVal - startVal) * Math.sqrt(t);
                break;
            default:
                value = startVal + (endVal - startVal) * t;
        }
        
        const y = height - (value / 100) * height;
        
        if (x === 0) {
            ctx.moveTo(x, y);
        } else {
            ctx.lineTo(x, y);
        }
    }
    
    ctx.stroke();
    
    // Draw start and end points
    ctx.fillStyle = '#6644a0';
    const startY = height - (startVal / 100) * height;
    const endY = height - (endVal / 100) * height;
    ctx.beginPath();
    ctx.arc(0, startY, 4, 0, Math.PI * 2);
    ctx.fill();
    ctx.beginPath();
    ctx.arc(width, endY, 4, 0, Math.PI * 2);
    ctx.fill();
}

// SETUP ALL LFO LISTENERS
function setupAllLFOListeners() {
    for (let i = 1; i <= 4; i++) {
        // Target
        const target = document.getElementById(`arr-lfo-${i}-target`);
        target.addEventListener('change', () => {
            if (currentClipEffects) {
                currentClipEffects.lfos[i-1].target = target.value;
            }
        });
        
        // Waveform
        const waveform = document.getElementById(`arr-lfo-${i}-waveform`);
        waveform.addEventListener('change', () => {
            if (currentClipEffects) {
                currentClipEffects.lfos[i-1].waveform = waveform.value;
            }
            drawLFOWaveform(i);
        });
        
        // Rate
        const rate = document.getElementById(`arr-lfo-${i}-rate`);
        const rateValue = document.getElementById(`arr-lfo-${i}-rate-value`);
        rate.addEventListener('input', () => {
            const val = parseFloat(rate.value);
            rateValue.textContent = val.toFixed(1);
            if (currentClipEffects) {
                currentClipEffects.lfos[i-1].rate = val;
            }
        });
        
        // Depth
        const depth = document.getElementById(`arr-lfo-${i}-depth`);
        const depthValue = document.getElementById(`arr-lfo-${i}-depth-value`);
        depth.addEventListener('input', () => {
            const val = parseInt(depth.value);
            depthValue.textContent = `${val}%`;
            if (currentClipEffects) {
                currentClipEffects.lfos[i-1].depth = val;
            }
            drawLFOWaveform(i);
        });
    }
}

// SETUP ALL AUTOMATION LISTENERS
function setupAllAutomationListeners() {
    for (let i = 1; i <= 4; i++) {
        // Target
        const target = document.getElementById(`arr-automation-${i}-target`);
        target.addEventListener('change', () => {
            if (currentClipEffects) {
                currentClipEffects.automations[i-1].target = target.value;
            }
        });
        
        // Start
        const start = document.getElementById(`arr-automation-${i}-start`);
        const startValue = document.getElementById(`arr-automation-${i}-start-value`);
        start.addEventListener('input', () => {
            const val = parseInt(start.value);
            startValue.textContent = val;
            if (currentClipEffects) {
                currentClipEffects.automations[i-1].start = val;
            }
            drawAutomationCurve(i);
        });
        
        // End
        const end = document.getElementById(`arr-automation-${i}-end`);
        const endValue = document.getElementById(`arr-automation-${i}-end-value`);
        end.addEventListener('input', () => {
            const val = parseInt(end.value);
            endValue.textContent = val;
            if (currentClipEffects) {
                currentClipEffects.automations[i-1].end = val;
            }
            drawAutomationCurve(i);
        });
        
        // Duration
        const duration = document.getElementById(`arr-automation-${i}-duration`);
        const durationValue = document.getElementById(`arr-automation-${i}-duration-value`);
        duration.addEventListener('input', () => {
            const val = parseInt(duration.value);
            durationValue.textContent = val;
            if (currentClipEffects) {
                currentClipEffects.automations[i-1].duration = val;
            }
        });
        
        // Curve
        const curve = document.getElementById(`arr-automation-${i}-curve`);
        curve.addEventListener('change', () => {
            if (currentClipEffects) {
                currentClipEffects.automations[i-1].curve = curve.value;
            }
            drawAutomationCurve(i);
        });
    }
}

function applyEffects() {
    console.log('ðŸŽ¯ applyEffects() called');
    console.log('  currentClipForContext:', currentClipForContext);
    console.log('  currentClipEffects:', currentClipEffects);
    
    if (!currentClipForContext || !currentClipEffects) {
        console.warn('âš ï¸ No clip or effects to apply');
        return;
    }
    
    // Find the actual clip in the state and update its effects
    const clip = arrangementState.clips.find(c => c.id === currentClipForContext.id);
    console.log('  Found clip in state:', clip);
    
    if (clip) {
        const effectsToSave = JSON.parse(JSON.stringify(currentClipEffects));
        // Always save the full EQ array for persistence and playback
        if (effectsToSave.eq && Array.isArray(effectsToSave.eq)) {
            // Save both array and object for compatibility
            const eqObj = {
                low: 0,
                lowmid: 0,
                mid: 0,
                highmid: 0,
                high: 0
            };
            effectsToSave.eq.forEach(point => {
                if (Math.abs(point.frequency - 200) < 1) eqObj.low = point.gain;
                else if (Math.abs(point.frequency - 500) < 1) eqObj.lowmid = point.gain;
                else if (Math.abs(point.frequency - 1500) < 1) eqObj.mid = point.gain;
                else if (Math.abs(point.frequency - 4000) < 1) eqObj.highmid = point.gain;
                else if (Math.abs(point.frequency - 8000) < 1) eqObj.high = point.gain;
            });
            effectsToSave.eqObject = eqObj; // Save object for legacy compatibility
        }
        // Save to clip
        clip.effects = JSON.parse(JSON.stringify(effectsToSave));
        console.log('âœ… Effects applied to clip:', clip.id, clip.effects);
        // If this is a pattern clip, also update the pattern's effects and pianoRollData
        if (clip.type === 'pattern' && arrangementState.patterns[clip.data]) {
            arrangementState.patterns[clip.data].effects = JSON.parse(JSON.stringify(effectsToSave));
            console.log('âœ… Effects also applied to pattern:', clip.data, arrangementState.patterns[clip.data].effects);
            if (pianoRollData[clip.data]) {
                pianoRollData[clip.data].effects = JSON.parse(JSON.stringify(effectsToSave));
                console.log('âœ… Effects also applied to pianoRollData:', clip.data, pianoRollData[clip.data].effects);
            }
        }
        saveArrangement(false);
    } else {
        console.error('âŒ Could not find clip in arrangement state');
    }
    
    console.log('ðŸ”’ Calling hideEffectsPopup()');
    hideEffectsPopup();
    // After applying, refresh preview to use latest pattern.effects
    if (currentClipForContext && currentClipForContext.type === 'pattern') {
        setTimeout(() => {
            startPatternEffectsPreview(currentClipForContext);
        }, 100);
        // Patch: Force arrangement playback to reload updated pattern effects
        if (arrangementState.isPlaying) {
            console.log('ðŸ”„ Rescheduling arrangement playback to apply new effects...');
            stopArrangementPlayback();
            setTimeout(() => {
                startArrangementPlayback();
            }, 200);
        }
    }
}

function resetEffects() {
    console.log('ðŸ”„ resetEffects() called');
    console.log('  currentClipForContext:', currentClipForContext);
    
    if (!currentClipForContext) {
        console.warn('âš ï¸ No clip to reset effects for');
        return;
    }
    
    // Reset to default effects
    const defaultEffects = getDefaultEffects();
    currentClipEffects = JSON.parse(JSON.stringify(defaultEffects));
    console.log('  Loading default effects into controls');
    loadEffectsIntoControls(currentClipEffects);
    
    console.log('âœ… Effects reset to default');
}

function openPatternEditor(clip) {
    console.log('ðŸŽ¹ openPatternEditor called with clip:', clip);
    
    if (clip.type !== 'pattern') {
        console.warn('âš ï¸ Clip is not a pattern, type:', clip.type);
        return;
    }
    
    const pattern = arrangementState.patterns[clip.data];
    if (!pattern) {
        console.warn('âš ï¸ Pattern not found:', clip.data);
        console.log('Available patterns:', Object.keys(arrangementState.patterns));
        return;
    }
    
    console.log('ðŸ“‚ Pattern found:', pattern);
    
    // Set current sample for popup (needed for initPianoRoll)
    currentSampleForPopup = clip.data;
    
    // Set pattern name in input
    const nameInput = document.getElementById('pattern-name-input');
    if (nameInput) {
        nameInput.value = clip.data;
    }
    
    // Initialize piano roll data for this pattern
    if (!pianoRollData[clip.data]) {
        pianoRollData[clip.data] = {
            notes: pattern.notes || [],
            gridWidth: pattern.gridWidth || 16,
            soundSource: pattern.soundSource || 'synth',
            soundDesign: pattern.soundDesign || {
                osc1: { wave: 'sine', detune: 0, level: 50 },
                osc2: { wave: 'sawtooth', detune: 0, level: 50 },
                filter: { type: 'lowpass', cutoff: 2000, resonance: 0 },
                envelope: { 
                    attack: 10, 
                    decay: 100, 
                    sustain: 70, 
                    release: 200,
                    pitchMod: { enabled: false, amount: 0 }
                }
            }
        };
    } else {
        // Update with latest pattern data
        pianoRollData[clip.data].notes = pattern.notes || [];
        pianoRollData[clip.data].gridWidth = pattern.gridWidth || 16;
        pianoRollData[clip.data].soundSource = pattern.soundSource || 'synth';
        pianoRollData[clip.data].soundDesign = pattern.soundDesign;
        
        // Ensure pitchMod exists in envelope
        if (pianoRollData[clip.data].soundDesign && pianoRollData[clip.data].soundDesign.envelope) {
            if (!pianoRollData[clip.data].soundDesign.envelope.pitchMod) {
                pianoRollData[clip.data].soundDesign.envelope.pitchMod = { enabled: false, amount: 0 };
            }
        }
    }
    
    // Open the pattern editor popup with this pattern's data
    // Use classList.add('active') to match the save/cancel button behavior
    patternEditorPopup.classList.add('active');
    isEditingPattern = true;
    currentEditingPatternName = clip.data;
    
    console.log('âœ… Pattern editor popup opened with active class');
    
    // Load pattern data into editor
    pianoRollNotes = JSON.parse(JSON.stringify(pattern.notes || []));
    pianoRollGridWidth = pattern.gridWidth || 16;
    
    // Update sound source
    const soundSourceSelect = document.getElementById('piano-roll-sound-source');
    if (soundSourceSelect) {
        soundSourceSelect.value = pattern.soundSource || 'synth';
    }
    
    // Load sound design if available
    if (pattern.soundDesign) {
        loadSoundDesignControls(pattern.soundDesign);
    }
    
    // Initialize piano roll and visualizer
    initPianoRoll();
    initPianoRollVisualizer();
    
    // Trigger sound source change to ensure ADSR canvas is drawn
    setTimeout(() => {
        if (soundSourceSelect) {
            soundSourceSelect.dispatchEvent(new Event('change'));
        }
    }, 100);
    
    console.log('âœï¸ Editing pattern:', clip.data);
}

function loadSoundDesignControls(sd) {
    if (!sd) {
        console.warn('âš ï¸ No sound design data to load');
        return;
    }
    
    console.log('ðŸŽ›ï¸ Loading sound design controls:', sd);
    
    // Helper function to safely set element value
    const safeSetValue = (id, value) => {
        const el = document.getElementById(id);
        if (el) {
            if (el.tagName === 'INPUT' || el.tagName === 'SELECT') {
                el.value = value;
            } else {
                el.textContent = value;
            }
        } else {
            console.warn(`âš ï¸ Element not found: ${id}`);
        }
    };
    
    // Load oscillator 1 settings
    if (sd.osc1) {
        safeSetValue('sd-osc1-wave', sd.osc1.wave);
        safeSetValue('sd-osc1-detune', sd.osc1.detune);
        safeSetValue('sd-osc1-detune-val', sd.osc1.detune);
        safeSetValue('sd-osc1-level', sd.osc1.level);
        safeSetValue('sd-osc1-level-val', sd.osc1.level + '%');
    }
    
    // Load oscillator 2 settings
    if (sd.osc2) {
        safeSetValue('sd-osc2-wave', sd.osc2.wave);
        safeSetValue('sd-osc2-detune', sd.osc2.detune);
        safeSetValue('sd-osc2-detune-val', sd.osc2.detune);
        safeSetValue('sd-osc2-level', sd.osc2.level);
        safeSetValue('sd-osc2-level-val', sd.osc2.level + '%');
    }
    
    // Load filter settings
    if (sd.filter) {
        safeSetValue('sd-filter-type', sd.filter.type);
        safeSetValue('sd-filter-cutoff', sd.filter.cutoff);
        safeSetValue('sd-filter-cutoff-val', sd.filter.cutoff + ' Hz');
        safeSetValue('sd-filter-resonance', sd.filter.resonance);
        safeSetValue('sd-filter-resonance-val', sd.filter.resonance);
    }
    
    // Load envelope settings
    if (sd.envelope) {
        safeSetValue('sd-env-attack', sd.envelope.attack);
        safeSetValue('sd-env-attack-val', sd.envelope.attack + ' ms');
        safeSetValue('sd-env-decay', sd.envelope.decay);
        safeSetValue('sd-env-decay-val', sd.envelope.decay + ' ms');
        safeSetValue('sd-env-sustain', sd.envelope.sustain);
        safeSetValue('sd-env-sustain-val', sd.envelope.sustain + '%');
        safeSetValue('sd-env-release', sd.envelope.release);
        safeSetValue('sd-env-release-val', sd.envelope.release + ' ms');
        
        // Load pitch modulation settings
        if (sd.envelope.pitchMod) {
            const pitchEnable = document.getElementById('sd-env-pitch-enable');
            const pitchAmount = document.getElementById('sd-env-pitch-amount');
            const pitchAmountVal = document.getElementById('sd-env-pitch-amount-val');
            
            if (pitchEnable) {
                pitchEnable.checked = sd.envelope.pitchMod.enabled || false;
            }
            if (pitchAmount) {
                pitchAmount.value = sd.envelope.pitchMod.amount || 0;
            }
            if (pitchAmountVal) {
                pitchAmountVal.textContent = (sd.envelope.pitchMod.amount || 0) + '';
            }
        }
    }
    
    // Redraw ADSR canvas after loading
    setTimeout(() => {
        drawADSRCanvas();
    }, 100);
    
    console.log('âœ… Sound design controls loaded');
}

// ========================================
// INTERACTIVE EQ SYSTEM
// Copied from PsychologicalStudio
// ========================================

// Interpolate gain using Catmull-Rom spline
function interpolateGainSpline(frequency, sortedPoints) {
    if (sortedPoints.length === 0) return 0;
    if (sortedPoints.length === 1) return sortedPoints[0].gain;
    
    const logPoints = sortedPoints.map(p => ({
        x: Math.log10(p.frequency),
        y: p.gain
    }));
    
    const x = Math.log10(frequency);
    
    if (x <= logPoints[0].x) return logPoints[0].y;
    if (x >= logPoints[logPoints.length - 1].x) return logPoints[logPoints.length - 1].y;
    
    let i = 0;
    for (i = 0; i < logPoints.length - 1; i++) {
        if (x >= logPoints[i].x && x <= logPoints[i + 1].x) {
            break;
        }
    }
    
    const p0 = logPoints[Math.max(0, i - 1)];
    const p1 = logPoints[i];
    const p2 = logPoints[i + 1];
    const p3 = logPoints[Math.min(logPoints.length - 1, i + 2)];
    
    const t = (x - p1.x) / (p2.x - p1.x);
    const t2 = t * t;
    const t3 = t2 * t;
    
    return 0.5 * (
        2 * p1.y +
        (-p0.y + p2.y) * t +
        (2 * p0.y - 5 * p1.y + 4 * p2.y - p3.y) * t2 +
        (-p0.y + 3 * p1.y - 3 * p2.y + p3.y) * t3
    );
}

// Add a new EQ point
function addEQPoint(frequency, gain) {
    if (!currentClipEffects || !currentClipEffects.eq) return null;
    
    // Check if we already have an EQ array structure
    if (!Array.isArray(currentClipEffects.eq)) {
        // Convert from object structure to array structure
        currentClipEffects.eq = [];
    }
    
    if (currentClipEffects.eq.length >= MAX_EQ_POINTS) return null;
    if (frequency <= 20 || frequency >= 20000) return null;
    
    let type = "peaking";
    if (frequency < 200) type = "lowshelf";
    else if (frequency > 8000) type = "highshelf";
    
    const newPoint = {
        frequency: frequency,
        gain: gain,
        q: 1,
        type: type
    };
    
    currentClipEffects.eq.push(newPoint);
    currentClipEffects.eq.sort((a, b) => a.frequency - b.frequency);
    
    updatePreviewEffects();
    drawEQVisual();
    
    return newPoint;
}

// Initialize visual EQ canvas
function initVisualEQ() {
    eqCanvas = document.getElementById("arr-eq-canvas");
    if (!eqCanvas) {
        console.warn('âš ï¸ EQ canvas not found');
        return;
    }
    
    eqCtx = eqCanvas.getContext("2d");
    const container = eqCanvas.parentElement;
    eqCanvas.width = container.clientWidth;
    eqCanvas.height = container.clientHeight;
    
    drawEQVisual();
    
    // Add event listeners
    eqCanvas.addEventListener("mousedown", startDraggingEQBand);
    eqCanvas.addEventListener("mousemove", dragEQBand);
    eqCanvas.addEventListener("mouseup", stopDraggingEQBand);
    eqCanvas.addEventListener("mouseleave", stopDraggingEQBand);
    eqCanvas.addEventListener("touchstart", handleEQTouchStart);
    eqCanvas.addEventListener("touchmove", handleEQTouchMove);
    eqCanvas.addEventListener("touchend", stopDraggingEQBand);
    
    initWaveformVisualization();
}

// Initialize waveform visualization
function initWaveformVisualization() {
    if (!previewGainNode) return;
    
    if (!waveformAnalyzer) {
        waveformAnalyzer = audioContext.createAnalyser();
        waveformAnalyzer.fftSize = 4096;
        waveformAnalyzer.smoothingTimeConstant = 0.7;
        
        // Connect to preview output
        if (previewGainNode) {
            previewGainNode.disconnect();
            previewGainNode.connect(waveformAnalyzer);
            waveformAnalyzer.connect(audioContext.destination);
        }
    }
    
    startWaveformAnimation();
}

// Start waveform animation
function startWaveformAnimation() {
    if (waveformAnimationId) {
        cancelAnimationFrame(waveformAnimationId);
    }
    
    const bufferLength = waveformAnalyzer.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    
    function animate() {
        waveformAnimationId = requestAnimationFrame(animate);
        waveformAnalyzer.getByteFrequencyData(dataArray);
        
        waveformHistory.push([...dataArray]);
        if (waveformHistory.length > waveformHistorySize) {
            waveformHistory.shift();
        }
        
        drawEQVisual();
    }
    
    animate();
}

// Stop waveform animation
function stopWaveformAnimation() {
    if (waveformAnimationId) {
        cancelAnimationFrame(waveformAnimationId);
        waveformAnimationId = null;
    }
    waveformHistory = [];
    if (eqCanvas) {
        drawEQVisual();
    }
}

// Draw EQ visual
function drawEQVisual() {
    if (!eqCanvas || !eqCtx) return;
    
    const width = eqCanvas.width;
    const height = eqCanvas.height;
    const padding = 20;
    
    // Clear canvas
    eqCtx.fillStyle = "#0a0a0f";
    eqCtx.fillRect(0, 0, width, height);
    
    // Draw grid
    eqCtx.strokeStyle = "#1a1a2e";
    eqCtx.lineWidth = 1;
    
    // Horizontal lines
    for (let i = 0; i <= 4; i++) {
        const y = padding + (i * (height - 2 * padding) / 4);
        eqCtx.beginPath();
        eqCtx.moveTo(padding, y);
        eqCtx.lineTo(width - padding, y);
        eqCtx.stroke();
    }
    
    // Vertical lines
    for (let i = 0; i <= 4; i++) {
        const x = padding + (i * (width - 2 * padding) / 4);
        eqCtx.beginPath();
        eqCtx.moveTo(x, padding);
        eqCtx.lineTo(x, height - padding);
        eqCtx.stroke();
    }
    
    // Draw 0dB line
    eqCtx.strokeStyle = "#333";
    eqCtx.lineWidth = 1;
    eqCtx.setLineDash([5, 3]);
    const zeroDbY = height / 2;
    eqCtx.beginPath();
    eqCtx.moveTo(padding, zeroDbY);
    eqCtx.lineTo(width - padding, zeroDbY);
    eqCtx.stroke();
    eqCtx.setLineDash([]);
    
    // Draw waveform if available
    if (waveformHistory.length > 0) {
        drawEQWaveform();
    }
    
    // Draw EQ curve
    if (!currentClipEffects || !currentClipEffects.eq) return;
    
    // Handle both object and array EQ structures
    let eqPoints = [];
    if (Array.isArray(currentClipEffects.eq)) {
        eqPoints = currentClipEffects.eq;
    } else {
        // Convert object structure to points for visualization
        // This is for backward compatibility
        const eq = currentClipEffects.eq;
        if (eq.low !== undefined && eq.low !== 0) {
            eqPoints.push({ frequency: 200, gain: eq.low, type: 'lowshelf', q: 1 });
        }
        if (eq.lowmid !== undefined && eq.lowmid !== 0) {
            eqPoints.push({ frequency: 500, gain: eq.lowmid, type: 'peaking', q: 1 });
        }
        if (eq.mid !== undefined && eq.mid !== 0) {
            eqPoints.push({ frequency: 1500, gain: eq.mid, type: 'peaking', q: 1 });
        }
        if (eq.highmid !== undefined && eq.highmid !== 0) {
            eqPoints.push({ frequency: 4000, gain: eq.highmid, type: 'peaking', q: 1 });
        }
        if (eq.high !== undefined && eq.high !== 0) {
            eqPoints.push({ frequency: 8000, gain: eq.high, type: 'highshelf', q: 1 });
        }
    }
    
    const sortedPoints = [...eqPoints].sort((a, b) => a.frequency - b.frequency);
    
    // Draw curve
    eqCtx.strokeStyle = "#4CAF50";
    eqCtx.lineWidth = 4;
    eqCtx.shadowColor = "rgba(76, 175, 80, 0.8)";
    eqCtx.shadowBlur = 8;
    eqCtx.beginPath();
    
    const numPoints = 200;
    for (let i = 0; i <= numPoints; i++) {
        const x = padding + (i * (width - 2 * padding) / numPoints);
        const freq = 20 * Math.pow(20000 / 20, (x - padding) / (width - 2 * padding));
        let gain = interpolateGainSpline(freq, sortedPoints);
        const y = height / 2 - (gain / 24) * (height / 2 - padding);
        
        if (i === 0) {
            eqCtx.moveTo(x, y);
        } else {
            eqCtx.lineTo(x, y);
        }
    }
    
    eqCtx.stroke();
    eqCtx.shadowBlur = 0;
    
    // Draw EQ points
    for (let i = 0; i < eqPoints.length; i++) {
        const point = eqPoints[i];
        const x = padding + (Math.log10(point.frequency / 20) / Math.log10(20000 / 20)) * (width - 2 * padding);
        const y = height / 2 - (point.gain / 24) * (height / 2 - padding);
        
        // Point color
        if (point.fixed) {
            eqCtx.fillStyle = "#FFC107";
            eqCtx.shadowColor = "rgba(255, 193, 7, 0.8)";
        } else {
            eqCtx.fillStyle = (point === draggedPoint) ? "#FF5722" : "#4CAF50";
            eqCtx.shadowColor = (point === draggedPoint) ? "rgba(255, 87, 34, 0.8)" : "rgba(76, 175, 80, 0.8)";
        }
        
        eqCtx.shadowBlur = 15;
        eqCtx.beginPath();
        eqCtx.arc(x, y, 9, 0, Math.PI * 2);
        eqCtx.fill();
        
        // Inner circle
        eqCtx.fillStyle = "#fff";
        eqCtx.shadowBlur = 0;
        eqCtx.beginPath();
        eqCtx.arc(x, y, 6, 0, Math.PI * 2);
        eqCtx.fill();
        
        // Frequency label
        eqCtx.fillStyle = "rgba(0, 0, 0, 0.7)";
        eqCtx.fillRect(x - 25, y + 20, 50, 15);
        eqCtx.fillStyle = "#fff";
        eqCtx.font = "bold 10px Arial";
        eqCtx.textAlign = "center";
        
        let freqLabel;
        if (point.frequency < 1000) {
            freqLabel = `${Math.round(point.frequency)}Hz`;
        } else {
            const kHzValue = point.frequency / 1000;
            if (kHzValue === Math.round(kHzValue)) {
                freqLabel = `${Math.round(kHzValue)}k`;
            } else {
                freqLabel = `${kHzValue.toFixed(1)}k`;
            }
        }
        eqCtx.fillText(freqLabel, x, y + 30);
        
        // Gain label
        eqCtx.fillStyle = "rgba(0, 0, 0, 0.7)";
        eqCtx.fillRect(x - 25, y - 35, 50, 15);
        eqCtx.fillStyle = "#fff";
        eqCtx.fillText(`${point.gain > 0 ? '+' : ''}${point.gain.toFixed(1)}dB`, x, y - 25);
    }
}

// Draw EQ waveform visualization
function drawEQWaveform() {
    const width = eqCanvas.width;
    const height = eqCanvas.height;
    const padding = 20;
    
    // Create gradient
    const gradient = eqCtx.createLinearGradient(0, height - padding, 0, padding);
    gradient.addColorStop(0, "rgba(28, 0, 212, 0.9)");
    gradient.addColorStop(0.1, "rgba(0, 191, 255, 0.95)");
    gradient.addColorStop(0.3, "rgba(0, 210, 154, 0.9)");
    gradient.addColorStop(0.5, "rgba(255, 196, 0, 0.85)");
    gradient.addColorStop(0.7, "rgba(255, 0, 0, 0.85)");
    gradient.addColorStop(0.9, "rgba(255, 0, 157, 0.85)");
    gradient.addColorStop(1, "rgba(170, 0, 255, 0.85)");
    
    const sliceWidth = (width - 2 * padding) / waveformHistorySize;
    
    for (let h = 0; h < waveformHistory.length; h++) {
        const dataArray = waveformHistory[h];
        const x = padding + (h * sliceWidth);
        const alpha = 0.4 + (h / waveformHistory.length) * 0.6;
        
        eqCtx.beginPath();
        eqCtx.moveTo(x, height - padding);
        
        const maxFreq = audioContext.sampleRate / 2;
        const minLogFreq = Math.log10(20);
        const maxLogFreq = Math.log10(maxFreq);
        
        for (let i = 0; i < dataArray.length; i++) {
            const freq = (i * maxFreq) / dataArray.length;
            const logFreq = Math.log10(Math.max(20, freq));
            const normalizedLogFreq = (logFreq - minLogFreq) / (maxLogFreq - minLogFreq);
            const freqX = padding + (normalizedLogFreq * (width - 2 * padding));
            
            if (freqX >= x && freqX <= x + sliceWidth) {
                const amplitude = dataArray[i] / 255;
                const enhancedAmplitude = Math.pow(amplitude, 0.4);
                const ampY = height - padding - (enhancedAmplitude * (height - 2 * padding));
                eqCtx.lineTo(freqX, ampY);
            }
        }
        
        eqCtx.lineTo(x + sliceWidth, height - padding);
        eqCtx.closePath();
        
        eqCtx.globalAlpha = alpha;
        eqCtx.fillStyle = gradient;
        eqCtx.fill();
        
        if (h > waveformHistory.length * 0.7) {
            eqCtx.shadowColor = "rgba(0, 255, 170, 0.8)";
            eqCtx.shadowBlur = 10;
            eqCtx.fill();
            eqCtx.shadowBlur = 0;
        }
    }
    
    eqCtx.globalAlpha = 1;
}

// Start dragging EQ band
function startDraggingEQBand(e) {
    if (!currentClipEffects || !currentClipEffects.eq) return;
    
    // Ensure EQ is array format
    if (!Array.isArray(currentClipEffects.eq)) {
        currentClipEffects.eq = [];
    }
    
    const rect = eqCanvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    const padding = 20;
    const height = eqCanvas.height;
    
    // Check if clicking on existing point
    for (let i = 0; i < currentClipEffects.eq.length; i++) {
        const point = currentClipEffects.eq[i];
        if (point.fixed) continue;
        
        const pointX = padding + (Math.log10(point.frequency / 20) / Math.log10(20000 / 20)) * (eqCanvas.width - 2 * padding);
        const pointY = height / 2 - (point.gain / 24) * (height / 2 - padding);
        const distance = Math.sqrt(Math.pow(x - pointX, 2) + Math.pow(y - pointY, 2));
        
        if (distance <= 9) {
            isDraggingEqBand = true;
            draggedPoint = point;
            isCreatingNewPoint = false;
            return;
        }
    }
    
    // Create new point if under max
    if (currentClipEffects.eq.length < MAX_EQ_POINTS) {
        const frequency = 20 * Math.pow(20000 / 20, (x - padding) / (eqCanvas.width - 2 * padding));
        if (frequency <= 20 || frequency >= 20000) return;
        
        const gain = -(y - height / 2) / (height / 2 - padding) * 24;
        const newPoint = addEQPoint(frequency, gain);
        
        isDraggingEqBand = true;
        draggedPoint = newPoint;
        isCreatingNewPoint = true;
    }
}

// Drag EQ band
function dragEQBand(e) {
    if (!isDraggingEqBand || !draggedPoint || !currentClipEffects || !currentClipEffects.eq) return;
    
    const rect = eqCanvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    const padding = 20;
    const height = eqCanvas.height;
    
    // Calculate new gain
    const gain = -(y - height / 2) / (height / 2 - padding) * 24;
    const clampedGain = Math.max(-24, Math.min(24, gain));
    
    // Calculate new frequency
    const freq = 20 * Math.pow(20000 / 20, (x - padding) / (eqCanvas.width - 2 * padding));
    const clampedFreq = Math.max(20, Math.min(20000, freq));
    
    draggedPoint.gain = clampedGain;
    draggedPoint.frequency = clampedFreq;
    
    updatePreviewEffects();
    drawEQVisual();
}

// Stop dragging EQ band
function stopDraggingEQBand() {
    isDraggingEqBand = false;
    draggedPoint = null;
    isCreatingNewPoint = false;
}

// Handle touch start
function handleEQTouchStart(e) {
    e.preventDefault();
    if (!currentClipEffects || !currentClipEffects.eq) return;
    
    // Ensure EQ is array format
    if (!Array.isArray(currentClipEffects.eq)) {
        currentClipEffects.eq = [];
    }
    
    const touch = e.touches[0];
    const rect = eqCanvas.getBoundingClientRect();
    const x = touch.clientX - rect.left;
    const y = touch.clientY - rect.top;
    const padding = 20;
    const height = eqCanvas.height;
    
    // Check if touching existing point
    for (let i = 0; i < currentClipEffects.eq.length; i++) {
        const point = currentClipEffects.eq[i];
        if (point.fixed) continue;
        
        const pointX = padding + (Math.log10(point.frequency / 20) / Math.log10(20000 / 20)) * (eqCanvas.width - 2 * padding);
        const pointY = height / 2 - (point.gain / 24) * (height / 2 - padding);
        const distance = Math.sqrt(Math.pow(x - pointX, 2) + Math.pow(y - pointY, 2));
        
        if (distance <= 9) {
            isDraggingEqBand = true;
            draggedPoint = point;
            isCreatingNewPoint = false;
            return;
        }
    }
    
    // Create new point
    if (currentClipEffects.eq.length < MAX_EQ_POINTS) {
        const frequency = 20 * Math.pow(20000 / 20, (x - padding) / (eqCanvas.width - 2 * padding));
        if (frequency <= 20 || frequency >= 20000) return;
        
        const gain = -(y - height / 2) / (height / 2 - padding) * 24;
        const newPoint = addEQPoint(frequency, gain);
        
        isDraggingEqBand = true;
        draggedPoint = newPoint;
        isCreatingNewPoint = true;
    }
}

// Handle touch move
function handleEQTouchMove(e) {
    e.preventDefault();
    if (!isDraggingEqBand || !draggedPoint || !currentClipEffects || !currentClipEffects.eq) return;
    
    const touch = e.touches[0];
    const rect = eqCanvas.getBoundingClientRect();
    const x = touch.clientX - rect.left;
    const y = touch.clientY - rect.top;
    const padding = 20;
    const height = eqCanvas.height;
    
    const gain = -(y - height / 2) / (height / 2 - padding) * 24;
    const clampedGain = Math.max(-24, Math.min(24, gain));
    
    const freq = 20 * Math.pow(20000 / 20, (x - padding) / (eqCanvas.width - 2 * padding));
    const clampedFreq = Math.max(20, Math.min(20000, freq));
    
    draggedPoint.gain = clampedGain;
    draggedPoint.frequency = clampedFreq;
    
    updatePreviewEffects();
    drawEQVisual();
}

console.log('âœ… Interactive EQ System Loaded');

// ========================================
// LFO SYSTEM (4 Independent LFOs)
// Copied from PsychologicalStudio
// ========================================

// Setup LFO tabs switching
function setupLFOTabs() {
    // Make this idempotent: replace the container to remove old listeners if any
    const tabsContainer = document.querySelector('.lfo-tabs');
    if (!tabsContainer) return;

    // Clone container to clear existing event listeners if already initialized
    const newContainer = tabsContainer.cloneNode(true);
    tabsContainer.parentNode.replaceChild(newContainer, tabsContainer);

    const lfoTabButtons = newContainer.querySelectorAll('.lfo-tab');
    const lfoPanels = document.querySelectorAll('.lfo-panel');

    console.log('ðŸŽ›ï¸ setupLFOTabs: Found', lfoTabButtons.length, 'tabs and', lfoPanels.length, 'panels');

    // Ensure at least one tab is marked active; if none, activate the first
    let activeFound = false;
    lfoTabButtons.forEach(btn => { if (btn.classList.contains('active')) activeFound = true; });
    if (!activeFound && lfoTabButtons[0]) {
        lfoTabButtons[0].classList.add('active');
        const id = lfoTabButtons[0].getAttribute('data-lfo');
        const panel = document.getElementById(`arr-lfo-panel-${id}`);
        if (panel) panel.classList.add('active');
    }
    lfoTabButtons.forEach(button => {
        button.addEventListener('click', function() {
            const lfoNum = this.getAttribute('data-lfo');

            // Update tab buttons
            lfoTabButtons.forEach(btn => btn.classList.remove('active'));
            this.classList.add('active');

            // Update panels
            lfoPanels.forEach(panel => panel.classList.remove('active'));
            const panel = document.getElementById(`arr-lfo-panel-${lfoNum}`);
            if (panel) panel.classList.add('active');

            // Initialize visualizer for this LFO when its tab is shown
            initSingleLFOVisualizer(parseInt(lfoNum));
        });
    });
}

// Setup all LFO event listeners (call when popup opens)
function setupAllLFOEventListeners() {
    for (let i = 1; i <= 4; i++) {
        setupSingleLFOEventListeners(i);
    }
}

// Setup event listeners for a single LFO
function setupSingleLFOEventListeners(lfoNum) {
    const lfoIndex = lfoNum - 1;
    
    const target = document.getElementById(`arr-lfo-${lfoNum}-target`);
    const waveform = document.getElementById(`arr-lfo-${lfoNum}-waveform`);
    const rate = document.getElementById(`arr-lfo-${lfoNum}-rate`);
    const depth = document.getElementById(`arr-lfo-${lfoNum}-depth`);
    
    if (!target || !waveform || !rate || !depth) {
        console.warn(`âš ï¸ LFO ${lfoNum} controls not found`);
        return;
    }
    
    // Store current values before cloning
    const targetValue = target.value;
    const waveformValue = waveform.value;
    const rateValue = rate.value;
    const depthValue = depth.value;
    
    // Clone to remove old listeners
    const newTarget = target.cloneNode(true);
    const newWaveform = waveform.cloneNode(true);
    const newRate = rate.cloneNode(true);
    const newDepth = depth.cloneNode(true);
    
    // Restore values after cloning
    newTarget.value = targetValue;
    newWaveform.value = waveformValue;
    newRate.value = rateValue;
    newDepth.value = depthValue;
    
    target.parentNode.replaceChild(newTarget, target);
    waveform.parentNode.replaceChild(newWaveform, waveform);
    rate.parentNode.replaceChild(newRate, rate);
    depth.parentNode.replaceChild(newDepth, depth);
    
    newTarget.addEventListener("change", function() {
        updateSingleLFOInRealTime(lfoNum);
    });
    
    newWaveform.addEventListener("change", function() {
        updateSingleLFOInRealTime(lfoNum);
    });
    
    newRate.addEventListener("input", function() {
        updateSingleLFOInRealTime(lfoNum);
    });
    
    newDepth.addEventListener("input", function() {
        updateSingleLFOInRealTime(lfoNum);
    });
}

// Update a single LFO in real-time
function updateSingleLFOInRealTime(lfoNum) {
    if (!currentClipEffects) return;
    
    console.log('ðŸŽ›ï¸ updateSingleLFOInRealTime:', lfoNum);
    
    const lfoIndex = lfoNum - 1;
    
    const target = document.getElementById(`arr-lfo-${lfoNum}-target`).value;
    const waveform = document.getElementById(`arr-lfo-${lfoNum}-waveform`).value;
    const rate = parseFloat(document.getElementById(`arr-lfo-${lfoNum}-rate`).value);
    const depth = parseInt(document.getElementById(`arr-lfo-${lfoNum}-depth`).value);
    
    console.log('LFO settings:', { target, waveform, rate, depth });
    
    document.getElementById(`arr-lfo-${lfoNum}-rate-value`).textContent = rate.toFixed(1);
    document.getElementById(`arr-lfo-${lfoNum}-depth-value`).textContent = `${depth}%`;
    
    // Ensure lfos array exists
    if (!currentClipEffects.lfos) {
        currentClipEffects.lfos = [
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 },
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 },
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 },
            { enabled: false, target: 'none', waveform: 'sine', rate: 1, depth: 0 }
        ];
    }
    
    // Set enabled based on whether target is set and depth > 0
    const enabled = target !== 'none' && depth > 0;
    
    currentClipEffects.lfos[lfoIndex] = { 
        enabled, 
        target, 
        waveform, 
        rate, 
        depth 
    };
    
    console.log(`âœ… LFO ${lfoNum} saved:`, currentClipEffects.lfos[lfoIndex]);
    
    // Update visualizer
    drawLFOWaveform(lfoNum);
    
    // Apply effects in real-time (restart LFO with new settings)
    applyEffectsRealTime();
    updatePreviewLFOs(); // Restart LFO oscillators with new settings
}

// Initialize all 4 LFO visualizers
function initAllLFOVisualizers() {
    // Initialize LFO 1 immediately since its panel is active/visible
    initSingleLFOVisualizer(1);
    
    // For LFOs 2-4, set reasonable default dimensions
    // They will be properly initialized when their tabs are clicked
    for (let i = 2; i <= 4; i++) {
        const lfoCanvas = document.getElementById(`arr-lfo-${i}-wave`);
        if (lfoCanvas) {
            // Set a reasonable default size
            lfoCanvas.width = 300;
            lfoCanvas.height = 60;
        }
    }
    
    console.log('âœ… All LFO visualizers initialized');
}

// Initialize a single LFO visualizer
function initSingleLFOVisualizer(lfoNum) {
    const lfoCanvas = document.getElementById(`arr-lfo-${lfoNum}-wave`);
    if (!lfoCanvas) {
        console.warn(`âš ï¸ LFO ${lfoNum} canvas not found`);
        return;
    }
    
    const ctx = lfoCanvas.getContext("2d");
    const container = lfoCanvas.parentElement;
    lfoCanvas.width = container.clientWidth;
    lfoCanvas.height = container.clientHeight;
    
    console.log(`âœ… LFO ${lfoNum} visualizer initialized:`, lfoCanvas.width, 'x', lfoCanvas.height);
    
    drawLFOWaveform(lfoNum);
}

// Draw LFO waveform for a specific LFO
function drawLFOWaveform(lfoNum) {
    const lfoCanvas = document.getElementById(`arr-lfo-${lfoNum}-wave`);
    if (!lfoCanvas) return;
    
    const ctx = lfoCanvas.getContext("2d");
    const width = lfoCanvas.width;
    const height = lfoCanvas.height;
    
    // Clear canvas
    ctx.fillStyle = "#111";
    ctx.fillRect(0, 0, width, height);
    
    // Get current LFO settings
    const waveformSelect = document.getElementById(`arr-lfo-${lfoNum}-waveform`);
    const rateInput = document.getElementById(`arr-lfo-${lfoNum}-rate`);
    const depthInput = document.getElementById(`arr-lfo-${lfoNum}-depth`);
    
    if (!waveformSelect || !rateInput || !depthInput) return;
    
    const waveform = waveformSelect.value;
    const rate = parseFloat(rateInput.value);
    const depth = parseInt(depthInput.value);
    
    // Draw grid
    ctx.strokeStyle = "#333";
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.stroke();
    
    // Different color for each LFO
    const lfoColors = {
        1: "#3F51B5",  // Indigo
        2: "#E91E63",  // Pink
        3: "#00BCD4",  // Cyan
        4: "#FF9800"   // Orange
    };
    
    // Draw waveform with LFO-specific color
    ctx.strokeStyle = lfoColors[lfoNum] || "#3F51B5";
    ctx.lineWidth = 2;
    ctx.beginPath();
    
    const samples = width;
    const period = samples / (rate * 10);
    const amplitude = (height / 2) * (depth / 100);
    
    for (let x = 0; x < samples; x++) {
        let y;
        const phase = (x % period) / period * Math.PI * 2;
        
        switch (waveform) {
            case "sine":
                y = height / 2 - Math.sin(phase) * amplitude;
                break;
            case "square":
                y = height / 2 - (Math.sin(phase) > 0 ? 1 : -1) * amplitude;
                break;
            case "triangle":
                const t = (phase / Math.PI) % 2;
                y = height / 2 - (t < 1 ? 2 * t - 1 : 3 - 2 * t) * amplitude;
                break;
            case "sawtooth":
                y = height / 2 - (2 * ((phase / Math.PI) % 1) - 1) * amplitude;
                break;
            default:
                y = height / 2;
        }
        
        if (x === 0) {
            ctx.moveTo(x, y);
        } else {
            ctx.lineTo(x, y);
        }
    }
    
    ctx.stroke();
}

console.log('âœ… LFO System Loaded');

// ========================================
// AUTOMATION SYSTEM (4 Independent Automations)
// Copied from PsychologicalStudio
// ========================================

// Setup Automation tabs switching
function setupAutomationTabs() {
    const tabs = document.querySelectorAll('.automation-tab');
    const panels = document.querySelectorAll('.automation-panel');
    
    console.log('ðŸŽ›ï¸ setupAutomationTabs: Found', tabs.length, 'tabs and', panels.length, 'panels');
    
    tabs.forEach(button => {
        button.addEventListener('click', function() {
            const autoNum = this.getAttribute('data-automation');
            
            // Update tab buttons
            tabs.forEach(btn => btn.classList.remove('active'));
            this.classList.add('active');
            
            // Update panels
            panels.forEach(panel => panel.classList.remove('active'));
            document.getElementById(`arr-automation-panel-${autoNum}`).classList.add('active');
            
            // Initialize visualizer for this automation when its tab is shown
            setTimeout(() => {
                initSingleAutomationVisualizer(parseInt(autoNum));
            }, 10);
        });
    });
}

// Setup all automation event listeners (call when popup opens)
function setupAllAutomationEventListeners() {
    for (let i = 1; i <= 4; i++) {
        setupSingleAutomationEventListeners(i);
    }
}

// Setup event listeners for a single automation
function setupSingleAutomationEventListeners(autoNum) {
    const autoIndex = autoNum - 1;
    
    const target = document.getElementById(`arr-automation-${autoNum}-target`);
    const start = document.getElementById(`arr-automation-${autoNum}-start`);
    const end = document.getElementById(`arr-automation-${autoNum}-end`);
    const duration = document.getElementById(`arr-automation-${autoNum}-duration`);
    const curve = document.getElementById(`arr-automation-${autoNum}-curve`);
    
    if (!target || !start || !end || !duration || !curve) {
        console.warn(`âš ï¸ Automation ${autoNum} controls not found`);
        return;
    }
    
    // Load existing values
    const auto = currentClipEffects.automations[autoIndex] || { target: "none", start: 50, end: 50, duration: 1, curve: "linear" };
    target.value = auto.target || "none";
    start.value = auto.start !== undefined ? auto.start : 50;
    end.value = auto.end !== undefined ? auto.end : 50;
    duration.value = auto.duration !== undefined ? auto.duration : 1;
    curve.value = auto.curve || "linear";
    
    document.getElementById(`arr-automation-${autoNum}-start-value`).textContent = start.value;
    document.getElementById(`arr-automation-${autoNum}-end-value`).textContent = end.value;
    document.getElementById(`arr-automation-${autoNum}-duration-value`).textContent = duration.value;
    
    // Target change
    target.addEventListener('change', function() {
        currentClipEffects.automations[autoIndex].target = this.value;
        // Auto-enable when target is set
        currentClipEffects.automations[autoIndex].enabled = this.value !== 'none';
        console.log(`ðŸŽ›ï¸ Automation ${autoNum} target:`, this.value, 'enabled:', currentClipEffects.automations[autoIndex].enabled);
        drawAutomationCurve(autoNum);
        applyEffectsRealTime();
        // Only update preview automations for sample clips, not pattern clips
        // (Pattern clips calculate automation per-note, not continuously)
        if (currentClipForContext && currentClipForContext.type === 'sample') {
            updatePreviewAutomations();
        }
    });
    
    // Start value change
    start.addEventListener('input', function() {
        currentClipEffects.automations[autoIndex].start = parseInt(this.value);
        document.getElementById(`arr-automation-${autoNum}-start-value`).textContent = this.value;
        drawAutomationCurve(autoNum);
        applyEffectsRealTime();
        // Pattern clips don't need preview automation restart (calculated per-note)
        if (currentClipForContext && currentClipForContext.type === 'sample') {
            updatePreviewAutomations();
        }
    });
    
    // End value change
    end.addEventListener('input', function() {
        currentClipEffects.automations[autoIndex].end = parseInt(this.value);
        document.getElementById(`arr-automation-${autoNum}-end-value`).textContent = this.value;
        drawAutomationCurve(autoNum);
        applyEffectsRealTime();
        // Pattern clips don't need preview automation restart (calculated per-note)
        if (currentClipForContext && currentClipForContext.type === 'sample') {
            updatePreviewAutomations();
        }
    });
    
    // Duration change
    duration.addEventListener('input', function() {
        currentClipEffects.automations[autoIndex].duration = parseInt(this.value);
        document.getElementById(`arr-automation-${autoNum}-duration-value`).textContent = this.value;
        drawAutomationCurve(autoNum);
        applyEffectsRealTime();
        // Pattern clips don't need preview automation restart (calculated per-note)
        if (currentClipForContext && currentClipForContext.type === 'sample') {
            updatePreviewAutomations();
        }
    });
    
    // Curve change
    curve.addEventListener('change', function() {
        currentClipEffects.automations[autoIndex].curve = this.value;
        console.log(`ðŸŽ›ï¸ Automation ${autoNum} curve:`, this.value);
        drawAutomationCurve(autoNum);
        applyEffectsRealTime();
        // Pattern clips don't need preview automation restart (calculated per-note)
        if (currentClipForContext && currentClipForContext.type === 'sample') {
            updatePreviewAutomations();
        }
    });
}

// Initialize all automation visualizers
function initAllAutomationVisualizers() {
    // Initialize Automation 1 immediately since its panel is active/visible
    initSingleAutomationVisualizer(1);
    
    // For Automations 2-4, set reasonable default dimensions
    for (let i = 2; i <= 4; i++) {
        const autoCanvas = document.getElementById(`arr-automation-${i}-canvas`);
        if (autoCanvas) {
            autoCanvas.width = 300;
            autoCanvas.height = 80;
        }
    }
    
    console.log('âœ… All Automation visualizers initialized');
}

// Initialize a single automation visualizer
function initSingleAutomationVisualizer(autoNum) {
    const canvas = document.getElementById(`arr-automation-${autoNum}-canvas`);
    if (!canvas) {
        console.warn(`âš ï¸ Automation ${autoNum} canvas not found`);
        return;
    }
    
    const ctx = canvas.getContext("2d");
    const container = canvas.parentElement;
    canvas.width = container.clientWidth;
    canvas.height = container.clientHeight;
    
    console.log(`âœ… Automation ${autoNum} visualizer initialized:`, canvas.width, 'x', canvas.height);
    
    drawAutomationCurve(autoNum);
}

// Draw automation curve for a specific automation
function drawAutomationCurve(autoNum) {
    const canvas = document.getElementById(`arr-automation-${autoNum}-canvas`);
    if (!canvas) return;
    
    const ctx = canvas.getContext("2d");
    const width = canvas.width;
    const height = canvas.height;
    
    // Clear canvas
    ctx.fillStyle = "#111";
    ctx.fillRect(0, 0, width, height);
    
    // Get current automation settings
    const autoIndex = autoNum - 1;
    const auto = currentClipEffects.automations[autoIndex] || { target: "none", start: 50, end: 50, duration: 1, curve: "linear" };
    
    // Draw grid
    ctx.strokeStyle = "#333";
    ctx.lineWidth = 1;
    
    // Horizontal center line
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.stroke();
    
    // Vertical lines (quarters)
    for (let i = 1; i < 4; i++) {
        ctx.beginPath();
        ctx.moveTo(width * i / 4, 0);
        ctx.lineTo(width * i / 4, height);
        ctx.stroke();
    }
    
    // Different color for each automation
    const autoColors = {
        1: "#3F51B5",  // Indigo
        2: "#E91E63",  // Pink
        3: "#00BCD4",  // Cyan
        4: "#FF9800"   // Orange
    };
    
    // Draw automation curve
    ctx.strokeStyle = autoColors[autoNum] || "#3F51B5";
    ctx.lineWidth = 2;
    ctx.beginPath();
    
    const startY = height - (auto.start / 100 * height);
    const endY = height - (auto.end / 100 * height);
    
    ctx.moveTo(0, startY);
    
    // Draw curve based on type
    switch (auto.curve) {
        case "linear":
            ctx.lineTo(width, endY);
            break;
        case "exponential":
        case "easeIn":
            for (let x = 0; x <= width; x++) {
                const t = x / width;
                const eased = t * t;
                const y = startY + (endY - startY) * eased;
                ctx.lineTo(x, y);
            }
            break;
        case "logarithmic":
        case "easeOut":
            for (let x = 0; x <= width; x++) {
                const t = x / width;
                const eased = 1 - (1 - t) * (1 - t);
                const y = startY + (endY - startY) * eased;
                ctx.lineTo(x, y);
            }
            break;
        case "easeInOut":
            for (let x = 0; x <= width; x++) {
                const t = x / width;
                const eased = t < 0.5 ? 2 * t * t : 1 - Math.pow(-2 * t + 2, 2) / 2;
                const y = startY + (endY - startY) * eased;
                ctx.lineTo(x, y);
            }
            break;
    }
    
    ctx.stroke();
    
    // Draw start and end points
    ctx.fillStyle = autoColors[autoNum] || "#3F51B5";
    ctx.beginPath();
    ctx.arc(0, startY, 4, 0, Math.PI * 2);
    ctx.fill();
    ctx.beginPath();
    ctx.arc(width, endY, 4, 0, Math.PI * 2);
    ctx.fill();
}

// Make automation canvases interactive
function setupInteractiveAutomation() {
    for (let autoNum = 1; autoNum <= 4; autoNum++) {
        const canvas = document.getElementById(`arr-automation-${autoNum}-canvas`);
        if (!canvas) continue;
        
        const autoIndex = autoNum - 1;
        let isDragging = false;
        let dragType = null; // 'start' or 'end'
        
        // Mouse down - start dragging
        canvas.addEventListener('mousedown', (e) => {
            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;
            
            const auto = currentClipEffects.automations[autoIndex];
            if (!auto || auto.target === 'none') return;
            
            // Check if clicking near start point (left edge)
            const startY = canvas.height - (auto.start / 100 * canvas.height);
            if (Math.abs(x - 0) < 20 && Math.abs(y - startY) < 15) {
                isDragging = true;
                dragType = 'start';
                canvas.style.cursor = 'grabbing';
                return;
            }
            
            // Check if clicking near end point (right edge)
            const endY = canvas.height - (auto.end / 100 * canvas.height);
            if (Math.abs(x - canvas.width) < 20 && Math.abs(y - endY) < 15) {
                isDragging = true;
                dragType = 'end';
                canvas.style.cursor = 'grabbing';
                return;
            }
            
            // If clicking anywhere else on the curve, update both start and end proportionally
            const normalizedY = 100 - (y / canvas.height * 100);
            const normalizedX = x / canvas.width;
            
            // Interpolate the value based on x position
            if (normalizedX < 0.5) {
                // Closer to start, update start value
                isDragging = true;
                dragType = 'start';
                auto.start = Math.max(0, Math.min(100, normalizedY));
                document.getElementById(`arr-automation-${autoNum}-start`).value = auto.start;
                document.getElementById(`arr-automation-${autoNum}-start-value`).textContent = Math.round(auto.start);
            } else {
                // Closer to end, update end value
                isDragging = true;
                dragType = 'end';
                auto.end = Math.max(0, Math.min(100, normalizedY));
                document.getElementById(`arr-automation-${autoNum}-end`).value = auto.end;
                document.getElementById(`arr-automation-${autoNum}-end-value`).textContent = Math.round(auto.end);
            }
            
            drawAutomationCurve(autoNum);
            applyEffectsRealTime();
        });
        
        // Mouse move - drag point
        canvas.addEventListener('mousemove', (e) => {
            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;
            
            const auto = currentClipEffects.automations[autoIndex];
            if (!auto || auto.target === 'none') return;
            
            // Update cursor when hovering over points
            if (!isDragging) {
                const startY = canvas.height - (auto.start / 100 * canvas.height);
                const endY = canvas.height - (auto.end / 100 * canvas.height);
                
                if ((Math.abs(x - 0) < 20 && Math.abs(y - startY) < 15) ||
                    (Math.abs(x - canvas.width) < 20 && Math.abs(y - endY) < 15)) {
                    canvas.style.cursor = 'grab';
                } else {
                    canvas.style.cursor = 'crosshair';
                }
            }
            
            // If dragging, update the value
            if (isDragging) {
                const normalizedY = 100 - (y / canvas.height * 100);
                const clampedValue = Math.max(0, Math.min(100, normalizedY));
                
                if (dragType === 'start') {
                    auto.start = clampedValue;
                    document.getElementById(`arr-automation-${autoNum}-start`).value = clampedValue;
                    document.getElementById(`arr-automation-${autoNum}-start-value`).textContent = Math.round(clampedValue);
                } else if (dragType === 'end') {
                    auto.end = clampedValue;
                    document.getElementById(`arr-automation-${autoNum}-end`).value = clampedValue;
                    document.getElementById(`arr-automation-${autoNum}-end-value`).textContent = Math.round(clampedValue);
                }
                
                drawAutomationCurve(autoNum);
                applyEffectsRealTime();
            }
        });
        
        // Mouse up - stop dragging
        canvas.addEventListener('mouseup', () => {
            if (isDragging) {
                isDragging = false;
                dragType = null;
                canvas.style.cursor = 'crosshair';
            }
        });
        
        // Mouse leave - stop dragging
        canvas.addEventListener('mouseleave', () => {
            if (isDragging) {
                isDragging = false;
                dragType = null;
                canvas.style.cursor = 'default';
            }
        });
        
        // Set initial cursor
        canvas.style.cursor = 'crosshair';
    }
    
    console.log('âœ… Interactive automation canvases initialized');
}

console.log('âœ… Automation System Loaded');

// ========================================
// LEGACY AUTOMATION SYSTEM (OLD)
// Keeping for backward compatibility
// ========================================

// Legacy variables (not used by new 4-automation system)
let automationCanvases = {};
let automationContexts = {};
let automationDragState = {};

// Initialize automation canvas for effects popup (LEGACY - NOT USED)
function initAutomationCanvas() {
    const canvas = document.getElementById('arr-automation-canvas');
    if (!canvas) {
        console.warn('âš ï¸ Automation canvas not found');
        return;
    }
    
    const ctx = canvas.getContext('2d');
    const container = canvas.parentElement;
    canvas.width = container.clientWidth;
    canvas.height = container.clientHeight;
    
    automationCanvases['main'] = canvas;
    automationContexts['main'] = ctx;
    
    setupAutomationInteraction(canvas);
    drawLegacyAutomationCurve(); // Use the renamed legacy function
    
    console.log('âœ… LEGACY Automation canvas initialized:', canvas.width, 'x', canvas.height);
}

// Setup mouse/touch interaction for automation canvas
function setupAutomationInteraction(canvas) {
    let isDragging = false;
    let draggedPointIndex = null;
    
    canvas.addEventListener('mousedown', function(e) {
        const rect = canvas.getBoundingClientRect();
        const x = e.clientX - rect.left;
        const y = e.clientY - rect.top;
        
        if (!currentClipEffects || !currentClipEffects.automation) {
            currentClipEffects.automation = {
                enabled: false,
                target: 'volume',
                points: [
                    { time: 0, value: 50 },
                    { time: 1, value: 50 }
                ]
            };
        }
        
        const auto = currentClipEffects.automation;
        
        // Initialize points if they don't exist
        if (!auto.points || auto.points.length < 2) {
            auto.points = [
                { time: 0, value: 50 },
                { time: 1, value: 50 }
            ];
        }
        
        // Check if clicking near an existing point
        let clickedPoint = -1;
        for (let i = 0; i < auto.points.length; i++) {
            const point = auto.points[i];
            const pointX = point.time * canvas.width;
            const pointY = canvas.height - (point.value / 100 * canvas.height);
            
            if (Math.abs(x - pointX) < 10 && Math.abs(y - pointY) < 10) {
                clickedPoint = i;
                break;
            }
        }
        
        if (clickedPoint !== -1) {
            // Right click or Ctrl+click to delete point (except first and last)
            if (e.button === 2 || e.ctrlKey) {
                if (clickedPoint !== 0 && clickedPoint !== auto.points.length - 1) {
                    auto.points.splice(clickedPoint, 1);
                    drawLegacyAutomationCurve(); // LEGACY
                }
                e.preventDefault();
                return;
            }
            
            // Start dragging existing point
            isDragging = true;
            draggedPointIndex = clickedPoint;
        } else {
            // Add new point at clicked position
            const time = x / canvas.width;
            const value = ((canvas.height - y) / canvas.height) * 100;
            
            // Find where to insert the new point to keep time order
            let insertIndex = auto.points.findIndex(p => p.time > time);
            if (insertIndex === -1) insertIndex = auto.points.length;
            
            auto.points.splice(insertIndex, 0, { time: time, value: value });
            
            // Start dragging the new point
            isDragging = true;
            draggedPointIndex = insertIndex;
            
            drawLegacyAutomationCurve(); // LEGACY
        }
    });
    
    // Prevent context menu on right-click
    canvas.addEventListener('contextmenu', function(e) {
        e.preventDefault();
    });
    
    canvas.addEventListener('mousemove', function(e) {
        if (!isDragging || draggedPointIndex === null) {
            // Change cursor on hover
            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;
            
            if (!currentClipEffects || !currentClipEffects.automation || !currentClipEffects.automation.points) {
                canvas.style.cursor = 'crosshair';
                return;
            }
            
            const auto = currentClipEffects.automation;
            let nearPoint = false;
            for (let i = 0; i < auto.points.length; i++) {
                const point = auto.points[i];
                const pointX = point.time * canvas.width;
                const pointY = canvas.height - (point.value / 100 * canvas.height);
                
                if (Math.abs(x - pointX) < 10 && Math.abs(y - pointY) < 10) {
                    nearPoint = true;
                    break;
                }
            }
            
            canvas.style.cursor = nearPoint ? 'pointer' : 'crosshair';
            return;
        }
        
        const rect = canvas.getBoundingClientRect();
        const x = e.clientX - rect.left;
        const y = e.clientY - rect.top;
        
        const auto = currentClipEffects.automation;
        
        // Calculate new value
        let value = ((canvas.height - y) / canvas.height) * 100;
        value = Math.max(0, Math.min(100, value));
        
        // Calculate new time position
        let time = x / canvas.width;
        time = Math.max(0, Math.min(1, time));
        
        // Don't allow moving first or last point horizontally
        if (draggedPointIndex === 0) {
            time = 0;
        } else if (draggedPointIndex === auto.points.length - 1) {
            time = 1;
        } else {
            // Constrain time to be between neighbors
            const prevTime = auto.points[draggedPointIndex - 1].time;
            const nextTime = auto.points[draggedPointIndex + 1].time;
            time = Math.max(prevTime + 0.01, Math.min(nextTime - 0.01, time));
        }
        
        // Update point
        auto.points[draggedPointIndex].time = time;
        auto.points[draggedPointIndex].value = value;
        
        // Redraw
        drawLegacyAutomationCurve(); // LEGACY
    });
    
    canvas.addEventListener('mouseup', function() {
        isDragging = false;
        draggedPointIndex = null;
    });
    
    canvas.addEventListener('mouseleave', function() {
        isDragging = false;
        draggedPointIndex = null;
    });
    
    // Touch support
    canvas.addEventListener('touchstart', function(e) {
        e.preventDefault();
        const touch = e.touches[0];
        const mouseEvent = new MouseEvent('mousedown', {
            clientX: touch.clientX,
            clientY: touch.clientY,
            button: 0
        });
        canvas.dispatchEvent(mouseEvent);
    });
    
    canvas.addEventListener('touchmove', function(e) {
        e.preventDefault();
        const touch = e.touches[0];
        const mouseEvent = new MouseEvent('mousemove', {
            clientX: touch.clientX,
            clientY: touch.clientY
        });
        canvas.dispatchEvent(mouseEvent);
    });
    
    canvas.addEventListener('touchend', function(e) {
        e.preventDefault();
        const mouseEvent = new MouseEvent('mouseup', {});
        canvas.dispatchEvent(mouseEvent);
    });
}

// Draw automation curve on canvas (LEGACY - single automation)
function drawLegacyAutomationCurve() {
    // This is the old single automation curve drawer - NOT USED ANYMORE
    // Keeping for reference only
    return;
    
    const canvas = automationCanvases['main'];
    const ctx = automationContexts['main'];
    
    if (!canvas || !ctx) return;
    
    const width = canvas.width;
    const height = canvas.height;
    
    // Clear canvas
    ctx.fillStyle = '#0a0a0f';
    ctx.fillRect(0, 0, width, height);
    
    // Draw grid
    ctx.strokeStyle = '#1a1a2e';
    ctx.lineWidth = 1;
    
    // Horizontal lines (25%, 50%, 75%)
    for (let i = 1; i <= 3; i++) {
        const y = height * (i / 4);
        ctx.beginPath();
        ctx.moveTo(0, y);
        ctx.lineTo(width, y);
        ctx.stroke();
    }
    
    // Vertical lines (beat markers - 4 beats)
    for (let i = 1; i <= 3; i++) {
        const x = width * (i / 4);
        ctx.beginPath();
        ctx.moveTo(x, 0);
        ctx.lineTo(x, height);
        ctx.stroke();
    }
    
    // Draw 50% line (center reference)
    ctx.strokeStyle = '#333';
    ctx.setLineDash([5, 3]);
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.stroke();
    ctx.setLineDash([]);
    
    if (!currentClipEffects || !currentClipEffects.automation || !currentClipEffects.automation.points) return;
    
    const auto = currentClipEffects.automation;
    const sortedPoints = [...auto.points].sort((a, b) => a.time - b.time);
    
    // Draw automation curve - Purple color
    ctx.strokeStyle = '#9C27B0';
    ctx.lineWidth = 3;
    ctx.shadowColor = 'rgba(156, 39, 176, 0.8)';
    ctx.shadowBlur = 8;
    ctx.beginPath();
    
    for (let i = 0; i < sortedPoints.length; i++) {
        const point = sortedPoints[i];
        const x = point.time * width;
        const y = height - (point.value / 100 * height);
        
        if (i === 0) {
            ctx.moveTo(x, y);
        } else {
            ctx.lineTo(x, y);
        }
    }
    
    ctx.stroke();
    ctx.shadowBlur = 0;
    
    // Draw points as circles
    ctx.fillStyle = '#9C27B0';
    for (let i = 0; i < sortedPoints.length; i++) {
        const point = sortedPoints[i];
        const x = point.time * width;
        const y = height - (point.value / 100 * height);
        
        ctx.shadowColor = 'rgba(156, 39, 176, 0.8)';
        ctx.shadowBlur = 15;
        ctx.beginPath();
        ctx.arc(x, y, 7, 0, Math.PI * 2);
        ctx.fill();
        
        // White inner circle
        ctx.fillStyle = '#fff';
        ctx.shadowBlur = 0;
        ctx.beginPath();
        ctx.arc(x, y, 4, 0, Math.PI * 2);
        ctx.fill();
        ctx.fillStyle = '#9C27B0';
    }
    
    // Draw labels for start and end
    ctx.fillStyle = '#fff';
    ctx.font = '10px Arial';
    ctx.shadowBlur = 0;
    
    if (sortedPoints.length > 0) {
        const startPoint = sortedPoints[0];
        const startX = startPoint.time * width;
        const startY = height - (startPoint.value / 100 * height);
        ctx.fillText('Start', startX + 10, startY - 10);
        
        const endPoint = sortedPoints[sortedPoints.length - 1];
        const endX = endPoint.time * width;
        const endY = height - (endPoint.value / 100 * height);
        ctx.fillText('End', endX - 40, endY - 10);
    }
    
    // Draw target label
    const targetName = auto.target || 'volume';
    ctx.fillStyle = 'rgba(255, 255, 255, 0.6)';
    ctx.font = '11px Arial';
    ctx.fillText(`Target: ${targetName.toUpperCase()}`, 10, height - 5);
}

// Apply automation to preview playback
function applyAutomationToPreview() {
    if (!currentClipEffects || !currentClipEffects.automation || !previewSource) return;
    
    const auto = currentClipEffects.automation;
    if (!auto.enabled || !auto.points || auto.points.length < 2) return;
    
    const target = auto.target || 'volume';
    const sortedPoints = [...auto.points].sort((a, b) => a.time - b.time);
    const duration = previewSource.buffer.duration;
    const now = audioContext.currentTime;
    
    // Cancel any previous automation
    if (target === 'volume' && previewGainNode) {
        previewGainNode.gain.cancelScheduledValues(now);
        previewGainNode.gain.setValueAtTime(previewGainNode.gain.value, now);
    } else if (target === 'filter' && previewFilterNode) {
        previewFilterNode.frequency.cancelScheduledValues(now);
        previewFilterNode.frequency.setValueAtTime(previewFilterNode.frequency.value, now);
    } else if (target === 'pitch' && previewSource.playbackRate) {
        previewSource.playbackRate.cancelScheduledValues(now);
        previewSource.playbackRate.setValueAtTime(previewSource.playbackRate.value, now);
    }
    
    // Schedule automation points
    for (let i = 0; i < sortedPoints.length; i++) {
        const point = sortedPoints[i];
        const timeInSeconds = point.time * duration;
        const value = point.value / 100; // Normalize to 0-1
        
        if (target === 'volume' && previewGainNode) {
            const gainValue = value * 2; // 0-2 range for volume
            if (i === 0) {
                previewGainNode.gain.setValueAtTime(gainValue, now + timeInSeconds);
            } else {
                previewGainNode.gain.linearRampToValueAtTime(gainValue, now + timeInSeconds);
            }
        } else if (target === 'filter' && previewFilterNode) {
            const freqValue = 20 + (value * 19980); // 20Hz - 20kHz range
            if (i === 0) {
                previewFilterNode.frequency.setValueAtTime(freqValue, now + timeInSeconds);
            } else {
                previewFilterNode.frequency.exponentialRampToValueAtTime(freqValue, now + timeInSeconds);
            }
        } else if (target === 'pitch' && previewSource.playbackRate) {
            const pitchValue = 0.5 + (value * 1.5); // 0.5x - 2x range
            if (i === 0) {
                previewSource.playbackRate.setValueAtTime(pitchValue, now + timeInSeconds);
            } else {
                previewSource.playbackRate.exponentialRampToValueAtTime(pitchValue, now + timeInSeconds);
            }
        }
    }
}

// ========================================
// LFO SYSTEM
// ========================================

// Initialize LFO for preview playback
function initLfoForPreview() {
    if (!currentClipEffects || !currentClipEffects.lfo) return;
    
    const lfo = currentClipEffects.lfo;
    if (!lfo.enabled || lfo.depth === 0) {
        cleanupLfo();
        return;
    }
    
    // Create LFO oscillator
    if (!previewLfoNode) {
        previewLfoNode = audioContext.createOscillator();
        previewLfoGainNode = audioContext.createGain();
        
        previewLfoNode.connect(previewLfoGainNode);
        previewLfoNode.start();
    }
    
    // Update LFO parameters
    previewLfoNode.type = lfo.waveform || 'sine';
    previewLfoNode.frequency.value = lfo.rate || 1;
    previewLfoGainNode.gain.value = lfo.depth / 100;
    
    // Connect to target
    const target = lfo.target || 'filter';
    
    // Disconnect previous connections
    try {
        previewLfoGainNode.disconnect();
    } catch (e) {}
    
    if (target === 'filter' && previewFilterNode) {
        // Modulate filter cutoff frequency
        const baseFreq = previewFilterNode.frequency.value || 1000;
        const modulationRange = baseFreq * 0.5; // Â±50% modulation
        
        previewLfoGainNode.gain.value = modulationRange * (lfo.depth / 100);
        previewLfoGainNode.connect(previewFilterNode.frequency);
        
    } else if (target === 'volume' && previewGainNode) {
        // Modulate volume (tremolo effect)
        const modulationRange = 0.5; // Â±50% volume modulation
        
        previewLfoGainNode.gain.value = modulationRange * (lfo.depth / 100);
        previewLfoGainNode.connect(previewGainNode.gain);
        
    } else if (target === 'pitch' && previewSource && previewSource.detune) {
        // Modulate pitch using detune
        updatePitchLfo();
    }
    
    console.log('ðŸ”„ LFO initialized:', { target, rate: lfo.rate, depth: lfo.depth, waveform: lfo.waveform });
}

// Update pitch LFO (manual implementation for detune)
function updatePitchLfo() {
    if (!currentClipEffects || !currentClipEffects.lfo || !previewSource) return;
    
    const lfo = currentClipEffects.lfo;
    if (!lfo.enabled || lfo.depth === 0 || lfo.target !== 'pitch') {
        if (previewLfoUpdateTimeout) {
            clearTimeout(previewLfoUpdateTimeout);
            previewLfoUpdateTimeout = null;
        }
        return;
    }
    
    const time = audioContext.currentTime;
    const lfoRate = lfo.rate || 1;
    const lfoDepth = lfo.depth / 100;
    const waveform = lfo.waveform || 'sine';
    
    const lfoDuration = 1 / lfoRate;
    const phase = (time % lfoDuration) / lfoDuration * Math.PI * 2;
    
    let modulationValue = 0;
    switch (waveform) {
        case 'sine':
            modulationValue = Math.sin(phase);
            break;
        case 'square':
            modulationValue = Math.sin(phase) > 0 ? 1 : -1;
            break;
        case 'triangle':
            const t = (phase / Math.PI) % 2;
            modulationValue = t < 1 ? 2 * t - 1 : 3 - 2 * t;
            break;
        case 'sawtooth':
            modulationValue = 2 * ((phase / Math.PI) % 1) - 1;
            break;
    }
    
    // Calculate detune value in cents (max Â±1200 cents = 1 octave)
    const maxDetune = 1200;
    const detuneValue = maxDetune * lfoDepth * modulationValue;
    
    // Apply detune
    if (previewSource.detune) {
        previewSource.detune.setValueAtTime(detuneValue, time);
    }
    
    // Schedule next update
    previewLfoUpdateTimeout = setTimeout(updatePitchLfo, 50); // Update every 50ms
}

// Cleanup LFO on preview stop
function cleanupLfo() {
    if (previewLfoNode) {
        try {
            previewLfoNode.stop();
            previewLfoNode.disconnect();
        } catch (e) {}
        previewLfoNode = null;
    }
    
    if (previewLfoGainNode) {
        try {
            previewLfoGainNode.disconnect();
        } catch (e) {}
        previewLfoGainNode = null;
    }
    
    if (previewLfoUpdateTimeout) {
        clearTimeout(previewLfoUpdateTimeout);
        previewLfoUpdateTimeout = null;
    }
}

console.log('âœ… Automation & LFO System Loaded');

// ========================================
// THEME SYSTEM - Sync with PsychologicalStudio
// ========================================

const arrangeThemes = {
    default: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#4a4a4a',
        buttonHover: '#5a5a5a',
        accent: '#007bff',
        text: '#f0f0f0',
        border: '#333',
        trackBg: '#151515',     // Very dark for tracks
        clipBg: '#3a3a5e',
        gridLine: '#222',       // Dark grid lines
        timelineBg: '#1a1a1a',  // Dark grey timeline
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',    // Dark grey beat lines
        stepLine: '#1a1a1a'     // Darker step lines
    },
    dark: {
        background: '#000000',  // Pure black
        controlsBg: '#0f0f0f',
        buttonBg: '#2a2a2a',
        buttonHover: '#3a3a3a',
        accent: '#666666',
        text: '#cccccc',
        border: '#222',
        trackBg: '#0a0a0a',
        clipBg: '#2a2a2a',
        gridLine: '#1a1a1a',
        timelineBg: '#0f0f0f',
        barLine: '#333',
        beatLine: '#222222',
        stepLine: '#111111'
    },
    blue: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#2c3e50',
        buttonHover: '#34495e',
        accent: '#3498db',
        text: '#ecf0f1',
        border: '#34495e',
        trackBg: '#0f0f0f',
        clipBg: '#2c4e70',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    },
    green: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#2c5f2c',
        buttonHover: '#3d7a3d',
        accent: '#27ae60',
        text: '#d5f4e6',
        border: '#2c5f2c',
        trackBg: '#0f0f0f',
        clipBg: '#2c6f2c',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    },
    purple: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#5f2c5f',
        buttonHover: '#7a3d7a',
        accent: '#9b59b6',
        text: '#f4d5f4',
        border: '#5f2c5f',
        trackBg: '#0f0f0f',
        clipBg: '#5f2c7f',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    },
    red: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#5f2c2c',
        buttonHover: '#7a3d3d',
        accent: '#e74c3c',
        text: '#f4d5d5',
        border: '#5f2c2c',
        trackBg: '#0f0f0f',
        clipBg: '#7f2c2c',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    },
    orange: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#5f4a2c',
        buttonHover: '#7a623d',
        accent: '#e67e22',
        text: '#f4e6d5',
        border: '#5f4a2c',
        trackBg: '#0f0f0f',
        clipBg: '#7f6a2c',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    },
    pink: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#5f2c4a',
        buttonHover: '#7a3d63',
        accent: '#e91e63',
        text: '#f4d5e1',
        border: '#5f2c4a',
        trackBg: '#0f0f0f',
        clipBg: '#7f2c6a',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    },
    cyan: {
        background: '#0a0a0a',  // Dark black for main interface
        controlsBg: '#1a1a1a',  // Dark grey for controls
        buttonBg: '#2c5f5f',
        buttonHover: '#3d7a7a',
        accent: '#00bcd4',
        text: '#d5f4f4',
        border: '#2c5f5f',
        trackBg: '#0f0f0f',
        clipBg: '#2c7f7f',
        gridLine: '#1a1a1a',
        timelineBg: '#1a1a1a',
        barLine: '#444',        // Dark grey bar lines
        beatLine: '#2a2a2a',
        stepLine: '#1a1a1a'
    }
};

// Get current theme object
function getCurrentTheme() {
    const themeName = document.body.dataset.currentTheme || 'default';
    return arrangeThemes[themeName] || arrangeThemes.default;
}

function applyArrangementTheme(themeName) {
    const theme = arrangeThemes[themeName];
    if (!theme) {
        console.warn('Theme not found:', themeName);
        return;
    }
    
    console.log('ðŸŽ¨ Applying theme to arrangement:', themeName);
    
    // Apply to body and main container
    document.body.style.backgroundColor = theme.background;
    document.body.style.color = theme.text;
    
    // Apply CSS variables
    document.documentElement.style.setProperty('--button-hover-bg', theme.buttonHover);
    document.documentElement.style.setProperty('--accent-color', theme.accent);
    document.documentElement.style.setProperty('--text-color', theme.text);
    document.documentElement.style.setProperty('--border-color', theme.border);
    document.documentElement.style.setProperty('--track-bg', theme.trackBg);
    document.documentElement.style.setProperty('--clip-bg', theme.clipBg);
    document.documentElement.style.setProperty('--grid-line', theme.gridLine);
    document.documentElement.style.setProperty('--header-gradient-start', theme.controlsBg);
    document.documentElement.style.setProperty('--header-gradient-end', theme.background);
    
    // Apply to header
    const header = document.querySelector('.arrangement-header');
    if (header) {
        header.style.background = `linear-gradient(135deg, ${theme.controlsBg} 0%, ${theme.background} 100%)`;
        header.style.borderColor = theme.accent;
        header.style.color = theme.text;
    }
    
    // Apply to all buttons
    const buttons = document.querySelectorAll('.arr-btn, .arr-play-btn, .arr-stop-btn, .arr-loop-btn, .arr-back-btn, .arr-save-btn, button');
    buttons.forEach(btn => {
        // Skip if it's a specific color button (play, stop, etc)
        if (!btn.classList.contains('arr-play-btn') && 
            !btn.classList.contains('arr-stop-btn') && 
            !btn.classList.contains('arr-back-btn') &&
            !btn.classList.contains('arr-save-btn')) {
            btn.style.backgroundColor = theme.buttonBg;
            btn.style.color = theme.text;
            btn.style.borderColor = theme.border;
        }
    });
    
    // Apply to sidebar
    const sidebar = document.querySelector('.arr-sidebar');
    if (sidebar) {
        sidebar.style.backgroundColor = theme.controlsBg;
        sidebar.style.borderColor = theme.border;
    }
    
    // Apply to all sections in sidebar
    const sidebarSections = document.querySelectorAll('.arr-sidebar-section');
    sidebarSections.forEach(section => {
        section.style.backgroundColor = theme.controlsBg;
        section.style.borderColor = theme.border;
    });
    
    // Apply to dropdowns
    const selects = document.querySelectorAll('.arr-sample-select, .arr-pattern-select, select');
    selects.forEach(select => {
        select.style.backgroundColor = theme.buttonBg;
        select.style.color = theme.text;
        select.style.borderColor = theme.border;
    });
    
    // Apply to timeline
    const timeline = document.querySelector('.arr-timeline');
    if (timeline) {
        timeline.style.backgroundColor = theme.controlsBg;
        timeline.style.borderColor = theme.border;
        timeline.style.color = theme.text;
    }
    
    // Apply to track list
    const trackList = document.querySelector('.arr-track-list');
    if (trackList) {
        trackList.style.backgroundColor = theme.controlsBg;
        trackList.style.borderColor = theme.border;
    }
    
    // Apply to all track headers
    const trackHeaders = document.querySelectorAll('.arr-track');
    trackHeaders.forEach(track => {
        track.style.backgroundColor = theme.trackBg;
        track.style.borderColor = theme.border;
        track.style.color = theme.text;
    });
    
    // Apply to arrangement view container
    const arrView = document.querySelector('.arr-view');
    if (arrView) {
        arrView.style.backgroundColor = theme.background;
    }
    
    // Apply to canvas container
    const canvasContainer = document.querySelector('.arr-canvas-container');
    if (canvasContainer) {
        canvasContainer.style.backgroundColor = theme.background;
    }
    
    // Apply to effects popup
    const popup = document.getElementById('arr-effects-popup');
    if (popup) {
        popup.style.backgroundColor = theme.controlsBg;
        popup.style.borderColor = theme.accent;
        popup.style.color = theme.text;
    }
    
    // Apply to popup header
    const popupHeader = document.querySelector('.arr-popup-header');
    if (popupHeader) {
        popupHeader.style.backgroundColor = theme.buttonBg;
        popupHeader.style.borderColor = theme.border;
        popupHeader.style.color = theme.text;
    }
    
    // Apply to all popup sections
    const sections = document.querySelectorAll('.arr-effects-section, .effects-section');
    sections.forEach(section => {
        section.style.borderColor = theme.border;
        section.style.backgroundColor = theme.controlsBg;
    });
    
    // Apply to all labels
    const labels = document.querySelectorAll('label, .arr-label');
    labels.forEach(label => {
        label.style.color = theme.text;
    });
    
    // Apply to all inputs
    const inputs = document.querySelectorAll('input[type="range"], input[type="number"], input[type="text"]');
    inputs.forEach(input => {
        if (input.type === 'range') {
            input.style.setProperty('--thumb-color', theme.accent);
            input.style.setProperty('--track-color', theme.border);
        } else {
            input.style.backgroundColor = theme.buttonBg;
            input.style.color = theme.text;
            input.style.borderColor = theme.border;
        }
    });
    
    // Apply to tempo slider container
    const tempoContainer = document.querySelector('.arr-tempo');
    if (tempoContainer) {
        tempoContainer.style.color = theme.text;
    }
    
    // Apply to bar counter
    const barCounter = document.querySelector('.arr-bar-counter');
    if (barCounter) {
        barCounter.style.color = theme.text;
        barCounter.style.borderColor = theme.border;
        barCounter.style.backgroundColor = theme.buttonBg;
    }
    
    // Apply to tabs (LFO, Automation, etc)
    const tabs = document.querySelectorAll('.lfo-tab, .automation-tab');
    tabs.forEach(tab => {
        if (!tab.classList.contains('active')) {
            tab.style.backgroundColor = theme.buttonBg;
        } else {
            tab.style.backgroundColor = theme.accent;
        }
        tab.style.color = theme.text;
        tab.style.borderColor = theme.border;
    });
    
    // Apply to panels
    const panels = document.querySelectorAll('.lfo-panel, .automation-panel');
    panels.forEach(panel => {
        panel.style.backgroundColor = theme.controlsBg;
        panel.style.borderColor = theme.border;
    });
    
    // Apply to canvases borders
    const canvases = document.querySelectorAll('canvas');
    canvases.forEach(canvas => {
        canvas.style.borderColor = theme.border;
    });
    
    // Store current theme
    document.body.dataset.currentTheme = themeName;
    
    // Redraw the arrangement grid with new colors
    if (typeof drawArrangement === 'function') {
        drawArrangement();
    }
    
    console.log('âœ… Theme applied successfully');
}

// Initialize theme from localStorage
function initializeArrangementTheme() {
    // Get theme from PsychologicalStudio's localStorage
    const savedTheme = localStorage.getItem('psychologicalStudioTheme') || 'default';
    console.log('ðŸŽ¨ Loading saved theme from PsychologicalStudio:', savedTheme);
    applyArrangementTheme(savedTheme);
    
    // Listen for storage changes (when theme is changed in PsychologicalStudio)
    window.addEventListener('storage', (e) => {
        if (e.key === 'psychologicalStudioTheme' && e.newValue) {
            console.log('ðŸŽ¨ Theme changed in PsychologicalStudio, syncing:', e.newValue);
            applyArrangementTheme(e.newValue);
        }
    });
    
    // Also check periodically in case storage event doesn't fire
    setInterval(() => {
        const currentTheme = localStorage.getItem('psychologicalStudioTheme');
        if (currentTheme && currentTheme !== document.body.dataset.currentTheme) {
            console.log('ðŸŽ¨ Theme change detected via polling:', currentTheme);
            document.body.dataset.currentTheme = currentTheme;
            applyArrangementTheme(currentTheme);
        }
    }, 1000); // Check every second
}

// Call on page load
if (document.readyState === 'loading') {
    // Theme initialization should also be gated behind PsychologicalStudio access
    document.addEventListener('DOMContentLoaded', () => {
        if (checkPsychStudioAccess()) {
            // One-time consume token if present
            try { localStorage.removeItem('psychologicalStudioArrangementAccess'); } catch (e) {}
            initializeArrangementTheme();
        } else {
            // Do not initialize theme when opened directly â€” overlay will show instead
            showAccessLockedOverlay();
        }
    });
} else {
    initializeArrangementTheme();
}

console.log('âœ… Theme System Loaded');

console.log('âœ… Arrangement View Script Loaded!');
